{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to MkDocs","text":"<p>For full documentation visit mkdocs.org.</p>"},{"location":"#commands","title":"Commands","text":"<ul> <li><code>mkdocs new [dir-name]</code> - Create a new project.</li> <li><code>mkdocs serve</code> - Start the live-reloading docs server.</li> <li><code>mkdocs build</code> - Build the documentation site.</li> <li><code>mkdocs -h</code> - Print help message and exit.</li> </ul>"},{"location":"#project-layout","title":"Project layout","text":"<pre><code>mkdocs.yml    # The configuration file.\ndocs/\n    index.md  # The documentation homepage.\n    ...       # Other markdown pages, images and other files.\n</code></pre>"},{"location":"DevOps/Docker/","title":"Docker","text":"<p>![[architecture 1.svg]]</p>"},{"location":"DevOps/Docker/#images","title":"Images","text":"<p>An\u00a0image\u00a0is a read-only template with instructions for creating a Docker container. Often, an image is\u00a0based on\u00a0another image, with some additional customization. For example, you may build an image which is based on the\u00a0<code>ubuntu</code>\u00a0image, but installs the Apache web server and your application, as well as the configuration details needed to make your application run.</p> <p>You might create your own images or you might only use those created by others and published in a registry. To build your own image, you create a\u00a0Dockerfile\u00a0with a simple syntax for defining the steps needed to create the image and run it. Each instruction in a Dockerfile creates a layer in the image. When you change the Dockerfile and rebuild the image, only those layers which have changed are rebuilt. This is part of what makes images so lightweight, small, and fast, when compared to other virtualization technologies.</p>"},{"location":"DevOps/Docker/#containers","title":"Containers","text":"<p>A container is a runnable instance of an image. You can create, start, stop, move, or delete a container using the Docker API or CLI. You can connect a container to one or more networks, attach storage to it, or even create a new image based on its current state.</p> <p>By default, a container is relatively well isolated from other containers and its host machine. You can control how isolated a container\u2019s network, storage, or other underlying subsystems are from other containers or from the host machine.</p> <p>A container is defined by its image as well as any configuration options you provide to it when you create or start it. When a container is removed, any changes to its state that are not stored in persistent storage disappear.</p>"},{"location":"DevOps/Docker/#docker-compose","title":"Docker Compose","text":"<p>Compose is a tool for defining and running multi-container Docker applications. The multi wording is important. With Compose, you use a YAML file to configure your application\u2019s services. Then, with a single command, you create and start all the services from your configuration.</p> <p>For example lets say you have a python application that uses <code>redis</code> as the db. First you'd create your <code>Dockerfile</code> for the web application <pre><code># syntax=docker/dockerfile:1\nFROM python:3.7-alpine\nWORKDIR /code\nENV FLASK_APP=app.py\nENV FLASK_RUN_HOST=0.0.0.0\nRUN apk add --no-cache gcc musl-dev linux-headers\nCOPY requirements.txt requirements.txt\nRUN pip install -r requirements.txt\nEXPOSE 5000\nCOPY . .\nCMD [\"flask\", \"run\"]\n</code></pre></p> <p>Then you define your services in a Compose file. <pre><code>services:\n  web:\n    build: .\n    ports:\n      - \"8000:5000\"\n  redis:\n    image: \"redis:alpine\"\n</code></pre></p> <p>Finally, build your whole app with <code>docker compose up</code>.</p> <p>![[Diagrams-3.jpg]]</p>"},{"location":"DevOps/Kubernetes%20Project/","title":"Fleetman Web App","text":"<p>The purpose of this project is to better understand kubernetes and working with microservices. In the beginning stages, I only had the sbility to deploy this locally, and by the end I was able to deploy to AWS. Note: I did not develop the fleetman web app. </p> <pre><code># Commands\nminikube service webapp --url\nkubectl port-forward svc/queue 30070:8161 \nkubectl port-forward svc/fleetman-position-tracker 30060:8080\n</code></pre>"},{"location":"DevOps/Kubernetes%20Project/#why-do-i-need-to-run-minikube-service-command","title":"Why do I need to run minikube service command ?","text":"<p>The network is limited if using the Docker driver on Darwin, Windows, or WSL, and the Node IP is not reachable directly.</p> <p>Running minikube on Linux with the Docker driver will result in no tunnel being created.</p> <p>Services of type\u00a0<code>NodePort</code>\u00a0can be exposed via the\u00a0<code>minikube service &lt;service-name&gt; --url</code>\u00a0command. It must be run in a separate terminal window to keep the\u00a0tunnelopen. Ctrl-C in the terminal can be used to terminate the process at which time the network routes will be cleaned up.</p>"},{"location":"DevOps/Kubernetes%20Project/#labels-for-quickly-changing-release-versions","title":"Labels for Quickly Changing Release Versions","text":"<p>By the time you come back to this, the release0 will probably \\have been deleted from the project <pre><code># POD FILE\n\napiVersion: v1\nkind: Pod\nmetadata: \n  name: webapp\n  labels:\n    app: webapp\n    release: \"0\"\nspec:\n  containers:\n  - name: webapp\n    image: richardchesterwood/k8s-fleetman-webapp-angular:release0\n\n---\napiVersion: v1\nkind: Pod\nmetadata:\n  name: webapp-release-0-5\n  labels:\n    app: webapp\n    release: 0-5\nspec:\n  containers:\n  - name: webapp\n    image: richardchesterwood/k8s-fleetman-webapp-angular:release0-5\n\n---\napiVersion: v1\nkind: Pod\nmetadata:\n  name: queue\n  labels:\n    app: queue\nspec:\n  containers:\n  - name: queue\n    image: richardchesterwood/k8s-fleetman-queue:release1-arm64\n</code></pre></p> <pre><code># SERVICE FILE\napiVersion: v1\nkind: Service\nmetadata:\n  name: webapp\n\nspec:\n  selector:\n    app: webapp\n    # This relase key:value pair is being found in our above pod file. So, if we were to change this to \"0\", then the service would switch to the \n    # rlease0 image.\n    release: 0-5\n\n  ports:\n    - name: http\n      port: 80\n      nodePort: 30080\n\n  type: NodePort\n</code></pre>"},{"location":"DevOps/Kubernetes%20Project/#replica-sets","title":"Replica Sets","text":"<pre><code>### Replica Set###\napiVersion: apps/v1\nkind: ReplicaSet\nmetadata:\n  name: webapp\nspec:\n  selector:\n    matchLabels:\n      app: webapp\n  replicas: 2\n### Replica Set###\n\n    #### POD ###\n  template:\n    metadata:\n      labels:\n        app: webapp\n    spec:\n      containers:\n      - name: webapp\n        image: richardchesterwood/k8s-fleetman-webapp-angular:release0-5\n    #### POD ###\n\n\n\n---\napiVersion: v1\nkind: Pod\nmetadata:\n  name: queue\n  labels:\n    app: queue\nspec:\n  containers:\n  - name: queue\n    image: richardchesterwood/k8s-fleetman-queue:release1-arm64\n</code></pre>"},{"location":"DevOps/Kubernetes%20Project/#volumes","title":"Volumes","text":"<pre><code>### Deployment###\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: mongodb\nspec:\n  selector:\n    matchLabels:\n      app: mongodb\n  replicas: 1\n### Deployment ###\n\n    #### POD ###\n  template:\n    metadata:\n      labels:\n        app: mongodb\n    spec:\n      containers:\n      - name: mongodb\n        image: mongo:latest\n        volumeMounts:\n          - name: mongo-persistent-storage\n            # This is the folder inside the container that will be mapped to a\n            # folder on our host.\n            mountPath: /data/db\n      volumes:\n        - name: mongo-persistent-storage\n          hostPath:\n            path: /mnt/mongodb\n            type: DirectoryOrCreate\n    #### POD ###\n---\nkind: Service\napiVersion: v1\nmetadata:\n  name: fleetman-mongodb\nspec:\n  selector:\n    app: mongodb\n  ports:\n    - name: mongoport\n      port: 27012\n  type: ClusterIP\n</code></pre>"},{"location":"DevOps/Kubernetes%20Project/#aws","title":"AWS","text":"<p>[!WARNING] Remember to delete your cluster when not working on it. 1.  kops delete cluster ${NAME} --yes   1. DO NOT CLOSE TERMINAL UNTIL THIS IS FINISHED 2.  In the AWS console, ensure that you don't have any Load Balancers or Auto Scaling Groups running</p>"},{"location":"DevOps/Kubernetes%20Project/#monitoring","title":"Monitoring","text":"<ol> <li>kubectl apply -f crds.yaml<ol> <li>Run this command first</li> </ol> </li> <li>kubectl apply -f monitoring.yml<ol> <li>Then run this one</li> </ol> </li> <li>To access grafana, you'll need to change the service to a LoadBalancer<ol> <li>kubectl edit svc monitoring-grafana -n monitoring</li> </ol> </li> <li>Then you can access using the load-balacner DNS name.</li> </ol>"},{"location":"DevOps/ansible_terraform_project/","title":"Dev Ops Project","text":"<p>Objective: We will be deploying Grafana and Prometheus to EC2 instances using  Terraform, Ansible, and Jenkins</p>"},{"location":"DevOps/ansible_terraform_project/#the-terraform-part","title":"The Terraform Part","text":""},{"location":"DevOps/ansible_terraform_project/#lifecycle-policies","title":"Lifecycle Policies","text":"<p>Lets say we want to change our VPC cidr block from \"10.123.0.0/16\" to \"10.124.0.0/16\". If we try to apply this, it will fail. But why? Because, to update the cidr block, our VPC resource has to be destroyed and then created. In this process our internet gateway wont have anything to connect to because the VPC was destroyed. To get arouund this, we can add a lifecycle policy. </p> <pre><code>resource \"aws_vpc\" \"architech_vpc\" {\n  cidr_block           = var.vpc_cidr\n  enable_dns_hostnames = true\n  enable_dns_support   = true\n\n  tags = {\n    Name = \"architech_vpc-${random_id.random.dec}\"\n  }\n\n  lifecycle {\n    create_before_destroy = true\n  }\n\n}\n</code></pre> <p>The <code>create_before_destroy</code> does just that. It creates the new VPC first, so that the internet gateway has something to connect to prior to destroying. \ud83c\udf89</p>"},{"location":"DevOps/ansible_terraform_project/#connect-to-aws","title":"Connect to AWS","text":"<p>I'm connected to AWS via VS code, using a profile I created called <code>default</code>.</p>"},{"location":"DevOps/ansible_terraform_project/#the-ansible-part","title":"The Ansible Part","text":""},{"location":"DevOps/ansible_terraform_project/#introducing-jenkins","title":"Introducing Jenkins","text":""},{"location":"DevOps/ci_cd/","title":"CI/CD","text":""},{"location":"DevOps/ci_cd/#continuous-integration","title":"Continuous Integration","text":"<p>Continuous integration\u00a0is a software development practice where members of a team use a version control system and frequently integrate their work to the same location, such as a main branch. Each change is built and verified to detect integration errors as quickly as possible. Continuous integration is focused on automatically building and testing code, as compared to\u00a0continuous delivery, which automates the entire software release process up to production.</p>"},{"location":"DevOps/ci_cd/#continuous-delivery","title":"Continuous Delivery","text":"<p>Continuous delivery\u00a0is a software development methodology where the release process is automated. Every software change is automatically built, tested, and deployed to production. Before the final push to production, a person, an automated test, or a business rule decides when the final push should occur. Although every successful software change can be immediately released to production with continuous delivery, not all changes need to be released right away.</p>"},{"location":"DevOps/ci_cd/#gitlab","title":"Gitlab","text":"<p>All of the fun takes place in the <code>.gitlab-ci.yml</code> file. </p> <pre><code>#Self explamatory. Variables names to pass later\nvariables:\n\u00a0 IMAGE_NAME: xalxnder/demo-app\n\u00a0 IMAGE_TAG: python-app-1.0\n\u00a0\n#The names and order of the pipeline stages.\nstages:\n\u00a0 - test\n\u00a0 - build\n\u00a0 - deploy\n\nrun_tests:\n\u00a0 stage: test\n\u00a0 #Use\u00a0`image`\u00a0to specify a Docker image that the job runs in. So this run_tests stage will run in the python:3.9-slim-buster image.\n\u00a0 image: python:3.9-slim-buster\n\u00a0 #Command/s to run before the script\n\u00a0 before_script:\n\u00a0 \u00a0 - apt-get update &amp;&amp; apt-get install make\n\u00a0 #Shell script that is executed by a runner.\n\u00a0 script:\n\u00a0 \u00a0 - make test\n\nbuild_image:\n\u00a0 stage: build\n\u00a0 image: docker:20.10.16\n\u00a0# When you configure CI/CD, you specify an image, which is used to create the container where your jobs run. To specify this    image,   you use the\u00a0`image`\u00a0keyword. You can specify an additional image by using the\u00a0`services`\u00a0keyword. This additional image is used to create another container,     which is available to the first container. The two containers have access to one another and can communicate when running the job.\n\u00a0 services:\n\u00a0 \u00a0 - docker:20.10.16-dind\n\u00a0 variables:\n\u00a0 \u00a0 DOCKER_TLS_CERTDIR: \"/certs\"\n\u00a0 before_script:\n\u00a0 #For this example since we're using our own private docker registry, we'll need to login.\n\u00a0 \u00a0 - docker login -u $DOCKER_USERNAME -p $DOCKER_PASSWORD\n\u00a0 script:\n\u00a0 # Build docker Image\n\u00a0 \u00a0 - docker build -t $IMAGE_NAME:$IMAGE_TAG .\n\u00a0 \u00a0 #Push Image\n\u00a0 \u00a0 - docker push $IMAGE_NAME:$IMAGE_TAG\n\ndeploy:\n\u00a0 stage: deploy\n\u00a0 before_script:\n\u00a0 \u00a0 - chmod 400 $SSH_KEY\n\u00a0 script: ssh -o StrictHostKeyChecking=no -i $SSH_KEY root@216.155.152.132 \"\n\u00a0 \u00a0 \u00a0 docker login docker.io -u $DOCKER_USERNAME -p $DOCKER_PASSWORD &amp;&amp;\n\u00a0 \u00a0 \u00a0 docker run -d -p 5000:5000 docker.io/$IMAGE_NAME:$IMAGE_TAG\"\n</code></pre>"},{"location":"DevOps/microservies/","title":"Monoliths","text":"<p>A monolith architecture is one where an entire application is deployed as a single unit. For example, in a Java web based app, it will be a WAR file. Based on the business requirements, this WAR file will have the code for shopping cart management, sales, inventory management, authentication etc... As you can see, this will most likely turn into a mess.</p>"},{"location":"DevOps/microservies/#microservices","title":"Microservices","text":"<p>Self contained components or subsystem. They can live on their own, communicate with each other, and be deployed on their own. </p>"},{"location":"DevOps/Jenkins/controller_agent/","title":"Controller vs Agent","text":"<p>For the below we'll need the following prerequisites:  1. 2 VMs With Docker  2. Dockerfile with Jenkins</p>"},{"location":"DevOps/Jenkins/controller_agent/#how-to-isolate-controller-from-agent-docker-containers-on-same-host","title":"How To Isolate Controller From  Agent (Docker Containers on Same Host)","text":"<ol> <li>Create your controller  container with a Dockerfile <pre><code>FROM jenkins/jenkins:2.452.2-jdk17\nUSER root\nRUN apt-get update &amp;&amp; apt-get install -y lsb-release\nRUN curl -fsSLo /usr/share/keyrings/docker-archive-keyring.asc \\\n  https://download.docker.com/linux/debian/gpg\nRUN echo \"deb [arch=$(dpkg --print-architecture) \\\n  signed-by=/usr/share/keyrings/docker-archive-keyring.asc] \\\n  https://download.docker.com/linux/debian \\\n  $(lsb_release -cs) stable\" &gt; /etc/apt/sources.list.d/docker.list\nRUN apt-get update &amp;&amp; apt-get install -y docker-ce-cli\nUSER jenkins\nRUN jenkins-plugin-cli --plugins \"blueocean docker-workflow\"\n</code></pre></li> <li>Setup Jenkins via GUI</li> <li>Under plugins, add the Docker Plugin</li> <li>Create proxy container so that Jenkins can talk to Docker <pre><code>docker run -d --restart=always -p 127.0.0.1:2374:2375 --network jenkins -v /var/run/docker.sock:/var/run/docker.sock alpine/socat tcp-listen:2375,fork,reuseaddr unix-connect:/var/run/docker.sock\n</code></pre></li> <li>Mange Jenkins --&gt; Clouds --&gt; New Cloud</li> <li>Enter the cloud name, and select Docker for type</li> <li>Select Docker Agent Templates</li> <li>Enter a Label and Name</li> <li>For the Docker Image, you can select any docker image you'd like. Just make sure the architecture matches your host's</li> <li>Set <code>Remote File System Root</code> to /home/jenkins</li> <li>You can leave everything how it is, and hit save. </li> <li>Select Docker Cloud Details</li> <li>The Docker Host URI will be the ip address of the container you created in step 3, appended with <code>tcp://</code>. So for example, <code>tcp://192.268.188.2375</code>. </li> </ol>"},{"location":"DevOps/Jenkins/controller_agent/#how-to-isolate-controller-from-agentdocker-containers-on-separate-hosts","title":"How To Isolate Controller From Agent(Docker Containers On Separate Hosts)","text":""},{"location":"DevOps/Kubernetes/Architecture/","title":"Architecture","text":"<p>![[Pasted image 20240713154853.png]]</p> <p>Master Node (Control Plane)</p> <p>The control plane's components make global decisions about the cluster (for example, scheduling), as well as detecting and responding to cluster events (for example, starting up a new\u00a0pod\u00a0when a Deployment's\u00a0<code>[replicas](https://kubernetes.io/docs/reference/glossary/?all=true#term-replica)</code>\u00a0field is unsatisfied). The control plane has multiple compnents: - kube-apiserver - etcd - kube-scheduler - kube-controller-manager </p> <p>Nodes Kubernetes runs your\u00a0workload\u00a0by placing containers into Pods to run on\u00a0Nodes. A node may be a virtual or physical machine, depending on the cluster. Each node is managed by the\u00a0control plane\u00a0and contains the services necessary to run\u00a0Pods.</p> <p>Typically you have several nodes in a cluster; in a learning or resource-limited environment, you might have only one node.</p> <p>The\u00a0components\u00a0on a node include the\u00a0kubelet, a\u00a0container runtime, and the\u00a0kube-proxy.</p>"},{"location":"DevOps/Kubernetes/Kubernetes/","title":"Kubernetes","text":"<p>kubeadm vs minikube</p> <p>Designed for learning, development and testing,\u00a0minikube is a fast and simple solution for deploying a single node cluster. kubeadm builds a minimum viable, production-ready Kubernetes cluster that conforms to best practices.</p>"},{"location":"DevOps/Kubernetes/Kubernetes/#architecture","title":"Architecture","text":""},{"location":"DevOps/Kubernetes/Kubernetes/#pods","title":"Pods","text":"<p>Think of a pod as being a wrapper for a container. You can have more that one container in a pod, but rarely done. Pods are not visible outside the cluster. In Kubernetes, a\u00a0<code>Pod</code>\u00a0represents a set of running\u00a0containers\u00a0on your cluster.</p> <p>![[Pasted image 20230621044805.png]]</p> <p>![[Untitled Diagram 1.png]]</p>"},{"location":"DevOps/Kubernetes/Kubernetes/#service","title":"Service","text":"<p>If a pod dies and gets restarts, a new IP address is created. This is not efficient. This is where Services come into play.  In Kubernetes, a Service is a method for exposing a network application that is running as one or more\u00a0Pods\u00a0in your cluster.  Each Pod has its own IP address. </p> <p>Lifecycles of Pods and Services are not connected. So, if our DB pod dies and gets restarted, we it still has the same exact Service IP address  ![[Pasted image 20230621050441.png]]</p>"},{"location":"DevOps/Kubernetes/Kubernetes/#labels","title":"Labels","text":"<p>Labels enable users to map their own organizational structures onto system objects in a loosely coupled fashion, without requiring clients to store these mappings.</p> <p>These are examples of\u00a0commonly used labels; you are free to develop your own conventions. Keep in mind that label Key must be unique for a given object.</p> <ul> <li><code>\"release\" : \"stable\"</code>,\u00a0<code>\"release\" : \"canary\"</code></li> <li><code>\"environment\" : \"dev\"</code>,\u00a0<code>\"environment\" : \"qa\"</code>,\u00a0<code>\"environment\" : \"production\"</code></li> <li><code>\"tier\" : \"frontend\"</code>,\u00a0<code>\"tier\" : \"backend\"</code>,\u00a0<code>\"tier\" : \"cache\"</code></li> <li><code>\"partition\" : \"customerA\"</code>,\u00a0<code>\"partition\" : \"customerB\"</code></li> <li><code>\"track\" : \"daily\"</code>,\u00a0<code>\"track\" : \"weekly\"</code></li> </ul>"},{"location":"DevOps/Kubernetes/Kubernetes/#replica-sets","title":"Replica Sets","text":"<p>A ReplicaSet's purpose is to maintain a stable set of replica Pods running at any given time. As such, it is often used to guarantee the availability of a specified number of identical Pods.  You can specify how many pods at ANY given time should be running.</p>"},{"location":"DevOps/Kubernetes/Kubernetes/#deployments","title":"Deployments","text":"<p>A more sophisticated version of Replica Sets.  These manage the replica sets for us.</p>"},{"location":"DevOps/Kubernetes/Kubernetes/#storage","title":"Storage","text":""},{"location":"DevOps/Terraform/state/","title":"State","text":"<p>Terraform must store state about your managed infrastructure and configuration. This state is used by Terraform to map real world resources to your configuration, keep track of metadata, and to improve performance for large infrastructures.</p> <p>This state is stored by default in a local file named \"terraform.tfstate\", but we recommend\u00a0storing it in Terraform Cloud\u00a0to version, encrypt, and securely share it with your team.</p> <p>Terraform uses state to determine which changes to make to your infrastructure. Prior to any operation, Terraform does a\u00a0refresh\u00a0to update the state with the real infrastructure.</p> <p>The primary purpose of Terraform state is to store bindings between objects in a remote system and resource instances declared in your configuration. When Terraform creates a remote object in response to a change of configuration, it will record the identity of that remote object against a particular resource instance, and then potentially update or delete that object in response to future configuration changes.</p>"},{"location":"Linux/AUTOFS/","title":"AUTOFS","text":"<pre><code>`1`#### Configuring\u00a0`autofs`\u00a0to mount home directories on\u00a0`server1`\n</code></pre> <ol> <li> <p>Become\u00a0<code>root</code>:</p> <p><code>sudo -i</code></p> </li> <li> <p>Install the\u00a0<code>autofs</code>\u00a0package:</p> <p><code>yum -y install autofs</code></p> </li> <li> <p>Create the\u00a0<code>/export/home</code>\u00a0directory:</p> <p><code>mkdir -p /export/home</code></p> </li> <li> <p>Add the mapping for the\u00a0<code>/export/home</code>\u00a0directory to\u00a0<code>/etc/auto.master</code>:</p> <p><code>vi /etc/auto.master</code></p> </li> <li> <p>At the end of the file, above the line with\u00a0<code>+auto.master</code>, add:</p> <p><code>/export/home /etc/auto.home</code></p> </li> <li> <p>Save and quit:</p> <p><code>:wq</code></p> </li> <li> <p>Edit\u00a0<code>/etc/auto.home</code>:</p> <p><code>vi /etc/auto.home</code></p> </li> <li> <p>Add the following line:\u00a0(NOTE: Use command\u00a0<code>ip addr</code>\u00a0on\u00a0<code>server2</code>\u00a0for private IP address)</p> <p><code>* &lt;second_server_private_IP&gt;:/home/&amp;</code></p> </li> <li> <p>Save and quit:</p> <p><code>:wq</code></p> </li> <li> <p>Confirm NFS export:</p> <p><code>showmount -e &lt;second_server_private_IP&gt;</code></p> </li> <li> <p>Start and enable\u00a0<code>autofs</code>\u00a0service:</p> <p><code>systemctl enable --now autofs</code></p> </li> <li> <p>Check\u00a0<code>autofs</code>\u00a0status:</p> <p><code>systemctl status autofs</code></p> </li> <li> <p>On\u00a0<code>server1</code>, change user's home directory locations to\u00a0<code>/export/home</code>:</p> <p><code>for i in manny moe jack marcia jan cindy; do usermod -d /export/home/$i $i; done</code></p> </li> <li> <p>Confirm changes:</p> <p><code>grep -E 'manny|moe|jack|marcia|jan|cindy' /etc/passwd</code></p> </li> <li> <p>On\u00a0<code>server1</code>, test as the user\u00a0<code>manny</code>:</p> <p><code>su - manny</code></p> </li> <li> <p>Check directory:</p> <p><code>pwd</code></p> </li> <li> <p>Create a file:</p> <p><code>touch file1</code></p> </li> <li> <p>Create a directory:</p> <p><code>mkdir directory1</code></p> </li> <li> <p>Check our work:</p> <p><code>ls -la</code></p> </li> <li> <p>Log out\u00a0<code>manny</code>:</p> <p><code>exit</code></p> </li> <li> <p>On\u00a0<code>server1</code>, test as\u00a0<code>moe</code>:</p> <p><code>su - moe</code></p> </li> <li> <p>Check directory:</p> <p><code>pwd</code></p> </li> <li> <p>Create a file:</p> <p><code>touch file1</code></p> </li> <li> <p>Create a directory:</p> <p><code>mkdir directory1</code></p> </li> <li> <p>Check our work:</p> <p><code>ls -la</code></p> </li> <li> <p>Log out\u00a0<code>moe</code>:</p> <p><code>exit</code></p> </li> <li> <p>On\u00a0<code>server1</code>, test as\u00a0<code>jack</code>:</p> <p><code>su - jack</code></p> </li> <li> <p>Check directory:</p> <p><code>pwd</code></p> </li> <li> <p>Create a file:</p> <p><code>touch file1</code></p> </li> <li> <p>Create a directory:</p> <p><code>mkdir directory1</code></p> </li> <li> <p>Check our work:</p> <p><code>ls -la</code></p> </li> <li> <p>Log out\u00a0<code>jack</code>:</p> <p><code>exit</code></p> </li> <li> <p>Confirm that the home directories are mounted via\u00a0<code>autofs</code>\u00a0on the first server:</p> <p><code>mount | grep home</code></p> </li> </ol>"},{"location":"Linux/Make%20sure%20your%20baseurl%20parameter%20is%20correct/","title":"Make sure your baseurl parameter is correct","text":"<p>When configuring local repos, I received the following error. <pre><code>- Curl error (37): Couldn't read a file:// file for file:///repo/rhel9.iso/repodata/repomd.xml \n# Cant remember the exact output, but it was very similar to this\n</code></pre></p> <p>When configuring a repository from the installation disk, you'll need to create a mount location/directory. When editing the contents of that .repo file, ensure that the directory you created matches the {path} in <code>baseurl</code>=file:///{path}/{repo-name}.</p> <p>So if your directory is <code>test_dir</code>, your baseurl will be <code>baseurl=file:///test_dir/AppStream</code></p>"},{"location":"Linux/Make%20sure%20your%20baseurl%20parameter%20is%20correct/#linux-repos-baseurl","title":"linux #repos #baseurl","text":""},{"location":"Linux/Networks/","title":"Fundamentals","text":"<p>To set up networking on a server, your server needs a unique address on the network. For this purpose, Internet Protocol (IP) addresses are used. Currently, two versions of IP addresses are relevant:</p> <ol> <li>IPv4  - These are based on 32-bit addresses and have four octets, separated by dots, such as <code>192.168.10.100</code>.</li> <li>IPv6  - These are based on 128-bit addresses and are written in eight groups of hexadecimal numbers that are 16 bits each and separated by colons. An IPv6 address may look like <code>fe80:badb:abe01:45bc:34ad:1313:6723:8798</code>.</li> </ol>"},{"location":"Linux/Networks/#ip-addresses","title":"IP Addresses","text":"<p>To make it easier for computers to communicate with one another, every IP address belongs to a specific network, and to communicate with computers on another network, a router is used. A router is a machine (often dedicated hardware that has been created for that purpose) that connects networks to one another.</p>"},{"location":"Linux/Networks/#private-addresses","title":"Private Addresses","text":"<p>Private network addresses are addresses that are for use in internal networks only. Private networks are one solution(the other being IPv6) to the problem that arrises from the scarcity of available IP address. Some specific IP network addresses have been reserved for this purpose: -   <code>10.0.0.0/8</code> (a single Class A network) -   <code>172.16.0.0/12</code> (16 Class B networks)  -   <code>192.168.0.0/16</code> (256 Class C networks)</p> <p>When private addresses are used, the nodes that are using them cannot access the Internet directly, and nodes from the Internet cannot easily access them. Because that is not very convenient, Network Address Translation (NAT) is commonly used on the router that connects the private network to the Internet. In NAT, the nodes use a private IP address, but when accessing the Internet, this private IP address is replaced with the IP address of the NAT router. Hence, nodes on the Internet think that they are communicating with the NAT router, and not with the individual hosts. ![[Pasted image 20220712064219.png]]</p> <p>IP Address are broken into two portions. 1. 192.168.1 - The Network Portion     1. The unique number of your address     2. The class of your network 2. .14 - The Host Portion     1. Uniquely identifies the machine. </p> <p>Ok, so how do other hosts know which part of the address is the network and which part is host?? This is where subnet masking comes into play. </p>"},{"location":"Linux/Networks/#network-masks","title":"Network Masks","text":"<p>To know to which network a computer belongs, a subnet mask is used with every IP address. The subnet mask defines which part of the network address indicates the network and which part indicates the node.</p> <p>Example 192.168.123.132/24 or 255.255.255.0</p>"},{"location":"Linux/Networks/#mac-addresses","title":"Mac Addresses","text":"<p>Each network card also has a 12-byte MAC address. MAC addresses are for use on the local network (that is, the local physical network or local WLAN, just up to the first router that is encountered); they cannot be used for communications between nodes that are on different networks. MAC addresses are important, though, because they help computers find the specific network card that an IP address belongs to.</p>"},{"location":"Linux/Networks/#protocols-and-ports","title":"Protocols and Ports","text":"Port Service 80 HTTP 22 SSH"},{"location":"Linux/Networks/#managing-network-address-and-interfaces","title":"Managing Network Address and Interfaces","text":"<p>Network addresses can be assigned in two ways:</p> <ul> <li>Fixed IP addresses -  Useful for servers that always need to be available at the same IP address.</li> <li>Dynamically assigned IP addresses - Useful for end users\u2019 devices, and for instances in a cloud environment. To dynamically assign IP addresses, you usually use a Dynamic Host Configuration Protocol (DHCP) server.</li> </ul>"},{"location":"Linux/Networks/#validating-network-configuration","title":"Validating Network Configuration","text":""},{"location":"Linux/Networks/#validating-network-address-configuration","title":"Validating Network Address Configuration","text":"<p>To verify the configuration of the network address, you need to use the <code>ip</code> utility. With the <code>ip</code> utility, many aspects of networking can be monitored:</p> <ul> <li>Use<code>ip addr</code> to configure and monitor network addresses. <ul> <li>ip addr add - Specify the device, and the IP address you want to add. </li> </ul> </li> <li>Use <code>ip route</code> to configure and monitor routing information.<ul> <li>ip route show</li> </ul> </li> <li>Use <code>ip link</code> to configure and monitor network link state.</li> </ul> <p>[!WARNING] Changes made with ip are NOT persistent.</p>"},{"location":"Linux/Networks/#configuring-network-configuration-with-nmtui-and-nmcli","title":"Configuring Network Configuration with nmtui and nmcli","text":"<p>[!WARNING] Changes made with nm are persistent.</p> <p>[!TIP] nmtui has a text interface and nmcli is the command line interface. For the exam, stick with nmtui. When working with network configuration in RHEL 8, you should know the difference between a device and a connection:</p> <ul> <li>A device is a network interface card.</li> <li>A connection is the configuration that is used on a device.</li> </ul> <p>Believe it or not, if an ordinary user is logged in to the local console, this user can make changes to the network configuration. To check your current permissions, use the <code>nmcli gen permissions</code> command, as shown in</p>"},{"location":"Linux/Networks/#nmcli","title":"NMCLI","text":"<p>[!TIP] ENsure that the bash-completion RPM package is installed with working with nmcli</p>"},{"location":"Linux/Networks/#network-configuration-files","title":"Network Configuration Files","text":"<p>Every connection that you create is stored as a configuration file in the directory <code>/etc/sysconfig/network-scripts</code>. The name of the configuration files starts with ifcfg- and is followed by the name of the network interface. If you don't like using nmcli or nmtui, you can use the config files. After you're finished editing, just make sure you run <code>nmcli con up</code></p>"},{"location":"Linux/Networks/#hostname-and-name-resolution","title":"Hostname and Name Resolution","text":"<p>You can change the hostname with one of the following:  -   Use <code>nmtui</code> and select the option Change Hostname. -   Use <code>hostnamectl set-hostname</code>. -   Edit the contents of the configuration file /etc/hostname.</p>"},{"location":"Linux/Networks/#hostname-resolution","title":"Hostname Resolution","text":"<p>Hostname resolution can be configured in <code>/etc/hosts</code>. Setting up an /etc/hosts file is easy; just make sure that it contains at least two columns. The first column has the IP address of the specific host, and the second column specifies the hostname. The hostname can be provided as a short name (like server1) or as an FQDN. In an FQDN, the hostname as well as the complete DNS name are included, as in server1.example.com.</p> <p>If a host has more than one name, like a short name and a fully qualified DNS name, you can specify both of them in /etc/hosts. In that case, the second column must contain the FQDN, and the third column can contain the alias. Example 8-10 shows a hostname configuration example.</p>"},{"location":"Linux/Networks/#dns-name-resolution","title":"DNS Name Resolution","text":"<p>To specify which DNS server should be used, set the DNS server using <code>nmcli</code> or <code>nmtui</code>. The NetworkManager configuration stores the DNS information in the configuration file for the network connection, which is in /etc/sysconfig/network-scripts, and from there pushes the configuration to the /etc/resolv.conf file, which is used for DNS name server resolving.</p> <p>[!TIP] It is recommended to always set up at least two DNS name servers to be contacted. Why? IF the first server does not answer, then 2nd one is contacted. </p> <p>[!WARNING] Do not edit <code>/etc/resolv.conf</code>. It will be overwritten the next time you restart  Network Manager.</p> <p>To specify the DNS name servers you want to use, you have a few options: -   Use nmtui to set the DNS name servers.  -   Set the DNS1 and DNS2 parameters in the ifcfg network connection configuration file in /etc/sysconfig/network-scripts. -   Use a DHCP server that is configured to hand out the address of the DNS name server. -   Use nmcli con mod  [+]ipv4.dns . <p>Remeber, when updating your IP address make sure the following are set up: 1. Ip Address 2. Netmask 3. Gateway</p>"},{"location":"Linux/What%20is%20no__root__squash%3F/","title":"What is no  root  squash?","text":"<p>The <code>no__root__squash</code> option in <code>/etc/exports</code> is extremely unsafe to use. By default, NFS shares change the root user to the\u00a0<code>nfsnobody</code>\u00a0user, an unprivileged user account. This prevents a client computer\u2019s root user from being able to change all files and directories in the shared filesystem. For RHCSA this option is ok, but elsewhere, don't use it.</p>"},{"location":"Linux/What%20is%20no__root__squash%3F/#nfs-squash","title":"nfs #squash","text":""},{"location":"Linux/output_file_to_itself/","title":"Why does catting a file to itself erase it?","text":"<pre><code>\u279c  Bash cat input.txt\nmanny:1010:dba_admin,dba_managers,dba_staff moe:1011:dba_admin,dba_staff jack:1012:dba_intern,dba_staff marcia:1013:it_staff,it_managers jan:1014:dba_admin,dba_staff cindy:1015:dba_intern,dba_staff\n\n\u279c  Bash sed 's/ /\\n/g' input.txt\nmanny:1010:dba_admin,dba_managers,dba_staff\nmoe:1011:dba_admin,dba_staff\njack:1012:dba_intern,dba_staff\nmarcia:1013:it_staff,it_managers\njan:1014:dba_admin,dba_staff\ncindy:1015:dba_intern,dba_staff\n\n\u279c  Bash sed 's/ /\\n/g' input.txt &gt; input.txt\n\u279c  Bash cat input.txt\n</code></pre> <p>Consider\u00a03.1.1 Shell Operation, particularly the order in which things are done:</p> <ul> <li>redirections are processed\u00a0before\u00a0the command is actually executed, but</li> <li>expansions are processed before redirections.</li> </ul> <p>So in the above example, the shell truncates <code>input.txt</code>, THEN attempts to run the sed command. Since, input.txt has already been truncated, <code>sed</code> is working with an empty file.</p> <p>TLDR;</p> <p>DON'T DO THIS :) </p>"},{"location":"Linux/Quick%20Hits/replacing/","title":"Replacing","text":""},{"location":"Linux/Quick%20Hits/replacing/#replace-using-vim","title":"Replace Using Vim","text":"<pre><code>:%s/old/new/g\n</code></pre>"},{"location":"Linux/Quick%20Hits/replacing/#replace-lines-in-file-on-cli","title":"Replace lines in File on CLI","text":"<pre><code>sed -i -e 's/old/new/g' hello.txt\n</code></pre>"},{"location":"Linux/RHCSA/Find_Exercises/","title":"Find Exercises","text":"<ul> <li>Find a file named\u00a0<code>document.pdf</code>\u00a0in the\u00a0<code>/home/linuxize</code></li> <li>Find all files ending with\u00a0<code>.log.gz</code>\u00a0inside the\u00a0<code>/var/log/nginx</code></li> <li>Find all directories in your current working directory</li> <li>Find all files of exactly\u00a0<code>1024</code>\u00a0bytes inside the\u00a0<code>/tmp</code>\u00a0directory.</li> <li>Find files less than\u00a0<code>1MB</code>\u00a0inside the current working directory.</li> <li>files with a size greater than\u00a0<code>1MB</code></li> <li>Find all files with permissions of exactly\u00a0<code>775</code>\u00a0inside the\u00a0<code>/var/www/html</code>\u00a0directory</li> <li> <ul> <li>Find files less than\u00a0<code>500 MB</code>\u00a0inside the current working directory and copy them to the <code>/tmp</code>directory</li> </ul> </li> </ul>"},{"location":"Linux/RHCSA/bash_practice/","title":"Shell Scripting Exercises","text":"<p>Exercise_1 - Write a shell script that prints \u201cShell Scripting is Fun!\u201d on the screen**</p>"},{"location":"Linux/RHCSA/Asghar%20Ghori/Exam%201/","title":"Exam 1","text":"<ol> <li>Using\u00a0a\u00a0manual\u00a0method\u00a0(create/modify\u00a0files\u00a0by\u00a0hand),\u00a0configure\u00a0a\u00a0network connection on the primary network device with IP address\u00a0192.168.0.241/24, gateway 192.168.0.1, and nameserver 192.168.0.1. Use different\u00a0IP\u00a0assignments\u00a0based\u00a0on\u00a0your\u00a0lab\u00a0setup.\u00a0(Exercise\u00a016-3).\u00a0</li> <li>Using\u00a0a\u00a0manual\u00a0method\u00a0(modify\u00a0file\u00a0by\u00a0hand),\u00a0set\u00a0the\u00a0system\u00a0host-\u00a0name\u00a0to\u00a0rhcsa1.example.com\u00a0and\u00a0alias\u00a0rhcsa1.\u00a0Make\u00a0sure\u00a0that\u00a0the\u00a0new\u00a0host-\u00a0name\u00a0is\u00a0reflected\u00a0in\u00a0the\u00a0command\u00a0prompt.\u00a0(Exercises\u00a016-1\u00a0and\u00a016-5).\u00a0\u00a0</li> <li>Set\u00a0the\u00a0default\u00a0boot\u00a0target\u00a0to\u00a0multi-user.\u00a0(Chapter\u00a012,\u00a0topic:\u00a0Managing\u00a0Target Units).\u00a0\u00a0</li> <li> <p>Set\u00a0SELinux\u00a0to\u00a0permissive\u00a0mode.\u00a0</p> </li> <li> <p>Perform\u00a0a\u00a0case-insensitive\u00a0search\u00a0for\u00a0all\u00a0lines\u00a0in\u00a0the\u00a0/usr/share/dict/\u00a0linux.-words file that begin with the pattern \u201cessential\u201d. Redirect the output to\u00a0<code>/var/tmp/pattern.txt</code>file.\u00a0Make\u00a0sure\u00a0that\u00a0empty\u00a0lines\u00a0are\u00a0omitted.\u00a0(Chapter\u00a007,\u00a0topic: Regular Expressions).</p> </li> <li> <p>Create\u00a0user\u00a0accounts\u00a0called\u00a0lisa,\u00a0tom,\u00a0and\u00a0bob.\u00a0Set\u00a0their\u00a0passwords to Temp1234. Make lisa and bob accounts to expire on\u00a0December\u00a031,\u00a02021.\u00a0</p> </li> <li> <p>Create\u00a0a\u00a0group\u00a0called\u00a0devs\u00a0and\u00a0add\u00a0tom\u00a0and\u00a0bob\u00a0as\u00a0secondary\u00a0members.\u00a0(Exercise\u00a06</p> </li> <li> <p>Create\u00a0a\u00a0user\u00a0account\u00a0called\u00a0ashley\u00a0with\u00a0UID\u00a02929.\u00a0Set\u00a0the\u00a0password\u00a0to\u00a0user1234.\u00a0(Exercise\u00a05-2).\u00a0\u00a0</p> </li> <li> <p>Create\u00a0a\u00a0directory\u00a0called\u00a0dir1\u00a0under\u00a0/var/tmp\u00a0with\u00a0ownership\u00a0and\u00a0owning group set to root. Configure default ACLs on the directory and give lisa\u00a0read,\u00a0write,\u00a0and\u00a0execute\u00a0permissions.\u00a0(Exercise\u00a04-8).\u00a0\u00a0</p> </li> <li> <p>Create\u00a0a\u00a0logical\u00a0volume\u00a0called\u00a0lvol1\u00a0of\u00a0size\u00a0280MB\u00a0in\u00a0vgtest\u00a0volume\u00a0group.\u00a0Mount\u00a0the\u00a0ext4\u00a0file\u00a0system\u00a0persistently\u00a0to\u00a0/mnt/mnt1.\u00a0</p> </li> <li> <p>Change\u00a0group\u00a0membership\u00a0on\u00a0/mnt/mnt1\u00a0to\u00a0devs.\u00a0Set\u00a0read/write/\u00a0execute permissions on /mnt/mnt1 for group members, and revoke all permissions\u00a0for\u00a0public.\u00a0</p> </li> <li> <p>Create\u00a0a\u00a0logical\u00a0volume\u00a0called\u00a0lvswap\u00a0of\u00a0size\u00a0280MB\u00a0in\u00a0vgtest\u00a0volume\u00a0group. Initialize the logical volume for swap use. Use the UUID and place an\u00a0entry\u00a0for\u00a0persistence.</p> </li> <li> <p>Use\u00a0the\u00a0combination\u00a0of\u00a0tar\u00a0and\u00a0bzip2\u00a0commands\u00a0to\u00a0create\u00a0a\u00a0compressed archive of the /usr/lib directory. Store the archive under /var/tmp as\u00a0usr.tar.bz2.\u00a0</p> </li> <li> <p>Create\u00a0a\u00a0directory\u00a0hierarchy\u00a0/dir1/dir2/dir3/dir4\u00a0and\u00a0apply\u00a0SELinux\u00a0contexts\u00a0of\u00a0/etc\u00a0on\u00a0it\u00a0recursively.\u00a0(Chapter\u00a003,\u00a0topic:</p> </li> <li> <p>Task\u00a018:\u00a0Enable\u00a0access\u00a0to\u00a0the\u00a0atd\u00a0service\u00a0for\u00a0tom\u00a0and\u00a0deny\u00a0for\u00a0bob.\u00a0(Chapter\u00a008,\u00a0topic:\u00a0Controlling\u00a0User\u00a0Access).\u00a0\u00a0     /etc/at.deny     /etc/cron.deny</p> </li> <li> <p>Allow\u00a0tom\u00a0to\u00a0use\u00a0sudo\u00a0without\u00a0being\u00a0prompted\u00a0for\u00a0their\u00a0password.\u00a0(Chapter\u00a006,\u00a0topic:\u00a0Doing\u00a0as\u00a0Superuser\u00a0(or\u00a0Doing\u00a0as\u00a0Substitute\u00a0User)).\u00a0\u00a0</p> </li> <li> <p>Write\u00a0a\u00a0bash\u00a0shell\u00a0script\u00a0to\u00a0create\u00a0three\u00a0user\u00a0accounts\u2014user555,\u00a0user666, and user777\u2014with no login shell and passwords matching their user-\u00a0names. The script should also extract the three usernames from the /etc/\u00a0passwd\u00a0file\u00a0and\u00a0redirect\u00a0them\u00a0into\u00a0/var/tmp/newusers.\u00a0(Chapter\u00a022:\u00a0Script12\u00a0and\u00a0Chapter\u00a007,\u00a0topics:\u00a0Regular\u00a0Expressions,\u00a0and\u00a0Input,\u00a0Output,\u00a0and\u00a0Error\u00a0Redirections).\u00a0\u00a0</p> </li> <li> <p>Launch\u00a0a\u00a0simple\u00a0container\u00a0as\u00a0tom\u00a0using\u00a0the\u00a0latest\u00a0version\u00a0of\u00a0ubi7\u00a0image. Configure the container to auto-start at system reboots without the\u00a0need\u00a0for\u00a0tom\u00a0to\u00a0log\u00a0in.\u00a0(Exercise\u00a023-10).\u00a0\u00a0</p> </li> <li> <p>Launch\u00a0another\u00a0container\u00a0as\u00a0tom\u00a0using\u00a0the\u00a0latest\u00a0version\u00a0of\u00a0ubi8\u00a0image with two environment variables SHELL and HOSTNAME. Configure the\u00a0container to auto-start via systemd without the need for tom to log in.</p> </li> </ol>"},{"location":"Linux/RHCSA/Asghar%20Ghori/Exam%202/","title":"Exam 2","text":"<p>Task\u00a001:\u00a0Using\u00a0the\u00a0nmcli\u00a0command,\u00a0configure\u00a0a\u00a0network\u00a0connection\u00a0on\u00a0the\u00a0primary network device with IP address 192.168.0.242/24, gateway 192.168.0.1,\u00a0and nameserver 192.168.0.1.  Use different IP assignments based on your lab\u00a0environment.\u00a0(Exercise\u00a016-</p> <p>Task\u00a002:\u00a0Using\u00a0the\u00a0hostnamectl\u00a0command,\u00a0set\u00a0the\u00a0system\u00a0hostname\u00a0to\u00a0rhcsa2.example.com\u00a0and\u00a0alias\u00a0rhcsa2.\u00a0Make\u00a0sure\u00a0that\u00a0the\u00a0new\u00a0hostname\u00a0is\u00a0reflected\u00a0in\u00a0the\u00a0command\u00a0prompt.\u00a0(Exercises\u00a016-1\u00a0and\u00a016-5).\u00a0\u00a0</p> <p>Task\u00a003:\u00a0Create\u00a0a\u00a0user\u00a0account\u00a0called\u00a0bob\u00a0with\u00a0UID\u00a07000\u00a0and\u00a0comments\u00a0\u201cI\u00a0am bob\u201d. Set the maximum allowable inactivity for this user to 30 days.\u00a0(Exercises\u00a05-2,\u00a0and\u00a06-1\u00a0or\u00a06-2).\u00a0</p> <p>Task\u00a004:\u00a0Create\u00a0a\u00a0user\u00a0account\u00a0called\u00a0tedd\u00a0with\u00a0a\u00a0non-interactive\u00a0shell.\u00a0(Exercise\u00a05-4).\u00a0</p> <p>Task\u00a005:\u00a0Create\u00a0a\u00a0file\u00a0called\u00a0testfile1\u00a0under\u00a0/var/tmp\u00a0with\u00a0ownership\u00a0and\u00a0owning group set to root. Configure access ACLs on the file and give lisa read\u00a0and write access. Test access by logging in as lisa and editing the file.\u00a0(Chapter\u00a003,\u00a0topic:\u00a0Creating\u00a0Files\u00a0and\u00a0Directories,\u00a0and\u00a0Exercise\u00a04-7).\u00a0\u00a0</p> <p>Task\u00a007:\u00a0Create\u00a0a\u00a0logical\u00a0volume\u00a0called\u00a0lv1\u00a0of\u00a0size\u00a0equal\u00a0to\u00a010\u00a0LEs\u00a0in\u00a0vg1 volume group (create vg1 with PE size 8MB in a partition on the 400MB disk).\u00a0Initialize the logical volume with XFS type and mount it on /mnt/lvfs1. Create a\u00a0file called lv1file1 in the mount point. Set the file system to automatically\u00a0mount\u00a0at\u00a0each\u00a0system\u00a0reboot.\u00a0</p> <p>Task\u00a008:\u00a0Add\u00a0a\u00a0group\u00a0called\u00a0sres\u00a0and\u00a0change\u00a0group\u00a0membership\u00a0on\u00a0/mnt/\u00a0lvfs1 to sres. Set read/write/execute permissions on /mnt/lvfs1 for the\u00a0owner,\u00a0group\u00a0members,\u00a0and\u00a0others.\u00a0</p> <p>Task\u00a009:\u00a0Extend\u00a0the\u00a0file\u00a0system\u00a0in\u00a0the\u00a0logical\u00a0volume\u00a0lv1\u00a0by\u00a064MB\u00a0without\u00a0un-\u00a0mounting it and without losing any data. Confirm the new size for the logical\u00a0volume\u00a0and\u00a0the\u00a0file\u00a0system.\u00a0(Exercise\u00a015-4).\u00a0\u00a0</p> <p>Task\u00a010:\u00a0Create\u00a0a\u00a0swap\u00a0partition\u00a0of\u00a0size\u00a085MB\u00a0on\u00a0the\u00a0400MB\u00a0disk.\u00a0Use\u00a0its\u00a0UUID\u00a0and\u00a0ensure\u00a0it\u00a0is\u00a0activated\u00a0after\u00a0every\u00a0system\u00a0reboot.\u00a0(Exercise\u00a015-6).\u00a0\u00a0</p> <p>Task\u00a011:\u00a0Create\u00a0a\u00a0disk\u00a0partition\u00a0of\u00a0size\u00a0100MB\u00a0on\u00a0the\u00a0400MB\u00a0disk\u00a0and\u00a0format\u00a0it\u00a0with Ext4 file system structures. Assign label stdlabel to the file system. Mount\u00a0the file system on /mnt/stdfs1 persistently using the label. Create file stdfile1 in\u00a0the\u00a0mount\u00a0point.\u00a0(Exercise\u00a013-2\u00a0or\u00a013-4,\u00a0Chapter\u00a015,\u00a0topic:\u00a0Labeling\u00a0a\u00a0File\u00a0Sys-\u00a0tem,\u00a0and\u00a0Exercise\u00a015-1).\u00a0</p> <p>Task\u00a012:\u00a0Use\u00a0the\u00a0tar\u00a0and\u00a0gzip\u00a0command\u00a0combination\u00a0to\u00a0create\u00a0a\u00a0compressed\u00a0archive of the /etc directory. Store the archive under /var/tmp using a filename\u00a0of\u00a0your\u00a0choice.\u00a0(Exercise\u00a03-1).\u00a0\u00a0</p> <p>Task\u00a013:\u00a0Create\u00a0a\u00a0directory\u00a0/direct01\u00a0and\u00a0apply\u00a0SELinux\u00a0contexts\u00a0for\u00a0/root\u00a0to\u00a0it.\u00a0(Exercise\u00a021-2).\u00a0\u00a0</p> <p>Task\u00a014:\u00a0Set\u00a0up\u00a0a\u00a0cron\u00a0job\u00a0for\u00a0bob\u00a0to\u00a0search\u00a0for\u00a0files\u00a0by\u00a0the\u00a0name\u00a0\u201ccore\u201d\u00a0in\u00a0the /var directory and copy them to the directory <code>/var/tmp/coredir1</code>. This job\u00a0should\u00a0run\u00a0every\u00a0Monday\u00a0at\u00a01:20\u00a0a.m.\u00a0(Chapter\u00a004,\u00a0topics:\u00a0Using\u00a0the\u00a0find\u00a0Command,\u00a0and\u00a0Using\u00a0find\u00a0with\u00a0-exec\u00a0and\u00a0-ok\u00a0Flags,\u00a0and\u00a0Exercise\u00a08-4).\u00a0\u00a0</p> <p>Task\u00a015:\u00a0Search\u00a0for\u00a0all\u00a0files\u00a0in\u00a0the\u00a0entire\u00a0directory\u00a0structure\u00a0that\u00a0have\u00a0been\u00a0modified in the past 30 days and save the file listing in the /var/tmp/\u00a0mod-files.txt\u00a0file.\u00a0(Chapter\u00a004,\u00a0topics:\u00a0Using\u00a0the\u00a0find\u00a0Command\u00a0and\u00a0Using\u00a0find\u00a0with -exec and -ok Flags).\u00a0\u00a0</p> <p>Task\u00a016:\u00a0Modify\u00a0the\u00a0bootloader\u00a0program\u00a0and\u00a0set\u00a0the\u00a0default\u00a0autoboot\u00a0timer\u00a0value\u00a0to\u00a02\u00a0seconds.\u00a0(Exercise\u00a011-1).\u00a0\u00a0</p> <p>Task\u00a017:\u00a0Determine\u00a0the\u00a0recommended\u00a0tuning\u00a0profile\u00a0for\u00a0the\u00a0system\u00a0and\u00a0apply\u00a0it.\u00a0(Exercise\u00a012-2).\u00a0\u00a0</p> <p>Task\u00a018:\u00a0Configure\u00a0Chrony\u00a0to\u00a0synchronize\u00a0system\u00a0time\u00a0with\u00a0the\u00a0hardware\u00a0clock.\u00a0Remove\u00a0all\u00a0other\u00a0NTP\u00a0sources.\u00a0(Exercise\u00a018-1).\u00a0\u00a0</p> <p>Task\u00a019:\u00a0Install\u00a0package\u00a0group\u00a0called\u00a0\u201cDevelopment\u00a0Tools\u201d\u00a0and\u00a0capture\u00a0its\u00a0information\u00a0in\u00a0/var/tmp/systemtools.out\u00a0file.\u00a0(Chapter\u00a003,\u00a0topic:\u00a0Regular\u00a0Ex-\u00a0pressions,\u00a0and\u00a0Exercise\u00a010-3).\u00a0</p> <p>Task\u00a020:\u00a0Lock\u00a0user\u00a0account\u00a0bob.\u00a0Use\u00a0regular\u00a0expressions\u00a0to\u00a0capture\u00a0the\u00a0line\u00a0that\u00a0shows\u00a0the\u00a0lock\u00a0and\u00a0store\u00a0the\u00a0output\u00a0in\u00a0file\u00a0/var/tmp/bob.lock.\u00a0(Chapter\u00a003,\u00a0topic:\u00a0Regular\u00a0Expressions,\u00a0and\u00a0Exercise\u00a06-3).\u00a0</p> <p>Task\u00a021:\u00a0Write\u00a0a\u00a0bash\u00a0shell\u00a0script\u00a0so\u00a0that\u00a0it\u00a0prints\u00a0RHCSA\u00a0when\u00a0RHCE\u00a0is\u00a0passed as an argument, and vice versa. If no argument is provided, the script\u00a0should\u00a0print\u00a0a\u00a0usage\u00a0message\u00a0and\u00a0quit\u00a0with\u00a0exit\u00a0value\u00a05.\u00a0(Chapter\u00a022:\u00a0Script10).\u00a0\u00a0</p> <p>Task\u00a022:\u00a0Launch\u00a0a\u00a0root\u00a0container\u00a0and\u00a0configure\u00a0it\u00a0to\u00a0auto-start\u00a0via\u00a0systemd.\u00a0(Exercise\u00a023-9).\u00a0\u00a0</p> <p>Task\u00a023:\u00a0Launch\u00a0a\u00a0container\u00a0as\u00a0user80\u00a0with\u00a0/data01\u00a0mapped\u00a0to\u00a0/data01\u00a0using\u00a0the latest version of the ubi8 image. Configure a systemd service to auto-start\u00a0the container on system reboots without the need for user80 to log in. Create\u00a0files\u00a0under\u00a0the\u00a0shared\u00a0mount\u00a0point\u00a0and\u00a0validate\u00a0data\u00a0persistence.\u00a0(Exercise\u00a023-7\u00a0and\u00a023-10).</p>"},{"location":"Linux/RHCSA/Asghar%20Ghori/Exam%203/","title":"Exam 3","text":"<p>Task\u00a002:\u00a0On\u00a0server1,\u00a0configure\u00a0a\u00a0network\u00a0connection\u00a0on\u00a0the\u00a0primary\u00a0network\u00a0device with IP address 192.168.0.243/24, gateway 192.168.0.1, and nameserver\u00a0192.168.0.1 using the nmcli command (use different IP assignments based on\u00a0your\u00a0lab\u00a0environment).\u00a0(Exercise\u00a016-4).\u00a0</p> <p>Task\u00a003:\u00a0On\u00a0VM2,\u00a0set\u00a0the\u00a0system\u00a0hostname\u00a0to\u00a0server2.example.com\u00a0and\u00a0alias\u00a0server2 using a manual method (modify file by hand). Make sure that the new\u00a0hostname\u00a0is\u00a0reflected\u00a0in\u00a0the\u00a0command\u00a0prompt.\u00a0(Exercises\u00a016-1\u00a0and\u00a016-5).\u00a0\u00a0</p> <p>Task\u00a004:\u00a0On\u00a0server2,\u00a0configure\u00a0a\u00a0network\u00a0connection\u00a0on\u00a0the\u00a0primary\u00a0network\u00a0device with IP address 192.168.0.244/24, gateway 192.168.0.1, and nameserver\u00a0192.168.0.1 using a manual method (create/modify file by hand). Use different\u00a0IP\u00a0assignments\u00a0based\u00a0on\u00a0your\u00a0lab\u00a0environment.\u00a0(Exercise\u00a016-3).\u00a0\u00a0</p> <p>Task\u00a005:\u00a0Run\u00a0\u201cping\u00a0-c2\u00a0server2\u201d\u00a0on\u00a0server1.\u00a0Run\u00a0\u201cping\u00a0-c2\u00a0server1\u201d\u00a0on\u00a0server2.\u00a0You\u00a0should\u00a0see\u00a00%\u00a0loss\u00a0in\u00a0both\u00a0outputs.\u00a0(Exercise\u00a016-5).\u00a0\u00a0</p> <p>Task\u00a006:\u00a0On\u00a0server1\u00a0and\u00a0server2,\u00a0attach\u00a0the\u00a0RHEL\u00a08\u00a0ISO\u00a0image\u00a0to\u00a0the\u00a0VM\u00a0and\u00a0mount it persistently to /mnt/sr0. Define access to both repositories and con-\u00a0firm.\u00a0(Exercise\u00a010-1).</p> <p>Task\u00a007:\u00a0On\u00a0server1,\u00a0add\u00a0HTTP\u00a0port\u00a08300/tcp\u00a0to\u00a0the\u00a0SELinux\u00a0policy\u00a0database\u00a0persistently.\u00a0(Exercise\u00a021-3).\u00a0</p> <p>Task\u00a010:\u00a0Configure\u00a0NFS\u00a0service\u00a0on\u00a0server2\u00a0and\u00a0share\u00a0the\u00a0home\u00a0directory\u00a0for\u00a0user60 (create user60 on both systems) with server1. Configure AutoFS indirect map on server1 to automatically mount the home directory under  /nfsdir\u00a0when\u00a0user60\u00a0logs\u00a0on\u00a0to\u00a0server1.\u00a0(Exercises\u00a05-1,\u00a017-1,\u00a017-4,\u00a0and\u00a017-5).\u00a0\u00a0</p> <p>Task\u00a013:\u00a0On\u00a0server1,\u00a0create\u00a0a\u00a0group\u00a0called\u00a0group30\u00a0with\u00a0GID\u00a03000,\u00a0and\u00a0add\u00a0user60 and user80 to this group. Create a directory called /sdata, enable setgid\u00a0bit on it, and add write permission bit for group members. Set ownership and\u00a0owning group to root and group30. Create a file called file1 under /sdata as\u00a0user60\u00a0and\u00a0modify\u00a0the\u00a0file\u00a0as\u00a0user80\u00a0successfully.\u00a0(Exercises\u00a04-5,\u00a06-4,\u00a0and\u00a06-6).\u00a0\u00a0</p> <p>Task\u00a014:\u00a0On\u00a0server1,\u00a0create\u00a0directory\u00a0/var/dir1\u00a0with\u00a0full\u00a0permissions\u00a0for\u00a0every-\u00a0one. Disallow non-owners to remove files. Test by creating file\u00a0/var/dir1/stkfile1\u00a0as\u00a0user60\u00a0and\u00a0removing\u00a0it\u00a0as\u00a0user80.\u00a0(Exercise\u00a04-6).\u00a0\u00a0</p> <p>Task\u00a015:\u00a0On\u00a0server1,\u00a0search\u00a0for\u00a0all\u00a0manual\u00a0pages\u00a0for\u00a0the\u00a0description\u00a0containing\u00a0the keyword \u201cpassword\u201d and redirect the output to file /var/tmp/man.out.\u00a0(Chapter\u00a002,\u00a0topic\u00a0Searching\u00a0by\u00a0Keyword,\u00a0and\u00a0Chapter\u00a007,\u00a0topic:\u00a0Input,\u00a0Out-\u00a0put, and Error Redirections).\u00a0\u00a0Task\u00a016:\u00a0On\u00a0server1,\u00a0create\u00a0file\u00a0lnfile1\u00a0under\u00a0/var/tmp\u00a0and\u00a0create\u00a0one\u00a0hard\u00a0link\u00a0/var/tmp/lnfile2 and one soft link /boot/file1. Edit lnfile1 using one link at a\u00a0time and confirm. (Exercises 3-2 and 3-3).\u00a0\u00a0Task\u00a017:\u00a0On\u00a0server1,\u00a0install\u00a0module\u00a0postgresql\u00a0version\u00a09.6\u00a0(select\u00a0a\u00a0different\u00a0non-default\u00a0version\u00a0if\u00a09.6\u00a0is\u00a0not\u00a0available).\u00a0(Exercise\u00a010-5).\u00a0Task\u00a018:\u00a0On\u00a0server1,\u00a0add\u00a0the\u00a0http\u00a0service\u00a0to\u00a0the\u00a0\u201cexternal\u201d\u00a0firewalld\u00a0zone\u00a0persis-\u00a0tently.\u00a0(Exercise\u00a0201).\u00a0\u00a0Task\u00a019:\u00a0On\u00a0server1,\u00a0set\u00a0SELinux\u00a0type\u00a0shadow_t\u00a0on\u00a0a\u00a0new\u00a0file\u00a0testfile1\u00a0in\u00a0/usr\u00a0and\u00a0ensure\u00a0that\u00a0the\u00a0context\u00a0is\u00a0not\u00a0affected\u00a0by\u00a0a\u00a0SELinux\u00a0relabeling.\u00a0(Exercises\u00a021-1\u00a0and\u00a021-2).\u00a0\u00a0Task\u00a020:\u00a0Configure\u00a0password-less\u00a0ssh\u00a0access\u00a0for\u00a0user60\u00a0from\u00a0server1\u00a0to\u00a0rhc-\u00a0sa4.\u00a0(Exercise\u00a019-2).\u00a0\u00a0Task\u00a021:\u00a0Write\u00a0a\u00a0bash\u00a0shell\u00a0script\u00a0that\u00a0checks\u00a0for\u00a0the\u00a0existence\u00a0of\u00a0files\u00a0(not\u00a0directories) under the /usr/bin directory that begin with the letters \u201cac\u201d and\u00a0display\u00a0their\u00a0statistics\u00a0(the\u00a0stat\u00a0command).\u00a0(Chapter\u00a022:\u00a0Table\u00a022-1\u00a0and\u00a0Scrip-\u00a0t07).\u00a0\u00a0Task\u00a022:\u00a0On\u00a0server1,\u00a0launch\u00a0a\u00a0named\u00a0container\u00a0as\u00a0user60\u00a0with\u00a0host\u00a0port\u00a010000\u00a0mapped to container port 80. Employ the latest version of the ubi7 image.\u00a0Configure a systemd service to auto-start the container without the need for\u00a0user60 to log in. Validate port mapping using an appropriate podman subcom-\u00a0mand.\u00a0(Exercises\u00a023-5\u00a0and\u00a023-10).</p> <p>Task\u00a023:\u00a0On\u00a0server1,\u00a0launch\u00a0another\u00a0named\u00a0container\u00a0as\u00a0user60\u00a0with\u00a0/host_-\u00a0data01 mapped to /container_data01, one variable ENVIRON=Exam, and host\u00a0port 1050 mapped to container port 1050. Use the latest version of the ubi8\u00a0image. Configure a separate systemd service to auto-start the container without\u00a0the need for user60 to log in. Create a file under the shared directory and validate data persistence. Verify port mapping and variable settings using appropriate\u00a0podman\u00a0subcommands.\u00a0(Exercises\u00a023-5,\u00a023-7,\u00a023-8,\u00a0and\u00a023-10).</p>"},{"location":"Linux/RHCSA/Asghar%20Ghori/Exam%204/","title":"Exam 4","text":"<p>Task\u00a001:\u00a0On\u00a0VM1,\u00a0set\u00a0the\u00a0system\u00a0hostname\u00a0to\u00a0rhcsa5.example.com\u00a0and\u00a0alias\u00a0rhcsa5 using the hostnamectl command. Make sure that the new hostname is\u00a0reflected\u00a0in\u00a0the\u00a0command\u00a0prompt.\u00a0(Exercises\u00a016-1\u00a0and\u00a016-5).</p> <p>Task\u00a002:\u00a0On\u00a0rhcsa5,\u00a0configure\u00a0a\u00a0network\u00a0connection\u00a0on\u00a0the\u00a0primary\u00a0network\u00a0device with IP address 192.168.0.245/24, gateway 192.168.0.1, and nameserver\u00a0192.168.0.1 using the nmcli command. Use different IP assignments based on\u00a0your\u00a0lab\u00a0environment.\u00a0(Exercise\u00a016-4).\u00a0</p> <p>Task\u00a003:\u00a0On\u00a0VM2,\u00a0set\u00a0the\u00a0system\u00a0hostname\u00a0to\u00a0rhcsa6.example.com\u00a0and\u00a0alias\u00a0rhcsa6 using a manual method (modify file by hand). Make sure that the new\u00a0hostname\u00a0is\u00a0reflected\u00a0in\u00a0the\u00a0command\u00a0prompt.\u00a0(Exercises\u00a016-1\u00a0and\u00a016-5).\u00a0\u00a0</p> <p>Task\u00a004:\u00a0On\u00a0rhcsa6,\u00a0configure\u00a0a\u00a0network\u00a0connection\u00a0on\u00a0the\u00a0primary\u00a0network\u00a0device with IP address 192.168.0.246/24, gateway 192.168.0.1, and nameserver\u00a0192.168.0.1 using a manual method (create/modify files by hand). Use different\u00a0IP\u00a0assignments\u00a0based\u00a0on\u00a0your\u00a0lab\u00a0environment.\u00a0(Exercise\u00a016-3).\u00a0\u00a0Task\u00a005:\u00a0Run\u00a0\u201cping\u00a0-c2\u00a0rhcsa6\u201d\u00a0on\u00a0rhcsa5.\u00a0Run\u00a0\u201cping\u00a0-c2\u00a0rhcsa5\u201d\u00a0on\u00a0rhcsa6.\u00a0You\u00a0should\u00a0see\u00a00%\u00a0loss\u00a0in\u00a0both\u00a0outputs.\u00a0(Exercise\u00a016-5).\u00a0\u00a0</p> <p>Task\u00a007:\u00a0Export\u00a0/share5\u00a0on\u00a0rhcsa5\u00a0and\u00a0mount\u00a0it\u00a0to\u00a0/share6\u00a0persistently\u00a0on\u00a0rhcsa6.\u00a0(Exercises\u00a017-1\u00a0and\u00a017-</p> <p>2).\u00a0\u00a0Task\u00a008:\u00a0Use\u00a0NFS\u00a0to\u00a0export\u00a0home\u00a0directories\u00a0for\u00a0all\u00a0users\u00a0(u1,\u00a0u2,\u00a0and\u00a0u3)\u00a0on\u00a0rhcsa6 so that their home directories become available under /home1 when\u00a0they\u00a0log\u00a0on\u00a0to\u00a0rhcsa5.\u00a0Create\u00a0u1,\u00a0u2,\u00a0and\u00a0u3.\u00a0(Exercises\u00a017-1\u00a0and\u00a017-</p> <p>Task\u00a009:\u00a0On\u00a0rhcsa5,\u00a0add\u00a0HTTP\u00a0port\u00a08400/udp\u00a0to\u00a0tman he\u00a0public\u00a0zone\u00a0persistently.</p> <p>Task\u00a010:\u00a0Configure\u00a0password less\u00a0ssh\u00a0access\u00a0for\u00a0u1\u00a0from\u00a0rhcsa5\u00a0to\u00a0rhcsa6.\u00a0Copy the directory /etc/sysconfig from rhcsa5 to rhcsa6 under /var/tmp/\u00a0remote\u00a0securely.</p> <p>Task\u00a012:\u00a0On\u00a0rhcsa6,\u00a0install\u00a0module\u00a0\u201ccontainer-tools\u201d\u00a0stream\u00a0rhel8.\u00a0(Exercise\u00a010-5).\u00a0\u00a0</p> <p>Task\u00a014:\u00a0On\u00a0rhcsa5\u00a0and\u00a0rhcsa6,\u00a0set\u00a0the\u00a0tuning\u00a0profile\u00a0to\u00a0powersave.\u00a0(Exercise\u00a012-2).\u00a0\u00a0</p> <p>Task\u00a015:\u00a0On\u00a0rhcsa5,\u00a0create\u00a0file\u00a0lnfile1\u00a0under\u00a0/var/tmp\u00a0and\u00a0create\u00a0three\u00a0hard\u00a0links\u00a0called hard1, hard2, and hard3 for it. Identify the inode number associated with\u00a0all four files. Edit any of the files and observe the metadata for all the files for\u00a0confirmation.\u00a0(Exercise\u00a03-2).\u00a0\u00a0</p> <p>Task\u00a016:\u00a0On\u00a0rhcsa5,\u00a0members\u00a0(user100\u00a0and\u00a0user200)\u00a0of\u00a0group100\u00a0should\u00a0be\u00a0able to collaborate on files under /shared but cannot delete each other\u2019s files.\u00a0(Exercises\u00a04-5\u00a0and\u00a04-</p> <p>Task\u00a017:\u00a0Synchronize\u00a0the\u00a0entire\u00a0/etc\u00a0directory\u00a0on\u00a0rhcsa5\u00a0to\u00a0/var/tmp/etc\u00a0on\u00a0rhc-\u00a0sa6. Use in-transit compression. Capture the output and any errors in the /var/\u00a0tmp/etc.transfer\u00a0file\u00a0on\u00a0rhcsa5\u00a0during\u00a0the\u00a0synchronization\u00a0process.\u00a0(Chapter\u00a019,\u00a0topic:\u00a0Synchronizing\u00a0Files\u00a0Remotely\u00a0Using\u00a0rsync,\u00a0and\u00a0Chapter\u00a007,\u00a0topic:\u00a0Regular Expressions).\u00a0\u00a0</p> <p>Task\u00a018:\u00a0On\u00a0rhcsa6,\u00a0list\u00a0all\u00a0files\u00a0that\u00a0are\u00a0part\u00a0of\u00a0the\u00a0\u201csetup\u201d\u00a0package,\u00a0and\u00a0use\u00a0regular expressions and I/O redirection to send the output lines containing\u00a0\u201chosts\u201d\u00a0to\u00a0/var/tmp/setup.pkg.\u00a0(Exercise\u00a09-2,\u00a0and\u00a0Chapter\u00a007,\u00a0topics:\u00a0Regular\u00a0Expressions, and Input, Output, and Error Redirections).\u00a0\u00a0</p> <p>Task\u00a020:\u00a0On\u00a0rhcsa5,\u00a0configure\u00a0journald\u00a0to\u00a0store\u00a0messages\u00a0permanently\u00a0under\u00a0/var/log/journal and fall back to memory-only option if /var/log/journal direc-\u00a0tory\u00a0does\u00a0not\u00a0exist\u00a0or\u00a0has\u00a0permission/access\u00a0issues.\u00a0(Exercise\u00a012-1).\u00a0\u00a0</p> <p>Task\u00a021:\u00a0Write\u00a0a\u00a0bash\u00a0shell\u00a0script\u00a0that\u00a0defines\u00a0an\u00a0environment\u00a0variable\u00a0called\u00a0ENV1=book1 and creates a user account that matches the value of the variable.\u00a0(Chapter\u00a022:\u00a0Script02\u00a0and\u00a0Script03).\u00a0\u00a0</p> <p>Task\u00a022:\u00a0On\u00a0rhcsa5,\u00a0launch\u00a0a\u00a0named\u00a0root\u00a0container\u00a0with\u00a0host\u00a0port\u00a0443\u00a0mapped\u00a0to container port 443. Employ the latest version of the ubi7 image. Configure a\u00a0systemd service to auto-start the container at system reboots. Validate port\u00a0mapping\u00a0using\u00a0an\u00a0appropriate\u00a0podman\u00a0subcommand.\u00a0(Exercises\u00a023-5\u00a0and </p> <p>Task\u00a023:\u00a0On\u00a0rhcsa5,\u00a0launch\u00a0a\u00a0named\u00a0container\u00a0as\u00a0user100\u00a0with\u00a0/data01\u00a0mapped to /data01 and two variables KERN=$(uname -r) and SHELL defined.\u00a0 - Use the latest version of the ubi8 image. - Configure a systemd service to auto-\u00a0start the container at system reboots without the need for user100 to log in.\u00a0 - Create a file under the shared mount point and validate data persistence. Verify\u00a0port\u00a0mapping\u00a0using\u00a0an\u00a0appropriate\u00a0podman\u00a0subcommand.\u00a0(Exercises\u00a023-7,\u00a023-8,\u00a0and\u00a023-10).</p>"},{"location":"Linux/RHCSA/Objectives/1-Understand-And-User-Essential-Tools/1-Access%20a%20shell%20prompt%20and%20issue%20commands%20with%20correct%20syntax/","title":"1 Access a shell prompt and issue commands with correct syntax","text":"<p>[!TIP] A nondescript requirement, requires no discussion/notes. </p>"},{"location":"Linux/RHCSA/Objectives/1-Understand-And-User-Essential-Tools/10-Locate%2C%20read%2C%20and%20use%20system%20documentation%20including%20man%2C%20info%2C%20and%20files/","title":"10 Locate, read, and use system documentation including man, info, and files","text":""},{"location":"Linux/RHCSA/Objectives/1-Understand-And-User-Essential-Tools/10-Locate%2C%20read%2C%20and%20use%20system%20documentation%20including%20man%2C%20info%2C%20and%20files/#man","title":"man","text":"<p>The most helpful parts of a man page are at the bottom. You will find actual examples, and the See Also section. </p> <p>Use <code>man -k</code> to search the mandb. To update the mandb, just type ``mandb</p> <p>Man pages are categorized in different sections. - 1: Executable programs or shell commands - 5: File formats and conventions - 8: System Admin Commands</p>"},{"location":"Linux/RHCSA/Objectives/1-Understand-And-User-Essential-Tools/10-Locate%2C%20read%2C%20and%20use%20system%20documentation%20including%20man%2C%20info%2C%20and%20files/#locate","title":"Locate","text":"<p>If you're going to use this, make sure you have a cron job set up to update the database manually</p>"},{"location":"Linux/RHCSA/Objectives/1-Understand-And-User-Essential-Tools/10-Locate%2C%20read%2C%20and%20use%20system%20documentation%20including%20man%2C%20info%2C%20and%20files/#find","title":"Find","text":"<p>Search for a file named\u00a0<code>document.pdf</code>\u00a0in the\u00a0<code>/home/linuxize</code>\u00a0directory     - find /home/linuxize -type f -name document.pdf</p> <p>The <code>exec</code> option lets us run commands on whatever file we just found. Search for a file named\u00a0<code>document.pdf</code>\u00a0in the\u00a0<code>/home/linuxize</code>\u00a0directory, and then change its permissions.      - find /home/linuxize -type f -name document.pdf -exec chmod 0755 {} \\;</p> <p>The <code>{}</code> is the results placeholder, and the <code>;</code> is the delimiter. The <code>\\</code> is just used to escape it</p>"},{"location":"Linux/RHCSA/Objectives/1-Understand-And-User-Essential-Tools/2-Use%20input-output%20redirection%20%28%3E%2C%20%3E%3E%2C%20%7C%2C%202%3E%2C%20etc.%29/","title":"2 Use input output redirection (>, >>, |, 2>, etc.)","text":"<ul> <li> <p>(same as 1&gt;) - Redirects STDOUT. If redirection is to a file, the current contents of <code># ls -al /tmp &gt; /root/output.log</code></p> </li> <li> <p>(same as 1&gt;&gt;) - Redirects STDOUT. If output is written to a file, the output is <code># ls -al /usr &gt;&gt; /root/output.log</code></p> </li> <li>2&gt; - Redirects STDERR <code>somerandomcommand 2&gt;error.txt</code></li> <li>2&gt;&amp;1 - Redirects STDERR to the same destination as STDOUT. Notice that this has to be used in combination with normal output redirection, <code>ls whuhiu &gt; errout 2&gt;&amp;1</code>.</li> <li>&lt; (same as 0&lt;) - Redirects STDIN.</li> </ul>"},{"location":"Linux/RHCSA/Objectives/1-Understand-And-User-Essential-Tools/3-Use%20grep%20and%20regular%20expressions%20to%20analyze%20text/","title":"3 Use grep and regular expressions to analyze text","text":"<p>Display all lines containing the string bash in /etc/passwd     - grep bash /etc/passwd</p> <p>Display the lines that do NOT contain the string 'nologin'     - grep -v nologin /etc/passwd</p> <p>Search for the string 'linuxize.com' in all files inside the /etc/directory     - grep -r 'linuxize.com' /etc</p> <p>Searh for the string linux at the beginning of the line in file.txt     - grep '^linux' file.txt</p>"},{"location":"Linux/RHCSA/Objectives/1-Understand-And-User-Essential-Tools/5-Log%20in%20and%20switch%20users%20in%20multiuser%20targets/","title":"5 Log in and switch users in multiuser targets","text":""},{"location":"Linux/RHCSA/Objectives/1-Understand-And-User-Essential-Tools/5-Log%20in%20and%20switch%20users%20in%20multiuser%20targets/#how-to-set-multiuser-target","title":"How to Set Multiuser Target","text":"<ol> <li><code>systemctl get-default</code></li> <li> <ol> <li> </li> </ol> </li> <li> <ol> <li> </li> </ol> </li> </ol>"},{"location":"Linux/RHCSA/Objectives/1-Understand-And-User-Essential-Tools/5-Log%20in%20and%20switch%20users%20in%20multiuser%20targets/#systemctl-set-default-multi-user","title":"systemctl set-default multi-user","text":""},{"location":"Linux/RHCSA/Objectives/1-Understand-And-User-Essential-Tools/5-Log%20in%20and%20switch%20users%20in%20multiuser%20targets/#reboot","title":"reboot","text":""},{"location":"Linux/RHCSA/Objectives/1-Understand-And-User-Essential-Tools/6-Archive%2C%20compress%2C%20unpack%2C%20and%20uncompress%20files%20using%20tar%2C%20star%2C%20gzip%2C%20and%20bzip2/","title":"6 Archive, compress, unpack, and uncompress files using tar, star, gzip, and bzip2","text":""},{"location":"Linux/RHCSA/Objectives/1-Understand-And-User-Essential-Tools/6-Archive%2C%20compress%2C%20unpack%2C%20and%20uncompress%20files%20using%20tar%2C%20star%2C%20gzip%2C%20and%20bzip2/#archiving-and-compression","title":"Archiving and Compression","text":"<pre><code>ARCHIVING AND COMPRESSING ARE NOT THE SAME THING\n</code></pre>"},{"location":"Linux/RHCSA/Objectives/1-Understand-And-User-Essential-Tools/6-Archive%2C%20compress%2C%20unpack%2C%20and%20uncompress%20files%20using%20tar%2C%20star%2C%20gzip%2C%20and%20bzip2/#archiving-with-tar","title":"Archiving with Tar","text":""},{"location":"Linux/RHCSA/Objectives/1-Understand-And-User-Essential-Tools/6-Archive%2C%20compress%2C%20unpack%2C%20and%20uncompress%20files%20using%20tar%2C%20star%2C%20gzip%2C%20and%20bzip2/#create","title":"Create","text":"<p>tar -cf <code>{archive}</code> <code>{what you are archiving}</code></p>"},{"location":"Linux/RHCSA/Objectives/1-Understand-And-User-Essential-Tools/6-Archive%2C%20compress%2C%20unpack%2C%20and%20uncompress%20files%20using%20tar%2C%20star%2C%20gzip%2C%20and%20bzip2/#extract","title":"Extract","text":"<p>tar -xf  <code>{archive}</code> <code>{what you are archiving}</code></p> Option Use c Creates an archive. v Shows verbose output while tar is working. t Shows the contents of an archive. z Compresses/decompresses the archive while creating it, by using gzip. j Compresses/decompresses the archive by using bzip2. x Extracts an archive. u Updates an archive; only newer files will be written to the archive. C Changes the working directory before performing the command. r Appends files to an archive."},{"location":"Linux/RHCSA/Objectives/1-Understand-And-User-Essential-Tools/6-Archive%2C%20compress%2C%20unpack%2C%20and%20uncompress%20files%20using%20tar%2C%20star%2C%20gzip%2C%20and%20bzip2/#compression","title":"Compression","text":""},{"location":"Linux/RHCSA/Objectives/1-Understand-And-User-Essential-Tools/6-Archive%2C%20compress%2C%20unpack%2C%20and%20uncompress%20files%20using%20tar%2C%20star%2C%20gzip%2C%20and%20bzip2/#gzip","title":"gzip","text":"<p>gzip <code>filename</code>.    To uncompress, use gunzip</p>"},{"location":"Linux/RHCSA/Objectives/1-Understand-And-User-Essential-Tools/6-Archive%2C%20compress%2C%20unpack%2C%20and%20uncompress%20files%20using%20tar%2C%20star%2C%20gzip%2C%20and%20bzip2/#bzip2","title":"bzip2","text":"<p>bzip <code>filename</code></p>"},{"location":"Linux/RHCSA/Objectives/1-Understand-And-User-Essential-Tools/6-Archive%2C%20compress%2C%20unpack%2C%20and%20uncompress%20files%20using%20tar%2C%20star%2C%20gzip%2C%20and%20bzip2/#lab","title":"Lab","text":"<ol> <li>Log is user root. In the home directory of root, create one archive file that contains the contents of the <code>/home</code> directory and the <code>/etc</code> directory. Use the name <code>/root/essentials.tar</code>for the archive<ol> <li><code>tar -cf essentials.tar /home /etc</code></li> </ol> </li> <li>Copy this archive to the /tmp directory. Also create a hard link to this file in the / directory.<ol> <li><code>cp essentials.tar /tmp</code></li> <li><code>ln /tmp/essentials.tar .</code></li> </ol> </li> <li>Rename the file <code>/essentials.tar</code> to <code>/archive.tar</code>.<ol> <li><code>mv essentials.tar archive.tar</code></li> </ol> </li> <li>Create a symbolic link in the home directory of the user root that refers to  /archive.tar. Use the name link.tar for the symbolic link.<ol> <li><code>ln -s /archive.tar</code></li> </ol> </li> <li>Compress the /root/essentials.tar file.<ol> <li><code>gzip essentials.tar</code></li> </ol> </li> <li>Create a directory structure <code>/tmp/files/pictures</code>, <code>tmp/files/photos</code>, and <code>tmp/files/videos</code><ol> <li><code>mkdir -p /tmp/files/{pictures,photos,videos}</code></li> </ol> </li> <li>Copy all files that have a name starting with a,b,or c from /etc to /tmp/files<ol> <li><code>cd /etc</code></li> <li><code>cp -r [a-c]* /tmp/files/</code></li> </ol> </li> <li>From /tmp/files, move all files that have a name starting with an a, or b to <code>tmp/files/photos</code>, and files starting with a c to <code>tmp/files/videos</code><ol> <li><code>mv [a,b]* photos/</code></li> <li><code>mv c* videos/</code></li> </ol> </li> <li>Find all files in <code>/etc</code> that have a size smaller than 1000 bytes and copy those to <code>tmp/files/pictures</code><ol> <li><code>find /etc -type f -size -1000c -exec cp {} /tmp/files/pictures/  \\;</code></li> </ol> </li> <li>In <code>/tmp/files</code>, create a symbolic link to /var<ol> <li><code>ln -s /tmp/files</code></li> </ol> </li> <li>Create a compressed archive file of the <code>/home directory</code><ol> <li><code>tar -czvf home.tgz /home/</code></li> </ol> </li> <li>Extract this compressed archive with relative file names in <code>/tmp/archive</code><ol> <li><code>tar -xvf home.tar</code></li> </ol> </li> </ol>"},{"location":"Linux/RHCSA/Objectives/1-Understand-And-User-Essential-Tools/7-Create%20and%20Edit%20Text%20Files/","title":"7 Create and Edit Text Files","text":"<p>[!TIP] A nondescript requirement, requires no discussion/notes. </p>"},{"location":"Linux/RHCSA/Objectives/1-Understand-And-User-Essential-Tools/8-Create%2C%20delete%2C%20copy%2C%20and%20move%20files%20and%20directories/","title":"8 Create, delete, copy, and move files and directories","text":"<ul> <li>touch - This creates a file</li> <li>rm - This can delete a file. Use <code>-d</code> to delete a directory. </li> <li>rmdir - Used to delete a directory<ul> <li>If a directory is NOT empty, you'll need to use -f</li> </ul> </li> <li>cp - Used to copy files</li> <li>mv - Used to move/rename files</li> <li>mkdir - Used to create directories. <ul> <li>Use the <code>-p</code> flag to create directories recursively. </li> </ul> </li> </ul>"},{"location":"Linux/RHCSA/Objectives/1-Understand-And-User-Essential-Tools/9-List%20Set%20and%20Change%20Standard%20Permissions/","title":"9 List Set and Change Standard Permissions","text":""},{"location":"Linux/RHCSA/Objectives/1-Understand-And-User-Essential-Tools/9-List%20Set%20and%20Change%20Standard%20Permissions/#understanding-read-write-and-execute","title":"Understanding Read, Write, and Execute","text":"Permission Applied To Files Applied to Directories Read Open a file List contents of directory Write Change contents of a file Create and delete files Execute Run a program file Change to the directory"},{"location":"Linux/RHCSA/Objectives/1-Understand-And-User-Essential-Tools/9-List%20Set%20and%20Change%20Standard%20Permissions/#applying-the-permissions","title":"Applying The Permissions","text":"<p>To apply the above permissions, use <code>chmod</code>. There are two modes for chmod 1. Absolute Mode - Use digits. Not my favorite  2. Relative Mode - Use letters. My favorite \ud83d\ude08</p> Permission Numeric Representation Read 4 Write 2 Execute 1"},{"location":"Linux/RHCSA/Objectives/1-Understand-And-User-Essential-Tools/9-List%20Set%20and%20Change%20Standard%20Permissions/#special-permissions","title":"Special Permissions","text":"Permisison Numeric Value Relative Value On Files On Directories SUID 4 u+s User executes file with permissions of file owner.  A file with\u00a0SUID\u00a0always executes as the user who owns the file, regardless of the user passing the command. n/A SGID 2 g+s User executes file with permissions of group owner. -   If set on a file, it allows the file to be executed as the\u00a0group\u00a0that owns the file (similar to SUID) If set on a directory, any files created in the directory will have their\u00a0group\u00a0ownership set to that of the directory owner Sticky Bit 1 +t n/A Prevents users from deleting files from other users.   Only the owner can delete files"},{"location":"Linux/RHCSA/Objectives/1-Understand-And-User-Essential-Tools/Objectives/","title":"Access a shell prompt and issue commands with correct syntax","text":""},{"location":"Linux/RHCSA/Objectives/1-Understand-And-User-Essential-Tools/Objectives/#use-grep-and-regular-expressions-to-analyze-text","title":"Use grep and regular expressions to analyze text","text":""},{"location":"Linux/RHCSA/Objectives/1-Understand-And-User-Essential-Tools/Objectives/#access-remote-systems-using-ssh","title":"Access remote systems using SSH","text":""},{"location":"Linux/RHCSA/Objectives/1-Understand-And-User-Essential-Tools/Objectives/#log-in-and-switch-users-in-multiuser-targets","title":"Log in and switch users in multiuser targets","text":""},{"location":"Linux/RHCSA/Objectives/1-Understand-And-User-Essential-Tools/Objectives/#archive-compress-unpack-and-uncompress-files-using-tar-star-gzip-and-bzip2","title":"Archive, compress, unpack, and uncompress files using tar, star, gzip, and bzip2","text":""},{"location":"Linux/RHCSA/Objectives/1-Understand-And-User-Essential-Tools/Objectives/#create-and-edit-text-files","title":"Create and edit text files","text":""},{"location":"Linux/RHCSA/Objectives/1-Understand-And-User-Essential-Tools/Objectives/#create-delete-copy-and-move-files-and-directories","title":"Create, delete, copy, and move files and directories","text":""},{"location":"Linux/RHCSA/Objectives/1-Understand-And-User-Essential-Tools/Objectives/#create-hard-and-soft-links","title":"Create hard and soft links","text":""},{"location":"Linux/RHCSA/Objectives/1-Understand-And-User-Essential-Tools/Objectives/#creating-links","title":"Creating Links","text":"Command Explanation ln /etc/hosts . Creates a link to the file /etc/hosts in the current directory ln -s /etc/hosts . Creates a symbolic link to the file /etc/hosts in the current directory ln -s /home /tmp Creates a symbolic link to the directory /home in the directory /tmp # List, set, and change standard ugo/rwx permissions <p>[!TIP] To set the execute permission to directories only, use an uppercase X. The uppercase X ensures that files will not get the execute permission unless the file has already set the execute permission for some of the entities.</p>"},{"location":"Linux/RHCSA/Objectives/1-Understand-And-User-Essential-Tools/Objectives/#locate-read-and-use-system-documentation-including-man-info-and-files-in-usrsharedoc","title":"Locate, read, and use system documentation including man, info, and files in /usr/share/doc","text":""},{"location":"Linux/RHCSA/Objectives/10-Manage-Containers/1-Find%20and%20retrieve%20container%20images%20from%20a%20remote%20registry/","title":"1 Find and retrieve container images from a remote registry","text":"<p>podman search  podman run podman build</p>"},{"location":"Linux/RHCSA/Objectives/10-Manage-Containers/2-Inspect%20container%20images/","title":"2 Inspect container images","text":"<p>podman inspect</p>"},{"location":"Linux/RHCSA/Objectives/10-Manage-Containers/3-Perform%20basic%20container%20management%20such%20as%20running%2C%20starting%2C%20stopping%2C%20and%20listing%20running%20containers/","title":"3 Perform basic container management such as running, starting, stopping, and listing running containers","text":"<p>podman run podman start podman stop</p>"},{"location":"Linux/RHCSA/Objectives/10-Manage-Containers/6-Run%20a%20service%20inside%20a%20container/","title":"6 Run a service inside a container","text":"<p>[!TIP] A nondescript requirement, requires no discussion/notes. </p>"},{"location":"Linux/RHCSA/Objectives/10-Manage-Containers/7-Configure%20a%20container%20to%20start%20automatically%20as%20a%20systemd%20service/","title":"7 Configure a container to start automatically as a systemd service","text":""},{"location":"Linux/RHCSA/Objectives/10-Manage-Containers/7-Configure%20a%20container%20to%20start%20automatically%20as%20a%20systemd%20service/#containers-as-services","title":"Containers As Services","text":"<p>On a standalone platform where containers are running rootless containers, systemd is needed to autostart containers. To automatically start containers in standalone situation, you can create systemd user unit files for rootless containers and manage them with <code>systemctl</code> .</p> <p>In systemd, services are easily started and enabled with root permissions using commands like systemctl enable --now myservice.service. If no root permissions are available, you need to use systemctl --user. The --user option allows users to run the common systemd commands, but in user space only. This works for any service that can run without root permissions.</p> <p>When systemctl --user is used, services can be automatically started  only when a user session is started. To define an exception to that, you can use the loginctl session manager, which is part of the systemd solution to enable \u201clinger\u201d for a specific user account. If you use <code>loginctl enable-linger myuser</code>, you enable this for the user myuser. When linger is enabled, systemd services that are enabled for that specific user will be started on system start, not only when the user is logging in.</p>"},{"location":"Linux/RHCSA/Objectives/10-Manage-Containers/7-Configure%20a%20container%20to%20start%20automatically%20as%20a%20systemd%20service/#the-process","title":"The Process","text":"<ol> <li>Use sudo useradd linda to create a user linda.</li> <li>Use <code>sudo passwd linda</code> to set the password for user linda.</li> <li>Type <code>sudo loginctl enable-linger linda</code> to enable the linger feature for user linda.</li> <li>Log in as user linda (DON'T USE <code>su -</code>).<ol> <li>`ssh linda@localhost</li> </ol> </li> <li>Type <code>mkdir -p ~/.config/systemd/user; cd ~/.config/systemd/user</code> to create and activate the directory where the systemd user files will be created. Yes the directory must  be named user. </li> <li>Use <code>podman run -d --name mynginx -p 8081:80 nginx</code> to start an nginx pod.</li> <li>Type <code>podman ps</code> to verify the nginx pod has been started.</li> <li>Create the systemd user files using <code>podman generate systemd --name mynginx --files --new</code>.<ol> <li>A systemd unit file with the name <code>container-mynginx.service</code> is created.</li> </ol> </li> <li>Use <code>vim container-mynginx.service</code> and change the WantedBy line such that it reads <code>WantedBy=default.target</code>.</li> <li>Type <code>systemctl --user daemon-reload</code> to ensure that systemd picks up the changes.</li> <li>Use <code>systemctl --user enable container-mynginx.service</code> to enable the systemd user service. (Do not try to start it because it has already been started!)</li> <li>Type <code>systemctl --user status container-mynginx.service</code> to verify the service has the state of enabled.</li> <li>Reboot your server, login NOT AS linda and after rebooting, verify that the container is automatically started.</li> </ol>"},{"location":"Linux/RHCSA/Objectives/10-Manage-Containers/8-Attach%20persistent%20storage%20to%20a%20container/","title":"8 Attach persistent storage to a container","text":"<p>To add persistent storage to Podman containers, you bind-mount a directory on the host operating system into the container. A bind-mount is a specific type of mount, where a directory is mounted instead of a block device. To set up this storage solution, you need to prep first:</p> <p>For this example, we're using the <code>mariadb</code> image 1. <code>podman run -d --name mydb -e MYSQL_ROOT_PASSWORD=password mariadb 2. Make the directory you want to mount. Make sure this is in the user's home directory.  3.</code>podman unshare chown 27:27 mydb     1. podman-unshare - Run a command inside of a modified user namespace     2. The 27 is the mariadb's UID inside of the container 4. <code>podman stop mydb 5.</code>podman rm mydb</p> <p>Ok, now for the SELinux 1. The file context of the mydb directory is currently <code>user_home_t</code>. This needs to be changed, because SELinux won't allow us to bind directory to a directory that has this context.  2. <code>podman run -d --name mydb -e MYSQL_ROOT_PASSWORD=password -v /home/xavier/mydb:/var/lib/mysql:Z mariadb     1. The</code>:Z` takes care of the SELinux 3. Finally, verify  with ls on mydb, and you will see the directories from the container.      1. ![[Pasted image 20220913070924.png]]</p>"},{"location":"Linux/RHCSA/Objectives/10-Manage-Containers/Objectives/","title":"Objectives","text":"<ul> <li>Find and retrieve container images from a remote registry</li> <li>Inspect container images</li> <li>Perform container management using commands such as podman and skopeo</li> <li>Build a container from a Containerfile</li> <li>Perform basic container management such as running, starting, stopping, and listing running containers</li> <li>Run a service inside a container</li> <li>Configure a container to start automatically as a systemd service</li> <li>Attach persistent storage to a container</li> </ul>"},{"location":"Linux/RHCSA/Objectives/2-Create-Simple-Shell-Scripts/Objectives/","title":"Objectives","text":""},{"location":"Linux/RHCSA/Objectives/2-Create-Simple-Shell-Scripts/Objectives/#conditionally-execute-code-use-of-if-test-etc","title":"Conditionally execute code (use of: if, test, [], etc.)","text":"<pre><code>#!/bin/bash  \necho\u00a0\"Enter a number\"  \nread\u00a0n  \nif\u00a0[\u00a0$n\u00a0-lt\u00a0100\u00a0];\u00a0then  \nprintf\u00a0\"$n\u00a0is less than 100\\n\"  \nfi\n</code></pre>"},{"location":"Linux/RHCSA/Objectives/2-Create-Simple-Shell-Scripts/Objectives/#use-looping-constructs-for-etc-to-process-file-command-line-input","title":"Use Looping constructs (for, etc.) to process file, command line input","text":"<pre><code>#!/bin/bash\n\nfor i in 1 2 3 4 5\ndo\n\u00a0\u00a0\u00a0echo \"Welcome $i times\"\ndone\n</code></pre>"},{"location":"Linux/RHCSA/Objectives/2-Create-Simple-Shell-Scripts/Objectives/#process-script-inputs-1-2-etc","title":"Process script inputs ($1, $2, etc.)","text":"<pre><code>- Inputs are stored as $1,$2, etc.\n- If you want to see all of them, use $@\n</code></pre> <ul> <li>Processing output of shell commands within a script</li> </ul> <p>[!TIP] Use <code>bash -x</code> to enter debug mode.</p>"},{"location":"Linux/RHCSA/Objectives/2-Create-Simple-Shell-Scripts/Objectives/#example-scripts","title":"Example Scripts","text":"<pre><code>#Countdown script that converts the input to seconds, then counts down.\n#!/bin/bash\n\nif test -z $1\nthen\n        echo provide number of minutes\n        read COUNTER\nelse\n        COUNTER=$1\nfi\n\nCOUNTER=$(( COUNTER * 60 ))\n\nwhile [ $COUNTER -gt 0 ]\ndo\n        echo $COUNTER seconds remaining\n        COUNTER=$(( COUNTER - 1 ))\n        sleep 1\ndone\n\necho break is over, continuing\n</code></pre>"},{"location":"Linux/RHCSA/Objectives/3-Operate-Running-Systems/0-Objectives/","title":"0 Objectives","text":"<ul> <li>Boot, reboot, and shut down a system normally</li> <li>Boot systems into different targets manually</li> <li>Interrupt the boot process in order to gain access to a system</li> <li>Identify CPU/memory intensive processes and kill processes</li> <li>Adjust process scheduling</li> <li>Manage tuning profiles</li> <li>Locate and interpret system log files and journals</li> <li>Preserve system journals</li> <li>Start, stop, and check the status of network services</li> <li>Securely transfer files between systems</li> </ul>"},{"location":"Linux/RHCSA/Objectives/3-Operate-Running-Systems/1-Boot%2C%20reboot%20and%20shutdown%20a%20system%20normally/","title":"1 Boot, reboot and shutdown a system normally","text":"<p>To reboot the system, choose one command among these     -  reboot     -  systemctl reboot     -  shutdown -r now     -  init 6     -  telinit 6</p> <p>To shutdown the system, choose one command among these:</p> <pre><code>-  halt\n-  systemctl halt\n-  shutdown -h now\n-  init 0\n-  telinit 0\n</code></pre> <p>To switch off the system, choose one command among these:      - poweroff     -  systemctl poweroff</p>"},{"location":"Linux/RHCSA/Objectives/3-Operate-Running-Systems/10-Securely%20transfer%20files%20between%20systems/","title":"10 Securely transfer files between systems","text":""},{"location":"Linux/RHCSA/Objectives/3-Operate-Running-Systems/10-Securely%20transfer%20files%20between%20systems/#securely-transferring-files","title":"Securely Transferring Files","text":"<p>To transfer files, you can use, <code>scp</code>, <code>rsync</code>, or <code>sftp</code>.</p>"},{"location":"Linux/RHCSA/Objectives/3-Operate-Running-Systems/10-Securely%20transfer%20files%20between%20systems/#scp","title":"SCP","text":"<p>Copy the /etc/hosts file to the /tmp directory on server2 <code>scp /etc/hosts server2: /tmp</code></p> <p>Copy an entire subdirectory. <code>scp -r server2:/etc/ /tmp</code></p>"},{"location":"Linux/RHCSA/Objectives/3-Operate-Running-Systems/10-Securely%20transfer%20files%20between%20systems/#sftp","title":"SFTP","text":""},{"location":"Linux/RHCSA/Objectives/3-Operate-Running-Systems/10-Securely%20transfer%20files%20between%20systems/#rsync","title":"RSYNC","text":"<p>The rsync command uses SSH to synchronize files between a remote directory and a local directory. The advantage of synchronizing files is that only differences need to be considered. So, for example, if you synchronize a 100-MiB file in which only a few blocks have changed since the previous sync, only the changed blocks will be synchronized. This approach is also known as a delta sync.</p>"},{"location":"Linux/RHCSA/Objectives/3-Operate-Running-Systems/2-Boot%20Systems%20Into%20Different%20Targets%20Manually/","title":"2 Boot Systems Into Different Targets Manually","text":""},{"location":"Linux/RHCSA/Objectives/3-Operate-Running-Systems/2-Boot%20Systems%20Into%20Different%20Targets%20Manually/#booting-into-a-specific-target","title":"Booting Into a Specific Target","text":"<p>How would you boot into a specific target? - On theGrub 2 boot prompt, use <code>systemctl.unit=xxx.target</code> to boot into a specific target.      - ![[Pasted image 20220821143355.png|700]]</p> <ul> <li>How would you change between targets on a running system?<ul> <li>systemctl isolate xxx.target</li> </ul> </li> </ul>"},{"location":"Linux/RHCSA/Objectives/3-Operate-Running-Systems/3-Interrupt%20the%20boot%20process%20in%20order%20to%20gain%20access%20to%20a%20system/","title":"3 Interrupt the boot process in order to gain access to a system","text":"<p>At the beginning of the boot process, at the\u00a0GRUB 2\u00a0menu, type the\u00a0<code>e</code>\u00a0key to edit.</p>"},{"location":"Linux/RHCSA/Objectives/3-Operate-Running-Systems/4-Identify%20CPU_Memory_Intensive%20Processes%20and%20Kill%20Processes/","title":"Command Line Tools For Process Management","text":"Command Explanation ps Show an overview of current processes ps -ef ps ps -ef ps fax ps aux grep dd pgrep dd"},{"location":"Linux/RHCSA/Objectives/3-Operate-Running-Systems/4-Identify%20CPU_Memory_Intensive%20Processes%20and%20Kill%20Processes/#kill-killall-and-pkill","title":"Kill Killall and pkill","text":"Signal Explanation SIGTERM(15) Used to ASK a process to stop SIGTERM(9) Used to FORCE a process to stop SIGHUP (1) Used to HANG UP a process. The process will reread its config files. Like a restart. <p>To send one of these signals, use <code>kill</code>.</p>"},{"location":"Linux/RHCSA/Objectives/3-Operate-Running-Systems/5-Adjust%20process%20scheduling/","title":"Using nice and renice","text":"<pre><code>[ps aux | grep dd](&lt;[root@RHCSA-MAIN etc]# nice -n 5 dd if=/dev/zero of=/dev/null &amp;\n[1] 12219\n\n[root@RHCSA-MAIN etc]# ps aux |grep dd\nroot       12219 87.1  0.0 220992  1036 pts/3    RN   17:33   0:06 dd if=/dev/zero of=/dev/null\n\n[root@RHCSA-MAIN etc]# renice -n 10 -p 12221\n\n[root@RHCSA-MAIN etc]# renice -n 10 -p 12219\n12219 (process ID) old priority 5, new priority 10\n\n[root@RHCSA-MAIN etc]# ps aux |grep dd\n\nroot       12219 77.8  0.0 220992  1036 pts/3    RN   17:33   0:31 dd if=/dev/zero of=/dev/null\n</code></pre> <p>Use a <code>-</code> to increase priority and <code>+</code> tp decrease priority. </p> <p>[! Warning] Never set priority to -20.</p>"},{"location":"Linux/RHCSA/Objectives/3-Operate-Running-Systems/5-Adjust%20process%20scheduling/#adjust-process-scheduling","title":"Adjust process scheduling","text":"<p>The default process scheduling algorithm on RHEL is SCHED_OTHER</p> <p>We can find what scheduling algorithm a process is using with first finding the pid</p> <p>pidof -s [process]</p> <p></p> <p>From there we can use chrt to find the scheduling policy and priority</p> <p>chrt -p [pid of process]</p> <p></p> <p>To see all scheduling policies use\u00a0chrt -m</p> <p></p> <p>To set a process to use a different scheduling policy use\u00a0chrt [flag of policy] [priority of 0 or higher if applicable] -p [pid]</p> <p></p>"},{"location":"Linux/RHCSA/Objectives/3-Operate-Running-Systems/6-Locate%20and%20interpret%20system%20log%20files%20and%20journals/","title":"6 Locate and interpret system log files and journals","text":"<p>To get info about what is happening on your machine use the following 3 approaches: 1.  Monitor the files in\u00a0<code>/var/log</code>\u00a0that are written by\u00a0<code>rsyslogd</code>. 2.  Use the\u00a0<code>journalctl</code>\u00a0command to get more detailed information from the journal. 3.  Use the\u00a0<code>systemctl status &lt;unit&gt;</code>\u00a0command to get a short overview of the last significant events that have been logged by Systemd units through\u00a0<code>journald</code>.</p>"},{"location":"Linux/RHCSA/Objectives/3-Operate-Running-Systems/7-Manage%20Tuning%20Profiles/","title":"Tuned","text":"<p>Tuned is a daemon that monitors system activity and provides profiles. In these profiles, an admin can automatically tune a system for best possible latency, throughput or power consumption.  All you need to do is select the appropriate profile</p> Command Explanation tuned-adm list Shows an overview of the current available profiles tuned-adm profile Selects the profile"},{"location":"Linux/RHCSA/Objectives/3-Operate-Running-Systems/8-Preserve%20System%20Journals/","title":"Preserving the Systemd Journal","text":"<p>By default, the journal is stored in the file <code>/run/log/journal</code>. The entire /run directory is used for current process status information only, which means that the journal is cleared when the system reboots. To make the journal persistent between system restarts, you should make sure that a directory <code>/var/log/journal</code> exists. Yes, all you need to do is create this directory. The system will handle the rest. </p> <p>Storing the journal permanently requires setting the Storage=auto parameter in<code>/etc/systemd/journal.conf</code>. This parameter can have different values:</p> <ul> <li><code>Storage=auto</code> The journal will be written on disk if the directory /var/log/journal exists.</li> <li><code>Storage=volatile</code> The journal will be stored only in the /run/log/ journal directory.    </li> <li><code>Storage=persistent</code>The journal will be stored on disk in the directory /var/log/journal. This directory will be created automatically if it doesn\u2019t exist.</li> <li><code>Storage=none</code> No data will be stored, but forwarding to other targets such as the kernel log buffer or syslog will still work.</li> </ul> <p>[!WARNING]  The journal is NOT kept forever. The journal has built-in log rotation that will be used monthly. To change these settings, you can modify the file <code>/etc/systemd/journald.conf</code>.</p>"},{"location":"Linux/RHCSA/Objectives/3-Operate-Running-Systems/8-Preserve%20System%20Journals/#instructions","title":"Instructions","text":""},{"location":"Linux/RHCSA/Objectives/3-Operate-Running-Systems/8-Preserve%20System%20Journals/#create-a-storage-directory","title":"Create a storage directory","text":"<p>First, create a journal directory under the\u00a0<code>/var/log</code>\u00a0directory: <pre><code>[server]$ sudo mkdir /var/log/journal\n</code></pre></p>"},{"location":"Linux/RHCSA/Objectives/3-Operate-Running-Systems/8-Preserve%20System%20Journals/#edit-the-journaldconf-file","title":"Edit the journald.conf file","text":"<p>Edit the file\u00a0<code>/etc/systemd/journald.conf</code>\u00a0and set the\u00a0Storage\u00a0parameter to\u00a0persistent\u00a0(it is set to\u00a0auto\u00a0by default): <pre><code>[server]$ sudo vim /etc/systemd/journald.conf\n[Journal]\nStorage=persistent \n[...]\n</code></pre></p>"},{"location":"Linux/RHCSA/Objectives/3-Operate-Running-Systems/8-Preserve%20System%20Journals/#restart-systemd-journald","title":"Restart systemd-journald","text":"<p>Next, restart the\u00a0systemd-journald\u00a0service:</p> <pre><code>[server]$ systemctl restart systemd-journald\n</code></pre>"},{"location":"Linux/RHCSA/Objectives/3-Operate-Running-Systems/8-Preserve%20System%20Journals/#reboot-the-server","title":"Reboot the server","text":"<p>Finally, reboot the server to confirm the persistence of entries by listing the\u00a0<code>/var/log/journal</code>\u00a0content. You should have output that looks similar to this:</p> <pre><code>[server]$ ls /var/log/journal\n75ab164a278e48be9cf80d80716a8cd9\n</code></pre>"},{"location":"Linux/RHCSA/Objectives/3-Operate-Running-Systems/9-Start%2C%20stop%2C%20and%20check%20the%20status%20of%20network%20services/","title":"9 Start, stop, and check the status of network services","text":"<p>Starting a service:\u00a0systemctl start [service]</p> <p></p> <p>Stopping a service:\u00a0systemctl stop [service]</p> <p></p> <p>To check if service is running:\u00a0systemctl is-active [service]</p> <p></p> <p>To check if service is enabled at boot:\u00a0systemctl is-enabled [service]</p> <p></p> <p>Enable a service to run at boot:\u00a0systemctl enable [service]</p> <p></p> <p>Disable service from running at boot:\u00a0systemctl disable [service]</p> <p></p> <p>To permanently disable a service:\u00a0systemctl mask [service]</p> <p></p> <p>To re-activate a permanently disabled service:\u00a0systemctl unmask [service]</p> <p></p>"},{"location":"Linux/RHCSA/Objectives/4-Configure-Local-Storage/1-List%2C%20create%2C%20delete%20partitions%20on%20MBR%20and%20GPT%20disks/","title":"1 List, create, delete partitions on MBR and GPT disks","text":"<p>Always start with <code>lsblk</code> just to get an overview. ![[Pasted image 20220902050824.png]]</p>"},{"location":"Linux/RHCSA/Objectives/4-Configure-Local-Storage/1-List%2C%20create%2C%20delete%20partitions%20on%20MBR%20and%20GPT%20disks/#mbr","title":"MBR","text":"<p>Create  fdisk {device} 1. fdisk /dev/{deviceName} 2. <code>n</code> - To create a new partition 3. <code>p</code> - To create a primary partition 4. It will ask for first sector. You can just hit enter. 5. It will now as for Last Sector. Type the value of how big you want your partition to be. 6. <code>w</code> - To write/save your changes.</p>"},{"location":"Linux/RHCSA/Objectives/4-Configure-Local-Storage/1-List%2C%20create%2C%20delete%20partitions%20on%20MBR%20and%20GPT%20disks/#gpt","title":"GPT","text":"<p>Create gdisk {device} 1. <code>parted /dev/{deviceName}</code> 2. <code>mklabel gpt</code> 3. Verify with <code>print</code> 4. <code>mkpart one 1MiB 1024MiB</code> 5. quit 6. <code>udevadm settle</code></p> <p>[!WARNING] For parted there is a difference between G and GiB</p>"},{"location":"Linux/RHCSA/Objectives/4-Configure-Local-Storage/2-Logical%20Volumes/","title":"Creating Logical Volumes","text":"<p>Creating logical volumes involves creating 3 layers in the LVM architecture: 1. Convert physical devices into physical volumes 2. Create the volume group and assign PVs to it. 3. Create the logical volume itself. </p> <p>[!TIP] For the exam, you must memorize pv, vg, and lv. Remember though, use tab to see their options. </p>"},{"location":"Linux/RHCSA/Objectives/4-Configure-Local-Storage/2-Logical%20Volumes/#create-the-partition","title":"Create The Partition","text":"<ol> <li><code>parted /dev/{deviceName}</code></li> <li>It will ask for a partition table<ol> <li>msdos or gpt ![[Pasted image 20220902124750.png]]</li> </ol> </li> <li><code>mkpart</code></li> <li>It will ask for a partition name:<ol> <li>Set it to <code>lvm1</code></li> </ol> </li> <li>File System Type<ol> <li>Just press <code>enter</code></li> </ol> </li> <li>Set the start point</li> <li>Set the end point</li> <li>Verify with <code>print</code></li> <li>From the print command, get the number of the partition and type <code>set {number} lvm on</code></li> <li><code>quit</code> ![[Pasted image 20220902124832.png]]</li> </ol>"},{"location":"Linux/RHCSA/Objectives/4-Configure-Local-Storage/2-Logical%20Volumes/#create-the-physical-volume","title":"Create The Physical Volume","text":"<ol> <li><code>pvcreate /dev/{partition}</code><ol> <li>You should receive a success message ![[Pasted image 20220902124439.png]]</li> </ol> </li> </ol>"},{"location":"Linux/RHCSA/Objectives/4-Configure-Local-Storage/2-Logical%20Volumes/#create-the-volume-group","title":"Create The Volume Group","text":"<ol> <li><code>vgcreate vgdata /dev/{partition}</code><ol> <li>Again, you should receive a success message ![[Pasted image 20220902124506.png]]</li> </ol> </li> </ol>"},{"location":"Linux/RHCSA/Objectives/4-Configure-Local-Storage/2-Logical%20Volumes/#create-the-logical-volume","title":"Create The Logical Volume","text":"<ol> <li><code>lvcreate -n lvdata -L 812M vgdata</code> ![[Pasted image 20220902124540.png]]</li> </ol>"},{"location":"Linux/RHCSA/Objectives/4-Configure-Local-Storage/2-Logical%20Volumes/#putting-filesystem-on-the-logical-volume","title":"Putting Filesystem on the Logical Volume","text":"<ol> <li>mkfs.xfs /dev/vgdata/lvdata  ![[Pasted image 20220902124614.png]]</li> </ol>"},{"location":"Linux/RHCSA/Objectives/4-Configure-Local-Storage/2-Logical%20Volumes/#mount-it-in-fstab","title":"Mount it in FSTAB","text":"<ol> <li>Create your mount point<ol> <li>mkdir /mounts/lvm1</li> </ol> </li> <li>vim /etc/fstab<ol> <li>![[Pasted image 20220902055615.png]]</li> </ol> </li> <li>mount -a</li> <li>Reboot!</li> </ol>"},{"location":"Linux/RHCSA/Objectives/4-Configure-Local-Storage/3-Configure%20systems%20to%20mount%20file%20systems%20at%20boot%20by%20universally%20unique%20ID%20%28UUID%29%20or%20label/","title":"3 Configure systems to mount file systems at boot by universally unique ID (UUID) or label","text":"<p>To create a label, use the <code>tune2fs</code> command. ![[Pasted image 20220902130836.png]]</p> <p>[!Warning] Before using tune2fs, the partition must have a filesystem on top of it. </p> <p>Then add it to /etc/fstab ![[Pasted image 20220902130935.png]]</p>"},{"location":"Linux/RHCSA/Objectives/4-Configure-Local-Storage/4-Add%20new%20partitions%20and%20logical%20volumes%2C%20and%20swap%20to%20a%20system%20non-destructively/","title":"Creating Swap Partition","text":"<ol> <li>Type <code>parted {device}</code>, which will bring you to interactive shell.</li> <li><code>mkpart</code>, which will ask you for a name. just call it swap</li> <li>File System type should be <code>linux-swap</code>!!!</li> <li>Start - 1GiB</li> <li>End - 2GiB</li> <li><code>quit</code></li> <li><code>mkswap</code> {device name}</li> <li>Type <code>free -m</code>. You see the amount of swap space that is currently allocated. This does not include the swap space you have just created, as it still needs to be activated.</li> <li>Use <code>swapon {deviceName}</code> to switch on the newly allocated swap space. If, for instance, the swap device you have just created is /dev/sda6, use swapon /dev/sda6 to activate the swap space.</li> <li>Add it to <code>/etc/fstab</code> to make it persistent</li> <li>Type free -m again. You see that the new swap space has been added to your server.</li> </ol>"},{"location":"Linux/RHCSA/Objectives/4-Configure-Local-Storage/Objectives/","title":"Objectives","text":"<ul> <li>List, create, delete partitions on MBR and GPT disks</li> <li>Create and remove physical volumes</li> <li>Assign physical volumes to volume groups</li> <li>Create and delete logical volumes</li> <li>Configure systems to mount file systems at boot by universally unique ID (UUID) or label</li> <li>Add new partitions and logical volumes, and swap to a system non-destructively</li> </ul>"},{"location":"Linux/RHCSA/Objectives/5-Create-Configure-File-Systems/1-Create%2C%20mount%2C%20unmount%2C%20and%20use%20vfat%2C%20ext4%2C%20and%20xfs%20file%20systems/","title":"1 Create, mount, unmount, and use vfat, ext4, and xfs file systems","text":"<p>To create a filesystem, use <code>mkfs</code></p> <p>[!WARNING] Never just type mkfs. This will create an Ext2 file system, and theres no need for that anymore!!! </p>"},{"location":"Linux/RHCSA/Objectives/5-Create-Configure-File-Systems/2-Mount%20and%20unmount%20network%20file%20systems%20using%20NFS/","title":"Setting up an NFS Server","text":"<p>[!TIP] You do not have to do this for the exam. 1. Make sure nfs is installed     1. <code>systemctl status nfs-server</code> 2. If it is not, install it.     1. <code>dnf install nfs-utils</code> 3. Create the share directory.     1. <code>mkdir /data</code> 4. vim /etc/exports     1. ![[Pasted image 20220827152726.png]] 5. systemctl enable --now nfs-server 6. Configure the firewall rules 7. firewall-cmd  --add-service=nfs     1.<code>firewall-cmd  --add-service=mountd</code>     2. <code>firewall-cmd  --add-service=rpc-bind</code>     3. <code>firewall-cmd  --add-service=rpc-bind--permanent</code>     4. <code>firewall-cmd  --add-service=rpc-bind --permanent</code>     5. <code>firewall-cmd  --add-service=mountd --permanent</code>     6. <code>firewall-cmd  --add-service=nfs --permanent</code></p>"},{"location":"Linux/RHCSA/Objectives/5-Create-Configure-File-Systems/2-Mount%20and%20unmount%20network%20file%20systems%20using%20NFS/#mounting-nfs-shares","title":"Mounting NFS Shares","text":"<ol> <li><code>showmount -e {nfs-host}</code></li> <li>Add it in fstab<ol> <li>![[Pasted image 20220827153428.png]]</li> </ol> </li> <li>Check your work with <code>mount -a</code></li> <li>Reboot to test. </li> </ol>"},{"location":"Linux/RHCSA/Objectives/5-Create-Configure-File-Systems/3-Configure%20autofs/","title":"Understanding Automount","text":"<p>Automount is implemented by the autofs service that takes care of mounting a share when an attempt is made to access it. That means it is mounted on demand and that it does not have to be mounted permanently. An important benefit of using automount is that it works completely in user space and, contrary to mounts that are made through the mount command, no root permissions are required.</p> <ol> <li>Make sure autofs is installed.<ol> <li><code>yum install -y autofs</code> </li> </ol> </li> <li>Type showmount -e {NFS HOST}, which shows you NFS exports offered by server2.<ol> <li>![[Pasted image 20220907183044.png]]</li> </ol> </li> <li>Open the file <code>/etc/auto.master</code> and add the mount point, and the secondary file:<ol> <li>![[Screen Shot 2022-09-07 at 6.50.47 PM.png]]</li> </ol> </li> <li>Next create the secondary file. In this example, it will be /etc/auto.files. In this file, you'll add the mount point directory as a relative filename, NFS options, and the server and share name. <ol> <li>![[Pasted image 20220907185411.png]]</li> </ol> </li> <li><code>systemctl restart autofs</code></li> <li><code>systemctl enable --now autofs</code></li> <li>Verify with mount and grep commands<ol> <li>![[Pasted image 20220907190311.png]]</li> </ol> </li> </ol>"},{"location":"Linux/RHCSA/Objectives/5-Create-Configure-File-Systems/3-Configure%20autofs/#automount-on-home-directories","title":"Automount on home directories","text":"<p>To setup these examples, just create new users with home directories that don't already exist.  1. On your NFS server, add your new export     1. ![[Pasted image 20220908065744.png]]     2. restart nfs     3. Back on your main server edit the <code>/etc/auto.master</code> file         1. ![[Pasted image 20220908065927.png]]     4. Edit the corresponding map file. In this case, its <code>/etc/auto.ldap</code>         1. ![[Pasted image 20220908070016.png]]     5. <code>systemctl restart autofs</code></p>"},{"location":"Linux/RHCSA/Objectives/5-Create-Configure-File-Systems/4-Extend%20Existing%20Logical%20Volumes/","title":"4 Extend Existing Logical Volumes","text":"<ol> <li>[[Logical Volumes#Create The Partition]]</li> <li>Run <code>vgs</code> to verify</li> <li>As we can see, we no space left on our volume group<ol> <li>![[Pasted image 20220909065605.png]]</li> </ol> </li> <li>Once you have your partition use vgextend on it. <ol> <li>![[Pasted image 20220909065448.png]]</li> </ol> </li> <li>Run vgs to see your <code>VFREE</code>. This will be uses in the final command  </li> <li>Finally, run lvextend:<ol> <li>![[Pasted image 20220909065711.png]]</li> </ol> </li> </ol>"},{"location":"Linux/RHCSA/Objectives/5-Create-Configure-File-Systems/5-Create%20and%20configure%20set-GID%20directories%20for%20collaboration/","title":"5 Create and configure set GID directories for collaboration","text":""},{"location":"Linux/RHCSA/Objectives/5-Create-Configure-File-Systems/5-Create%20and%20configure%20set-GID%20directories%20for%20collaboration/#scenario","title":"Scenario","text":"<ul> <li>shelly and linda are both apart of the profs group.</li> <li>They want to share files in the <code>/data/profs</code> directory. </li> <li>Linda creates a file, and wants shelly to edit it. Without SGID, this is impossible because when linda creates a file, she becomes the owner, and group of that file. <ul> <li>![[Pasted image 20220909072650.png]]</li> </ul> </li> <li>To get around this, set up SGID on that directory.<ul> <li><code>chmod 2770 /data/profs/</code></li> </ul> </li> <li>Now, whenever a file is created in this directory, the group owner of the directory becomes the group owner of file. In this case, <code>profs</code><ul> <li>![[Pasted image 20220909072924.png]]</li> </ul> </li> <li>chmod 660 to make sure the file can actually be edited by group members. <ul> <li>![[Pasted image 20220909073039.png]]</li> </ul> </li> <li>Now shelly can edit <code>linda1</code> !!</li> </ul>"},{"location":"Linux/RHCSA/Objectives/5-Create-Configure-File-Systems/6-Diagnose%20and%20correct%20file%20permission%20problems/","title":"6 Diagnose and correct file permission problems","text":"<p>[[7. Managing Users and Groups#ACLs]]</p>"},{"location":"Linux/RHCSA/Objectives/5-Create-Configure-File-Systems/Objectives/","title":"Objectives","text":"<ul> <li>Create, mount, unmount, and use vfat, ext4, and xfs file systems</li> <li>Mount and unmount network file systems using NFS</li> <li>Configure autofs</li> <li>Extend existing logical volumes</li> <li>Create and configure set-GID directories for collaboration</li> <li>Diagnose and correct file permission problems</li> </ul>"},{"location":"Linux/RHCSA/Objectives/6-Deploy-Configure-Maintain-Systems/1-Schedule%20tasks%20using%20at%20and%20cron/","title":"1 Schedule tasks using at and cron","text":"<p>Cron 1. <code>crontab -e</code> 2. <code>:wq</code></p> <p>at 1. Make sure atd service is running     1. <code>systemctl status atd</code> 2. at {time of event}     1. ![[Pasted image 20220910054203.png]] 3. CTRL-d to quit</p>"},{"location":"Linux/RHCSA/Objectives/6-Deploy-Configure-Maintain-Systems/2-Start%20and%20stop%20services%20and%20configure%20services%20to%20start%20automatically%20at%20boot/","title":"2 Start and stop services and configure services to start automatically at boot","text":"<p><code>systemctl enable {service}</code></p>"},{"location":"Linux/RHCSA/Objectives/6-Deploy-Configure-Maintain-Systems/3-Configure%20systems%20to%20boot%20into%20a%20specific%20target%20automatically/","title":"3 Configure systems to boot into a specific target automatically","text":"<p>To view the current default target (what target is being used for the current boot process:</p> <p><code>systemctl get-default</code></p> <p>To list all of the currently loaded targets units (as called by the master target):</p> <p><code>systemctl list-units --type target</code> - The command will only show the currently active units, to show all units:</p> <p><code>systemctl list-units --type target --all</code></p> <p>To change the default target:</p> <p><code>systemctl set-default multi-user.target</code></p>"},{"location":"Linux/RHCSA/Objectives/6-Deploy-Configure-Maintain-Systems/4-Configure%20time%20service%20clients/","title":"NTP","text":"<p><code>chronyd</code> is the default NTP service on RHEL 9. Use <code>/etc/chrony.conf</code> to specify synchronization parameters.  ![[Pasted image 20220910060110.png]]</p>"},{"location":"Linux/RHCSA/Objectives/6-Deploy-Configure-Maintain-Systems/5-Install%20and%20update%20software%20packages%20from%20Red%20Hat%20Network%2C%20a%20remote%20repository%2C%20or%20from%20the%20local%20file%20system/","title":"5 Install and update software packages from Red Hat Network, a remote repository, or from the local file system","text":"<p>There is no internet connection on the machines, so you have to install locally.</p>"},{"location":"Linux/RHCSA/Objectives/6-Deploy-Configure-Maintain-Systems/5-Install%20and%20update%20software%20packages%20from%20Red%20Hat%20Network%2C%20a%20remote%20repository%2C%20or%20from%20the%20local%20file%20system/#local","title":"Local","text":"<p><code>dnf config-manager --add-repo=\"file:///repo/BaseOS\"</code> <code>dnf config-manager --add-repo=\"file:///repo/AppStrem\"</code> Verify with <code>ls /etc/yum.repos.d</code></p> <p>If dnf confg-manager isnt installed, you'll want to know how to do this by creating repo files.</p>"},{"location":"Linux/RHCSA/Objectives/6-Deploy-Configure-Maintain-Systems/5-Install%20and%20update%20software%20packages%20from%20Red%20Hat%20Network%2C%20a%20remote%20repository%2C%20or%20from%20the%20local%20file%20system/#not-on-the-exam","title":"Not On The Exam","text":"<ol> <li>MAKE SURE YOUR DISC IS ACTUALLY LOADED</li> <li><code>dd if=/dev/sr0 of=/{NAME_OF_ISO} bs=1M</code><ol> <li>if is the input file, and of is the output file.</li> </ol> </li> <li><code>mkdir /repo</code></li> <li>vim /etc/fstab<ol> <li>Add the following line:<ol> <li>/rhel9.iso              /repo                   iso9660 defaults        0 0</li> </ol> </li> </ol> </li> <li><code>systemctl daemon-reload</code></li> <li><code>mount -a</code></li> </ol> <p>Create two files     1. <code>/etc/yum.repos.d/appstream.repo</code>     2. <code>/etc/yum.repos.d/base.repo</code></p> <pre><code>[appstream]\nname=appstream\nbaseurl=file:///repo/AppStream\ngpgcheck=0       \n</code></pre> <p><pre><code>[base]\nname=base\nbaseurl=file:///repo/BaseOS\ngpgcheck=0\n</code></pre> To tell your server which repository to use, you need to create a file with a name that ends in .repo in the directory /etc/yum.repos.d. In that file you need the following contents</p>"},{"location":"Linux/RHCSA/Objectives/6-Deploy-Configure-Maintain-Systems/6-Modify%20the%20system%20bootloader/","title":"6 Modify the system bootloader","text":"<p>The GRUB 2 boot loader makes sure that you can boot Linux.</p>"},{"location":"Linux/RHCSA/Objectives/6-Deploy-Configure-Maintain-Systems/6-Modify%20the%20system%20bootloader/#runtime-parameters","title":"Runtime Parameters","text":"<p>Use  the <code>-e</code> command</p>"},{"location":"Linux/RHCSA/Objectives/6-Deploy-Configure-Maintain-Systems/6-Modify%20the%20system%20bootloader/#persistant-parameters","title":"Persistant Parameters","text":"<p>To apply changes to the GRUB 2 configuration, the starting point is the <code>/etc/default/grub</code> file, which has options that tell GRUB what to do and how to do it. After writing changes, use one of the following commands: - <code>grub2-mkconfig -o /boot/grub2/grub.cfg</code> - <code>grub2-mkconfig -o /boot/efi/EFI/redhat/grub.cfg</code></p> <p>How to know which one to use? - Use <code>lsblk</code>, and look for <code>/boot</code>. If you see /boot/efi and /boot, you are on EFI. If you see /boot, you are on MBR</p>"},{"location":"Linux/RHCSA/Objectives/6-Deploy-Configure-Maintain-Systems/Objectives/","title":"Objectives","text":"<ul> <li>Schedule tasks using at and cron</li> <li>Start and stop services and configure services to start automatically at boot</li> <li>Configure systems to boot into a specific target automatically</li> <li>Configure time service clients</li> <li>Install and update software packages from Red Hat Network, a remote repository, or from the local file system</li> <li>Modify the system bootloader</li> </ul>"},{"location":"Linux/RHCSA/Objectives/7-Manage-Basic-Networking/1-Configure%20IPv4%20and%20IPv6%20addresses/","title":"1 Configure IPv4 and IPv6 addresses","text":"<p>![[Pasted image 20220910171357.png]]</p>"},{"location":"Linux/RHCSA/Objectives/7-Manage-Basic-Networking/2-Configure%20hostname%20resolution/","title":"2 Configure hostname resolution","text":"<ul> <li>hostnamectl set-hostname to manage hostnames</li> <li>To resolve hostnames, /etc/hosts is used <ul> <li>![[Pasted image 20220910171858.png]]<ul> <li>The first part is the ip address</li> <li>The 2nd part is the FDQN</li> <li>The third part is the short name. </li> </ul> </li> </ul> </li> </ul> <p>If you're connecting to the world wide web, you'll want to use /etc/resolv.conf for DNS</p> <p>Finally, the order of host name resolution is determined through <code>/etc/nsswitch.conf</code></p>"},{"location":"Linux/RHCSA/Objectives/7-Manage-Basic-Networking/4-Restrict%20network%20access%20using%20firewall/","title":"Firewalld","text":"<p>Firewalld uses different components to make firewalling easier: - Service - Zone - Ports</p>"},{"location":"Linux/RHCSA/Objectives/7-Manage-Basic-Networking/4-Restrict%20network%20access%20using%20firewall/#adding-a-service","title":"Adding a Service","text":"<p>Lets say you want to add the ftp service. 1. <code>firewall-cmd --add-service=ftp</code> 2. Verify with <code>firewall-cmd --list-all</code> 3. This is not persistent, though. To make it so, you must add the permanent flag     1. <code>firewall-cmd --add-service=ftp --permanent</code>     2. <code>firewall-cmd --add-service=ftp</code></p>"},{"location":"Linux/RHCSA/Objectives/7-Manage-Basic-Networking/Objectives/","title":"Objectives","text":"<ul> <li>Configure IPv4 and IPv6 addresses</li> <li>Configure hostname resolution</li> <li>Configure network services to start automatically at boot</li> <li>Restrict network access using firewall-cmd/firewall</li> </ul>"},{"location":"Linux/RHCSA/Objectives/8-Manage-Users-Groups/1-Create%2C%20delete%2C%20and%20modify%20local%20user%20accounts/","title":"1 Create, delete, and modify local user accounts","text":"<p>useradd usermod userdel</p>"},{"location":"Linux/RHCSA/Objectives/8-Manage-Users-Groups/2-Change%20passwords%20and%20adjust%20password%20aging%20for%20local%20user%20accounts/","title":"2 Change passwords and adjust password aging for local user accounts","text":""},{"location":"Linux/RHCSA/Objectives/8-Manage-Users-Groups/2-Change%20passwords%20and%20adjust%20password%20aging%20for%20local%20user%20accounts/#update-the-password-for-a-user","title":"Update the password for a user","text":"<p>Use <code>chage</code> to update password aging ![[Pasted image 20220910173825.png]]</p>"},{"location":"Linux/RHCSA/Objectives/8-Manage-Users-Groups/3-Create%2C%20delete%2C%20and%20modify%20local%20groups%20and%20group%20memberships/","title":"3 Create, delete, and modify local groups and group memberships","text":"<p>groupadd  groupmod usermod -aG groupdel</p>"},{"location":"Linux/RHCSA/Objectives/8-Manage-Users-Groups/4Superuser/","title":"4Superuser","text":"<p>visudo</p>"},{"location":"Linux/RHCSA/Objectives/8-Manage-Users-Groups/Objectives/","title":"Objectives","text":"<ul> <li>Create, delete, and modify local user accounts</li> <li>Change passwords and adjust password aging for local user accounts</li> <li>Create, delete, and modify local groups and group memberships</li> <li>Configure superuser access</li> </ul>"},{"location":"Linux/RHCSA/Objectives/9-Manage-Security/1-Configure%20firewall%20settings/","title":"Firewalld","text":"<p>Firewalld uses different components to make firewalling easier: - Service - Zone - Ports</p>"},{"location":"Linux/RHCSA/Objectives/9-Manage-Security/1-Configure%20firewall%20settings/#adding-a-service","title":"Adding a Service","text":"<p>Lets say you want to add the ftp service. 1. <code>firewall-cmd --add-service=ftp</code> 2. Verify with <code>firewall-cmd --list-all</code> 3. This is not persistent, though. To make it so, you must add the permanent flag     1. <code>firewall-cmd --add-service=ftp --permanent</code>     2. <code>firewall-cmd --add-service=ftp</code></p>"},{"location":"Linux/RHCSA/Objectives/9-Manage-Security/2-Manage%20default%20file%20permissions/","title":"Setting Default Permissions with umask","text":"<p>If you do not use ACLs, there is a shell setting that determines the default permissions that you will get: <code>umask</code>. Default permissions for a file are 666. Default permissions for a directory are 777.  <pre><code>666 - 022 = 644\n-rw-r--r--. 1 root   root      0 Jul  9 06:22 test1\n6    4    4\n</code></pre></p> <p>So if we wanted to give every new file, read, read, and no permissions we'd run <code>umask  226</code></p> <pre><code>666 - 226 = 440\n-r--r-----. 1 root   root      0 Jul  9 06:26 test2\n4   4   0\n</code></pre> <p>To make the default file permissions 777(NOT RECOMMENDED), run <code>umask 000</code></p>"},{"location":"Linux/RHCSA/Objectives/9-Manage-Security/3Configure%20key-based%20authentication%20for%20SSH/","title":"3Configure key based authentication for SSH","text":""},{"location":"Linux/RHCSA/Objectives/9-Manage-Security/3Configure%20key-based%20authentication%20for%20SSH/#how-to","title":"How To","text":"<ol> <li><code>ssh-keygen</code></li> <li><code>ssh-copy-id {host/ip address}</code></li> </ol>"},{"location":"Linux/RHCSA/Objectives/9-Manage-Security/4-Set%20enforcing%20and%20permissive%20modes%20for%20SELinux/","title":"4 Set enforcing and permissive modes for SELinux","text":"<p><code>getenforce</code> shows the current state ![[Pasted image 20220911074632.png]] <code>setenforce permissive</code> <code>setenforcing enforcing</code></p>"},{"location":"Linux/RHCSA/Objectives/9-Manage-Security/5-List%20and%20identify%20SELinux%20file%20and%20process%20context/","title":"5 List and identify SELinux file and process context","text":"<p>To see current context, use <code>-Z</code> - ![[Pasted image 20220911081608.png]]     - For the exam, we're concerned with <code>_t</code></p> <p><code>semanage fcontext</code> to set file context label <code>semanage fcontext -a</code> - Sets a new context label <code>semanage fcontext -m</code> - Modifies an existing context label  <code>semanage fcontext -l -C</code> - This shows only settings that have changes in the current policy</p> <p>[!TIP] When using fcontext, this only writes to the SELinix Policy. But, we need it written to the filesystem. To do that, you must use <code>restorecon</code>.</p>"},{"location":"Linux/RHCSA/Objectives/9-Manage-Security/6-Restore%20default%20file%20contexts/","title":"6 Restore default file contexts","text":"<p><code>restorecon -Rv /path</code></p>"},{"location":"Linux/RHCSA/Objectives/9-Manage-Security/7-Manage%20SELinux%20port%20labels/","title":"7 Manage SELinux port labels","text":"<p>For any non-default port access, use <code>semanage port</code> to apply the correct label to the port.</p> <p>[!TIP] Please use <code>man semanage-port</code> for help on the exam. It literally has examples. </p>"},{"location":"Linux/RHCSA/Objectives/9-Manage-Security/7-Manage%20SELinux%20port%20labels/#scenario","title":"Scenario","text":"<ul> <li>We changed the default sshd port to <code>2022</code></li> <li>When attempting to restart the service, it failed. </li> <li>When checking <code>grep AVC /var/log/audit/audit.log</code>, we saw the following:<ul> <li>![[Pasted image 20220911084509.png]]</li> <li>Ok, let's check the man page.<ul> <li>![[Pasted image 20220911084548.png]]</li> </ul> </li> </ul> </li> <li>Cool, we see our example. So run that command.<ul> <li>[root@RHCSA-MAIN html]# semanage port -a -t ssh_port_t -p tcp 2022</li> <li>If you get an error that context is already assigned, you need to use <code>-m</code>, instead of <code>-a</code></li> </ul> </li> </ul>"},{"location":"Linux/RHCSA/Objectives/9-Manage-Security/8-Use%20boolean%20settings%20to%20modify%20system%20SELinux%20settings/","title":"8 Use boolean settings to modify system SELinux settings","text":"<ul> <li>semanage boolean -l </li> <li>setsebool -P  boolean [on|off]<ul> <li>Example -  `setsebool -P ftpd_anon_write on</li> </ul> </li> </ul>"},{"location":"Linux/RHCSA/Objectives/9-Manage-Security/9-Diagnose%20and%20address%20routine%20SELinux%20policy%20violations/","title":"9 Diagnose and address routine SELinux policy violations","text":"<p>Below are some of the common troubleshooting steps when dealing with SELinux</p> <ol> <li>Set the mode to permissive to troubleshoot</li> <li><code>grep AVC /var/log/audit/audit.log</code></li> </ol>"},{"location":"Linux/RHCSA/Practice%20Exams/A%20Cloud%20Guru/","title":"Managing Servers","text":""},{"location":"Linux/RHCSA/Practice%20Exams/A%20Cloud%20Guru/#create-usersgroups-and-configure-superuser-access-on-both-servers","title":"Create Users/Groups and Configure Superuser Access on Both Servers","text":"<p>We're going to lay the groundwork here and use these local accounts for all the subsequent tasks. You can write a script to do this, or do it by hand, from the data in the input file for the script. The file contents are:</p> <p><code>manny:1010:dba_admin,dba_managers,dba_staff moe:1011:dba_admin,dba_staff jack:1012:dba_intern,dba_staff marcia:1013:it_staff,it_managers jan:1014:dba_admin,dba_staff cindy:1015:dba_intern,dba_staff</code></p> <p>Set all user passwords to\u00a0<code>dbapass</code>. Also, change the users' PRIMARY groups' GID to match their UID. Don't forget to check their home directories to make sure permisisons are correct!</p> <p>Configure superuser access:</p> <p>Enable the following command aliases:</p> <ul> <li>SOFTWARE</li> <li>SERVICES</li> <li>PROCESSES</li> </ul> <p>Add a new command alias named \"MESSAGES\":</p> <p><code>/bin/tail -f /var/log/messages</code></p> <p>Enable superuser privilages for the following local groups:</p> <ul> <li>dba_managers: everything</li> <li>dba_admin: Command aliases: SOFTWARE, SERVICES, PROCESSES</li> <li>dba_intern: Command alias: MESSAGES</li> </ul>"},{"location":"Linux/RHCSA/Practice%20Exams/A%20Cloud%20Guru/#configure-yum-repositories-on-both-servers-and-install-packagesmodules","title":"Configure\u00a0<code>yum</code>\u00a0Repositories on Both Servers and Install Packages/Modules","text":"<p>You'll need to configure three repositories and install some software:</p> <p>RHEL 8 BaseOS:</p> <ul> <li>Repository ID: [rhel-8-baseos-rhui-rpms]</li> <li>The mirrorlist is:\u00a0<code>https://rhui3.REGION.aws.ce.redhat.com/pulp/mirror/content/dist/rhel8/rhui/$releasever/$basearch/baseos/os</code></li> <li>The GPG key is located at:\u00a0<code>/etc/pki/rpm-gpg/RPM-GPG-KEY-redhat-release</code></li> <li>You will need to add SSL configuration:</li> </ul> <p><code>sslverify=1 sslclientkey=/etc/pki/rhui/content-rhel8.key sslclientcert=/etc/pki/rhui/product/content-rhel8.crt sslcacert=/etc/pki/rhui/cdn.redhat.com-chain.crt</code></p> <p>RHEL 8 AppStream:</p> <ul> <li>Repository ID: [rhel-8-appstream-rhui-rpms]</li> <li>The mirrorlist is:\u00a0<code>https://rhui3.REGION.aws.ce.redhat.com/pulp/mirror/content/dist/rhel8/rhui/$releasever/$basearch/appstream/os</code></li> <li>The GPG key is located at:\u00a0<code>/etc/pki/rpm-gpg/RPM-GPG-KEY-redhat-release</code></li> <li>You will need to add SSL configuration:</li> </ul> <p><code>sslverify=1 sslclientkey=/etc/pki/rhui/content-rhel8.key sslclientcert=/etc/pki/rhui/product/content-rhel8.crt sslcacert=/etc/pki/rhui/cdn.redhat.com-chain.crt</code></p> <p>EPEL:</p> <ul> <li>Repository ID: [epel]</li> <li>The baseurl is:\u00a0<code>https://download.fedoraproject.org/pub/epel/$releasever/Everything/$basearch</code></li> </ul> <p>Configure the repositories on the first server, then make an archive of the files, securely copy them to the second server, then unarchive the repository files on the second server.</p> <p>Install software on both servers:</p> <ul> <li>Install the default AppStream stream/profile for\u00a0<code>container-tools</code></li> <li>Install the\u00a0<code>youtube-dl</code>\u00a0package (from EPEL)</li> <li>Check for system updates, but don't install them</li> </ul>"},{"location":"Linux/RHCSA/Practice%20Exams/A%20Cloud%20Guru/#configure-ip-addresses-on-the-second-network-interface-on-the-first-server","title":"Configure IP Addresses on the Second Network Interface on the First Server","text":"<p>On the first server, configure the second interface's IPv4/IPv6 addresses using\u00a0<code>nmtui</code>.</p> <p>IP Addresses:</p> <ul> <li>IPv4: 10.0.1.20/24</li> <li>IPv6: 2002:0a00:0114::/64</li> <li>Manual, not Automatic (DHCP) for both interfaces</li> <li>Only IP addresses, no other fields</li> <li>Configure only, do not activate</li> </ul>"},{"location":"Linux/RHCSA/Practice%20Exams/A%20Cloud%20Guru/#configure-persistent-journals-on-both-servers","title":"Configure Persistent Journals on Both Servers","text":"<p>By default, the\u00a0<code>systemd</code>\u00a0journal logs to memory in RHEL 8, in the location\u00a0<code>/run/log/journal</code>. While this works fine, we'd like to make our journals\u00a0persistent\u00a0across reboots.</p> <p>Configure the\u00a0<code>systemd</code>\u00a0journal logs to be persistent on both servers, logging to\u00a0<code>/var/log/journal</code>.</p>"},{"location":"Linux/RHCSA/Practice%20Exams/A%20Cloud%20Guru/#managing-tuned-profiles-and-individual-processes","title":"Managing Tuned Profiles and Individual Processes","text":"<p>On the first server:</p> <ul> <li>Set a merged\u00a0<code>tuned</code>\u00a0profile using the the\u00a0<code>powersave</code>\u00a0and\u00a0<code>virtual-guest</code>\u00a0profiles.</li> <li>Start one\u00a0<code>stress</code>\u00a0process and adjust the\u00a0<code>niceness</code>\u00a0value to 19.</li> <li>Adjust the\u00a0<code>niceness</code>\u00a0value of the\u00a0<code>stress</code>\u00a0process to 10.</li> <li>Kill the\u00a0<code>stress</code>\u00a0process.</li> </ul>"},{"location":"Linux/RHCSA/Practice%20Exams/A%20Cloud%20Guru/#manage-scheduled-tasks-on-the-first-server","title":"Manage Scheduled Tasks on the First Server","text":"<p>Create one\u00a0<code>at</code>\u00a0task and one\u00a0<code>cron</code>\u00a0job on the first server:</p> <ul> <li>The\u00a0<code>at</code>\u00a0job will create a file containing the string \"The at job ran\" in the file named\u00a0<code>/web/html/at.html</code>, two minutes from the time you schedule it.</li> <li>The\u00a0<code>cron</code>\u00a0job will append to the\u00a0<code>/web/html/cron.html</code>\u00a0file every minute, echoing the\u00a0<code>date</code>\u00a0to the file.</li> </ul> <p>These files will be available via the web server on the first server after the \"Troubleshoot SELinux issues\" objective is completed.</p>"},{"location":"Linux/RHCSA/Practice%20Exams/A%20Cloud%20Guru/#configure-time-service-clients-for-both-servers","title":"Configure Time Service Clients for Both Servers","text":"<p>Time sync is not working on either of our servers. We need to fix that.</p> <p>Configure\u00a0<code>chrony</code>\u00a0to use the following server:</p> <p><code>server 169.254.169.123 iburst</code></p> <p>Make sure your work is persistent and check your work!</p>"},{"location":"Linux/RHCSA/Practice%20Exams/A%20Cloud%20Guru/#managing-the-system-bootloader","title":"Managing the System Bootloader","text":"<p>On server1, make the following changes:</p> <ul> <li>Increase the timeout using\u00a0<code>GRUB_TIMEOUT=10</code></li> <li>Add the following line:\u00a0<code>GRUB_TIMEOUT_STYLE=hidden</code></li> <li>Add\u00a0<code>quiet</code>\u00a0to the end of the\u00a0<code>GRUB_CMDLINE_LINUX</code>\u00a0line</li> </ul> <p>Validate the changes in\u00a0<code>/boot/grub2/grub.cfg</code>. Do not reboot the server.</p>"},{"location":"Linux/RHCSA/Practice%20Exams/A%20Cloud%20Guru/#managing-storage","title":"Managing Storage","text":""},{"location":"Linux/RHCSA/Practice%20Exams/A%20Cloud%20Guru/#add-swap-space-persistently-and-nondisruptive","title":"Add Swap Space Persistently and Nondisruptive","text":"<p>We need to increase the swap on the second server. We're going to use half of our first unused 2G disk for this additional swap space. Configure the swap space\u00a0non-destructively\u00a0and\u00a0persistently.</p>"},{"location":"Linux/RHCSA/Practice%20Exams/A%20Cloud%20Guru/#configure-autofs-for-home-directories","title":"Configure\u00a0<code>autofs</code>\u00a0for Home Directories","text":"<p>Configure\u00a0<code>autofs</code>\u00a0on the NFS_SERVER to mount the user home directories on the main server at\u00a0<code>/export/home</code>.</p> <ul> <li>On the NFS_SERVER, configure a NFS server with the following export:</li> </ul> <p><code>/home &lt;first_server_private_IP&gt;(rw,sync,no_root_squash)</code></p> <ul> <li>On the first server, configure\u00a0<code>autofs</code>\u00a0to mount the exported\u00a0<code>/home</code>\u00a0directory on the second server at\u00a0<code>/export/home</code>. Change the home directories for our six users (manny|moe|jack|marcia|jan|cindy) to be\u00a0<code>/export/home/&lt;user&gt;</code>\u00a0and test.</li> </ul>"},{"location":"Linux/RHCSA/Practice%20Exams/A%20Cloud%20Guru/#managing-containers","title":"Managing Containers","text":""},{"location":"Linux/RHCSA/Practice%20Exams/A%20Cloud%20Guru/#create-a-persistent-systemd-container-using-podman","title":"Create a Persistent\u00a0<code>systemd</code>\u00a0Container Using Podman","text":"<p>As the\u00a0<code>cloud_user</code>\u00a0user on the first server, create a\u00a0persistent\u00a0<code>systemd</code>\u00a0container\u00a0with the following:</p> <ul> <li>Image: registry.access.redhat.com/rhscl/httpd-24-rhel7</li> <li>Port mappings: 8080 on the container to 8000 on the host</li> <li>Persistent storage at\u00a0<code>~/web_data</code>, mounted at\u00a0<code>/var/www/html</code>\u00a0in the container</li> <li>Container name: web_server </li> </ul> <p>Test the container to make sure when you run a curl, it displays the contents of <code>~/web_data/test.txt</code></p>"},{"location":"Linux/RHCSA/Practice%20Exams/Practice%20Exam_1/","title":"Practice Exam 1","text":"<ol> <li>Create a user named\u00a0tom, this user shall have a user id of 777 and a nologin shell.</li> <li> <p>Create five users:\u00a0student, jerry, laura, mary and scott\u00a0with home directories in /home.</p> </li> <li> <p>Set their passwords to\u00a0RHCSA123$</p> </li> <li> <p>Make accounts for\u00a0mary and scott\u00a0to expire on December 31, 2030</p> <ol> <li>Verify with <code>chage -l $username</code></li> </ol> </li> <li> <p>Users\u00a0jerry and laura\u00a0should have their secondary groups set to the group database (Create the group if it doesn\u2019t exist).</p> </li> <li> <p>Add a group called developers and change the group ownership on /mnt/mobile to the group developers.</p> </li> <li> <p>Set read/write/execute permissions on the directory /mnt/mobile to the owner and group members and no permissions for others.</p> </li> <li> <p>Create a Directory called dir2 as a user\u00a0laura\u00a0in her home directory and set default ACLs (Access Control List) on it for user\u00a0mary\u00a0for read and write access.</p> </li> <li> <p>Modify the boot loader configuration and set the default autoboot timer value to 2 seconds.</p> <ol> <li>Save changes with <code>grub2-mkconfig -o /boot/grub2/grub.cfg</code></li> </ol> </li> <li> <p>Configure your firewall to accept all ftp traffic to the system.</p> </li> <li> <p>Give user tom sudo access (with no password prompts) to the following tools:</p> <ol> <li>yum.</li> <li>firewall-cmd</li> </ol> </li> <li> <p>Start Firewalld and make sure it starts automatically on boot.</p> </li> <li> <p>Create a volume group named vg_apps using the two disks /dev/sdb and /dev/sdc.</p> </li> <li> <p>Create a logical volume named lv_mobile with size of 7GB with mount point /mnt/mobile (create the mount point as well) formatted with xfs file system structure and a block size of\u00a0100MB.</p> <ol> <li>Create a file named pixel.txt in the mount point and Set the file system to automatically mount at each system reboot.</li> </ol> </li> <li> <p>Create a swap partition of size\u00a0100MB\u00a0on the disk /dev/sdd. Use its UUID and ensure it is activated after every system reboot. Make sure the swap partition is enabled as well.</p> </li> <li> <p>Create a standard partition of size\u00a0100MB\u00a0on any available disk and format it with the ext4 file system structure.</p> <ol> <li>Mount the file system on /mnt/ext4 (create the mount point if it doesn\u2019t exist) persistently using a LABEL=STANDARD. Also create a file called docker.txt in the mount point.</li> </ol> </li> <li> <p>Create a temporary directory named /run/hello and create temporary file inside /run/hello named temp1.txt</p> </li> <li> <p>Add a host\u00a0172.16.1.101\u00a0with an alias RHCSA.</p> </li> <li> <p>Create a new network connection \u201cmyhome-connection\u201d with the following (\u00a0ip address 192.168.0.1/24\u00a0 - gateway 192.168.0.254\u00a0 -\u00a0 DNS 192.168.0.254\u00a0).</p> </li> <li> <p>Using only the tar command, create a compressed archive using xz compression method of the /etc/yum.repos.d directory. Name the files repos.tar.xz and store the file in directory /root/compressed (create compressed if it\u2019s not there already).</p> </li> <li> <p>Install nfs server-2. Create the directory /media/nfs and Permanently mount the NFS-SHARE on server-1 on /media/nfs</p> </li> <li> <p>Let\u2019s assume there is an NFS share on 192.168.100.113 with the name of NFS_SHARE. Mount the NFS_SHARE on /files/mynfs on demand with a timeout of 10 seconds.</p> </li> </ol>"},{"location":"Linux/RHCSA/Practice%20Exams/Practice%20Exam_1/#practice-exam","title":"practice-exam","text":""},{"location":"Linux/RHCSA/Practice%20Exams/Practice%20Exam_2/","title":"Practice Exam 2","text":"<ol> <li> <p>Create three users\u00a0jerry,\u00a0kobe, and\u00a0lebron. All three users must change their password upon their first login.</p> <ol> <li>passwd -e</li> </ol> </li> <li> <p>Create a group named\u00a0nba\u00a0and\u00a0jerry,\u00a0kobe, and\u00a0lebron\u00a0to it. All members of the\u00a0nba\u00a0group should have access to install any package on the system.</p> </li> <li> <p>Create a directory named <code>/staples</code>\u00a0and make\u00a0lebron\u00a0the owner of this directory.</p> <ol> <li>All the three members of the\u00a0nba\u00a0group should have full permissions to the <code>/staples</code> directory.</li> </ol> </li> <li> <p>Create a new file named\u00a0<code>champion.txt</code>\u00a0in <code>/staples</code>.</p> </li> <li> <p>kobe\u00a0should be the owner of the file\u00a0champion.txt\u00a0and\u00a0lebron\u00a0should have read access to the\u00a0champion.txt\u00a0file.</p> </li> <li> <p>The\u00a0champion.txt\u00a0file should NOT be modified or deleted by any user on the system.</p> </li> <li> <p>Create a soft link to your tmp directory called mytemp in var. Also create a hard link in <code>/root</code>to <code>/etc/services</code>  , and name it ports.txt .</p> </li> <li> <p>Create a file named\u00a0file1\u00a0in <code>/root</code> and make sure this file can\u2019t be deleted. Furthermore, give jerry read access to\u00a0file1.</p> </li> <li> <p>Create a new user\u00a0Mary, with a nologin shell. Make a copy of the file <code>/etc/passwd\u00a0\u2018 called \u2018\u00a0/root/passwd.bk</code> and allow\u00a0Mary\u00a0to read and write to the file <code>/root/passwd.bk</code></p> </li> <li> <p>Find all the file names under <code>/etc</code> that begins with letter v and ends with .conf</p> </li> <li> <p>As the root user, create a crontab entry that runs every 2 minutes to update the timestamp of the `\u00a0/etc/passwd\u00a0\u2018 file.</p> </li> <li> <p>Set up a cron job as\u00a0jerry\u00a0user to search for log files in the <code>/var</code> directory and list them in <code>/var/log/logfiles</code>. This job should run every Monday at 1:20 am system time.</p> <ol> <li>ls -lR | grep *.log</li> </ol> </li> <li> <p>Permanently disable SELinux on your system and change your default target to multi-user target.</p> </li> <li> <p>The virtual machine should have an IP address of\u00a0192.168.100.113.\u00a0You should configure\u00a08.8.8.8\u00a0as the DNS server.</p> </li> <li> <p>Install and configure\u00a0Apache\u00a0web server. Change the Apache default directory to <code>/web/html</code> and make sure it works. Apache service should start automatically upon server reboots.</p> </li> <li> <p>Create a volume group named\u00a0myvg\u00a0that spans two of your three available secondary disks.</p> </li> <li> <p>Create two logical volumes named\u00a0mylv1\u00a0and\u00a0mylv2\u00a0with a size of\u00a0500MB\u00a0for each one of them.</p> </li> <li> <p>Create an ext4 filesystem on the\u00a0mylv1\u00a0logical volume and mount it permanently on the <code>/myfiles</code> directory with the label\u00a0FILES.</p> </li> <li> <p>Extend the logical volume\u00a0mylv2\u00a0to\u00a0500MB.</p> </li> <li> <p>Create a\u00a01 GB\u00a0swap partition using the third available secondary disk on your system. Mount it permanently using a UUID.</p> </li> <li> <p>Activate a\u00a0network-latency\u00a0tuned profile on your system.</p> </li> <li> <p>You forgot the root password on the\u00a0virtual machine. Reboot the VM and reset your root password.</p> </li> <li>Using\u00a0tempfiles, create a temporary directory named\u00a0mylogs\u00a0in <code>/var/log</code>\u00a0with world permissions.</li> <li>Set your timezone to <code>America/New_York</code>.\u00a0Make sure\u00a0NTP\u00a0is active and synchronized.</li> </ol>"},{"location":"Linux/RHCSA/Practice%20Exams/Practice%20Exam_2/#practice","title":"practice","text":""},{"location":"Linux/RHCSA/Practice%20Exams/Practice%20Exam_SVG/","title":"Setting up a Base Server","text":"<ul> <li>Install two servers using the minimal installation pattern. </li> <li>Use the names server1.example.com and server2.example.com and use DHCP to get an IP address from the local DNS server.</li> <li>Ensure that the partition for / is 15 GiB. Also create a 1 GiB swap partition. Do NOT register the servers with Red Hat.</li> </ul>"},{"location":"Linux/RHCSA/Practice%20Exams/Practice%20Exam_SVG/#resetting-the-root-password","title":"Resetting the Root Password","text":"<ul> <li>Use the appropriate solution to reset the root password on server2, assuming that you have lost the root password and you have no administrator access to the server anymore</li> </ul>"},{"location":"Linux/RHCSA/Practice%20Exams/Practice%20Exam_SVG/#configuring-a-repository","title":"Configuring a Repository","text":"<ul> <li>On both servers, create an ISO file based on the installationDVD. Mount this ISO file persistently and configure the servers to use the local ISO file as the repositories. After successfully completing this assignment, you should be able to install software on both servers.</li> </ul>"},{"location":"Linux/RHCSA/Practice%20Exams/Practice%20Exam_SVG/#managing-partitions","title":"Managing Partitions","text":"<ul> <li>On server1, use your virtualization software to increase the size of your primary disk in such a way that at least 10 GiB of unallocated disk space is available</li> <li>In the free disk space, create a 1 GiB partition and format it with the vfat filesystem. </li> <li>Make sure it is mounted persistently on the /winfile directory.</li> <li>Also create a 1 GiB swap partition and ensure it is mounted persistently</li> </ul>"},{"location":"Linux/RHCSA/Practice%20Exams/Practice%20Exam_SVG/#managing-lvm-logical-volumes","title":"Managing LVM Logical Volumes","text":"<ul> <li>Create a logical volume with the name myfiles. <ul> <li>Ensure it uses 8 MiB extents. </li> <li>Configure the volume to use 75 extents. </li> <li>Format it with the ext4 file system and ensure it mounts persistently on /myfiles</li> </ul> </li> <li>Increase the size of the / logical volume by 5 GiB</li> <li>If volume groups need to be created, create them as needed</li> </ul>"},{"location":"Linux/RHCSA/Practice%20Exams/Practice%20Exam_SVG/#creating-users-and-groups","title":"Creating Users and Groups","text":"<ul> <li>Create a user lisa. Ensure she has the password set to \"password\" and is using UID 1234. She must be a member of the secondary group sales</li> <li>Create a user myapp. Ensure this user cannot open an interactive shell</li> </ul>"},{"location":"Linux/RHCSA/Practice%20Exams/Practice%20Exam_SVG/#configure-a-shared-directory-for-collaboration","title":"Configure a Shared Directory for Collaboration","text":"<p>On the second server:</p> <p>Create a directory at\u00a0<code>/home/dba_docs</code>\u00a0with:</p> <ul> <li>Group ownership: dba_staff</li> <li>Permissions: 770</li> <li>Set-GID set</li> <li>Sticky bit set</li> </ul> <p>Create a link in each shared user's home directory to this directory, for easy access.</p> <p>Set the following ACLs:</p> <ul> <li>Read-only for\u00a0<code>jack</code>\u00a0and\u00a0<code>cindy</code></li> <li>Full permissions for\u00a0<code>marcia</code> </li> </ul>"},{"location":"Linux/RHCSA/Practice%20Exams/Practice%20Exam_SVG/#managing-permissions","title":"Managing Permissions","text":"<ul> <li>Create a shared group directory /sales and ensure that lisa is the owner of that directory. </li> <li>The owner and the group sales should have permissions to access this directory and read and write files in it. Other users should have no permissions at all.</li> <li>Ensure that any new file that is created in this directory is group-owned by the group sales automatically.</li> </ul>"},{"location":"Linux/RHCSA/Practice%20Exams/Practice%20Exam_SVG/#scheduling-jobs","title":"Scheduling Jobs","text":"<p>Schedule a job that writes \"hello folks\" to syslog every Monday through Friday at 2 AM. Make sure this job is executed as the user lisa.</p> <p>Create one\u00a0<code>at</code>\u00a0task and one\u00a0<code>cron</code>\u00a0job on the first server:</p> <ul> <li>The\u00a0<code>at</code>\u00a0job will create a file containing the string \"The at job ran\" in the file named\u00a0<code>/web/html/at.html</code>, two minutes from the time you schedule it. <code>{command} | at now +2 minutes</code></li> <li>The\u00a0<code>cron</code>\u00a0job will append to the\u00a0<code>/web/html/cron.html</code>\u00a0file every minute, echoing the\u00a0<code>date</code>\u00a0to the file.</li> </ul>"},{"location":"Linux/RHCSA/Practice%20Exams/Practice%20Exam_SVG/#managing-containers-as-services","title":"Managing Containers as Services","text":"<ul> <li>Create a container with the name mydb that runs the mariadb database as user lisa. </li> <li>The container should automatically be started at system start, regardless of whether or not user lisa is logging in. </li> <li>The container further should meet the following requirements: <ul> <li>The host directory /home/lisa/mydb is mounted on the container, directory /var/lib/mysql</li> <li>The container is accessible on host port 3206</li> <li>You do not have to create any databases in it.</li> </ul> </li> </ul>"},{"location":"Linux/RHCSA/Practice%20Exams/Practice%20Exam_SVG/#managing-automount","title":"Managing Automount","text":"<ul> <li>On server2, create the directories /homes/user1 and /homes/user2.</li> <li>Use NFS to share these directories and ensure the firewall does not block access to these directories. </li> <li>On server1, create a solution that automatically, on-demand mounts <code>server2:/homes/user1</code> on <code>/homes/user1</code>, and also that automatically, on-demand mounts <code>server2:/homes/user2</code> on <code>/homes/user2</code> when these directories are accessed</li> </ul>"},{"location":"Linux/RHCSA/Practice%20Exams/Practice%20Exam_SVG/#setting-time","title":"Setting Time","text":"<ul> <li>Configure server1 and server2 as an NTP client for pool.ntp.org</li> </ul>"},{"location":"Linux/RHCSA/Practice%20Exams/Practice%20Exam_SVG/#managing-selinux","title":"Managing SELinux","text":"<ul> <li>Ensure that the Apache web server is installed and configure it to offer access on port 82</li> <li>Copy the file <code>/etc/hosts</code> to <code>/tmp/hosts</code>. Next, move <code>/tmp/hosts</code> to the directory <code>/var/www/html/hosts</code> and ensure this file can be accessed by the Apache web server</li> </ul>"},{"location":"Linux/RHCSA/Practice%20Exams/Practice%20Exam_SVG/#managing-processes","title":"Managing Processes","text":"<ul> <li>Create a user a linda and open a shell as this user </li> <li>As linda, run two background processes sleep 600; one of them with the highest possible priority, the other one with the lowest possible priority </li> <li>Use the most efficient way to terminate all current sessions for user linda</li> </ul>"},{"location":"Linux/RHCSA/Practice%20Exams/Practice%20Exam_SVG/#logging","title":"Logging","text":"<p>Configure persistent logging to <code>/var/log/journal</code> on server 1</p>"},{"location":"Linux/RHCSA/Practice%20Exams/Practice%20Exam_SVG/#managing-the-system-bootloader","title":"Managing the System Bootloader","text":"<p>On server1, make the following changes:</p> <ul> <li>Increase the timeout using\u00a0<code>GRUB_TIMEOUT=10</code></li> <li>Add the following line:\u00a0<code>GRUB_TIMEOUT_STYLE=hidden</code></li> <li>Add\u00a0<code>quiet</code>\u00a0to the end of the\u00a0<code>GRUB_CMDLINE_LINUX</code>\u00a0line</li> </ul> <p>Validate the changes in\u00a0<code>/boot/grub2/grub.cfg</code>. Do not reboot the server.</p>"},{"location":"Linux/RHCSA/Practice%20Exams/Practice%20Exam_SVG/#practice-exam-practice","title":"practice-exam  #practice","text":""},{"location":"Linux/RHCSA/Practice%20Exams/Practice_Exam_C/","title":"Practice Exam C","text":"<ol> <li>Create user <code>student</code> with password password, and user root with password password.</li> <li>Set default values for new users. Make sure that any new user password has a length of at least six characters and must be used for at least three days before it can be reset<ol> <li>/etc/login.defs</li> </ol> </li> <li>Create users <code>edwin</code> and <code>santos</code> and make them members of the group sales as a secondary group membership. Also, create users serene and alex and make them members of the group account as a secondary group.</li> <li>Create shared group directories /groups/sales and /groups/account, and make sure these groups meet the following requirements:<ol> <li>Members of the group sales have full access to their directory.</li> <li>Members of the group account have full access to their directory.</li> <li>Users have permissions to delete only their own files, but alex is the general manager, so user alex has access to delete all users\u2019 files.</li> </ol> </li> <li>Create a 4-GiB volume group, using a physical extent size of 2 MiB. In this volume group, create a 1-GiB logical volume with the name myfiles and mount it persistently on /myfiles.</li> <li>Create a group sysadmins. Make users edwin and santos members of this group and ensure that all members of this group can run all administrative commands using sudo.</li> <li>Optimize your server with the appropriate profile that optimizes throughput.   </li> <li>Configure your server to synchronize time with serverabc.example.com, where serverabc is an alias to myserver.example.com. Note that this server does not have to exist to accomplish this exercise.</li> <li>Configure a web server to use the nondefault document root /webfiles. In this directory, create a file index.html that has the contents hello world and then test that it works.</li> <li>Configure your system to automatically start a mariadb container. This container should expose its services at port 3306 and use the directory /var/ mariadb-container on the host for persistent storage of files it writes to the /var directory.</li> <li>Configure your system such that the container created in step 13 is automatically started as a Systemd user container.</li> </ol>"},{"location":"Linux/RHCSA/Practice%20Exams/Practice_Exam_C/#practice-exam","title":"practice-exam","text":""},{"location":"Linux/RHCSA/Practice%20Exams/Practice_Exam_D/","title":"Practice Exam D","text":"<ol> <li>Create user student with password password, and user root with password password.</li> <li>Create a 500-MiB partition on your second hard disk, and format it with the Ext4 file system. Mount it persistently on the directory /mydata, using the label mydata.</li> <li>Set default values for new users. A user should get a warning three days before expiration of the current password. Also, new passwords should have a maximum lifetime of 120 days.</li> <li>Create users edwin and santos and make them members of the group <code>livingopensource</code> as a secondary group membership. Also, create users serene and alex and make them members of the group operations as a secondary group.</li> <li>Create shared group directories<code>/groups/livingopensource</code> and <code>/groups /operations</code>, and make sure the groups meet the following requirements<ul> <li>Members of the group <code>livingopensource</code> have full access to their directory.</li> <li>Members of the group operations have full access to their directory.</li> <li>Others has no access to any of the directories.</li> <li>Alex is general manager, so user <code>alex</code> has read access to all files in both directories and has permissions to delete all files that are created in both directories. <ul> <li>Just make Alex the own of the <code>operations</code> and <code>livingopensource</code> directories</li> </ul> </li> </ul> </li> <li>Create a 1-GiB swap partition and mount it persistently.</li> <li>Find all files that have the SUID permission set, and write the result to the file /root/suidfiles.<ol> <li><code>find / -perm /2000</code></li> </ol> </li> <li>Create a 1-GiB LVM volume group. In this volume group, create a 512-MiB swap volume and mount it persistently.</li> <li>Install a web server and configure it to listen on port 8080.</li> <li>Create a configuration that allows user edwin to run all administrative commands using sudo.</li> </ol>"},{"location":"Linux/RHCSA/Practice%20Exams/Untitled/","title":"Untitled","text":""},{"location":"Linux/RHCSA/Practice%20Exams/Untitled/#understand-and-use-essential-tools","title":"Understand and use essential tools","text":"<ul> <li> <p>Task 1 :     Find all setuid files on the system and save the list         find / -perm 2000 &gt; list.txt</p> </li> <li> <p>Task 2 :     Find all log messages in /var/log/messages that contain \"ACPI\", and export them to a file called /root/logs. Then archive all of /var/log and save it to /tmp/log_archive.tgz         grep ACPI /var/log/messages &gt; /root/logs tar -czvf /tmp/log_archive.tgz /var/log</p> </li> <li> <p>Task 3 :     Create tar files compressed with gzip and bzip2 of /home and extract them         Gzip:         tar -cfz home.tar.gz /home         tar -xfz home.tar.gz         BZip2         tar -cfj home.tar.bz2 /home         tar -xfj home.tar.bz2</p> </li> <li> <p>Task 4 :     Create an empty file hard1 under /tmp and display its attributes. Create hard links hard2 and hard3. Edit hard2 and observe the attributes. Remove hard1 and hard3 and list the attributes again         - cd /tmp          - touch /tmp/hard1         - ln hard1 hard2          - vim hard2         - ls -li hard 2         - </p> </li> </ul> <p>Task 5 : - Create an empty file soft1 under /root pointing to /tmp/hard2. Edit soft1 and list the attributes after editing. Remove hard2 and then list soft1     - ln -s /tmp/hard2 soft1     - ls -li soft1</p> <p>Task 6 : - Create a file <code>perm_file1</code> with read permissions for owner, group and other.      - touch perm_file1     - chmod 444 perm_file1 - Add an execute bit for the owner and a write bit for group and public.      - chmod u+x, g+w, o +w - Revoke the write bit from public and assign read, write, and execute bits to the three user categories at the same time.      - chmod o - w     - chmod 777     - You can also use <code>a</code>, to assign permissions to all users! - Revoke write from the owning group and revoke write and execute bits from public     - chmod g-w, o-w, o-x <code>perm_file1</code></p>"},{"location":"Linux/RHCSA/Practice%20Exams/Untitled/#create-simple-shell-scripts","title":"Create simple shell scripts","text":"<ul> <li> <p>Task 1 :     Create a bash script that display the hostname ,system information and the users that are currently logged in</p> </li> <li> <p>Task 2 :     Create a bash script that shows total count of the supplied arguments , value of the first argument, PID of the script and all the supplied arguments</p> </li> <li> <p>Task 3 :     Create a bash script that can create user10, user20 and user30 accounts with each account is create a message saying \" The account is created successfuly \" will be displayed otherwise the script will terminate . In case of a successful account creation assign the user account a password as their username</p> </li> <li> <p>Task 4:     Write a script that finds all the files owned by new_user and have size greater than 30KB and less than 50KB and store them in /tmp/</p> </li> <li> <p>Task 5 :     Write a script named backup.sh under /root which will search files less than 2M from /usr and store it in /root/backup</p> </li> <li> <p>Task 6 :     As a System Administrator you are responsible to take a backup of your /etc directory every night. Build a shell script to take a backup of the /etc/directory using the tar command. The backup script should be named as /root/backup.sh. Schedule this script to run at 11:00 PM every night \u2013 except Sundays.</p> </li> </ul>"},{"location":"Linux/RHCSA/Practice%20Exams/Untitled/#operate-running-systems","title":"Operate running systems","text":"<p>Task 1 : - Modify the GRUB timeout and make it 1 second instead of 5 seconds     - <code>vim /etc/default/grub</code>     - <code>grub2-mkconfig /boot/grub2/grub.cfg</code>     - To determin if the system is booted in BIOS or UEFI:         - <code>dmesg | egrep -i \"efi|bios\"</code></p> <p>Task 2 : - Terminate the boot process at an early stage to access a debug shell to reset the root password     - reboot now     - ctrl+e</p> <p>Task 3 :     Download the latest available kernel packages from the Red Hat Customer Portal and install them</p> <p>Task 4 : - Install the tuned service, start it and enable it for auto-restart upon reboot.      - <code>dnf install tuned</code>     - <code>systemctl enable --now tuned</code> - Display all available profiles and the current active profile.      - <code>tuned-adm list</code>     - <code>tuned-adm active</code> - Switch to one of the available profiles and confirm.     -  <code>tuned-adm profile balanced``     -</code> tuned-adm acticve<code>- Determine the recommended profile for the system and switch to it.      -</code>tuned-adm recommend<code>-</code>tuned-adm profile virtual-guest<code>- Deactivate tuning and reactivate it     -</code>tuned-adm off<code>-</code>tuned-adm profile virtual-guest`</p> <p>Task 5: - Launch the command <code>dd if=/dev/zero of=/dev/null</code> three times as a background job.  - Increase the priority of one of these.     - renice -n -10 - Change the priority of the same process again, but this time use the value -15. Observe the difference.     - renice -n -15 - Kill all the dd processes you just started     - pkill dd</p> <p>Task 6 : - Configure the journal to be persistent across system reboots.      - In /etc/systemd/journald.conf, ensure that Storage is set to auto.     - mkdir -p /var/log/journal     - reboot - Configure logrotate to keep ten old versions of log files     - vim /etc/logrotate.conf         - rotate 10</p> <p>Task 7: - Copy the /etc/hosts file to the /tmp directory on server2 using scp command.      - <code>scp /etc/hosts server2:/tmp</code> - Try to connect to server2 as user root and copy the /etc/passwd file to you home directory</p> <p>Task 8 : - Download and install the apache web service.  - Try to configure apache to log error messages through syslog using the facility local1. - Create a rule that send all messages that it receives from local1 (That used above) facility to /var/log/httpd-error.log  verify the last changed by accessing a page that does not exist</p>"},{"location":"Linux/RHCSA/Practice%20Exams/Untitled/#configure-local-storage","title":"Configure local storage","text":"<p>Task 1 : - Create a 2 GB gpt partition and format the partition with xfs and mount the device persistently     <pre><code> lsblk      =&gt; to list all the block device\n fdisk /dev/sdb\n press m   =&gt; list all the opts\n enter g   =&gt; to create a new gpt part \n enter n   =&gt; to add new part \n accept the default part\n accept the default starting sector\n For the ending sector , Enter +2G \n enter w   =&gt; to write table to disk and exit \n partprobe =&gt; to inform the os part table change  \n mkfs.xfs /dev/sdb1 \n blkid   =&gt; to grep the uuid \n mkdir /mnt/task1\n echo 'UUID=xxxx /mnt/task1 xfs defaults 0 0' &gt;&gt; /etc/fstab\n mount -a \n</code></pre> Task 2 :  - Assign partition type \"msdos\" to /dev/sdc for using it as an MBR disk. Create and confirm a 100MB primary partition on the disk</p> <pre><code>```bash\nsame steps created in task 1 expet the size and the type \"msdos\" \n  # enter o   =&gt; to create an MBR disk \n```\n</code></pre> <p>Task 3 : - Delete the sdb1 partition that was created in Task1 above      - When deleting a partition, make sure you UMOUNT     <pre><code>umount /mnt/test\nAdd comment to fstab\nfdisk {device}\nd\n</code></pre></p> <p>Task 4 : - Initialize one partition sdb1 (90MB) and one disk sdc (250MB) for use in LVM.  - Create a volume group called vgbook and add both physical volumes to it.  - Use the PE size of 16MB and list and display the volume group and the physical volumes</p> <p>Task 5:  - Create two logical volumes, lvol1 and lvbook1, in the vgbook volume group.   - Use 120MB for lvol1 and 192MB for lvbook1.   - Display the details of the volume group and the logical volumes</p> <p>Task 6 :  - Add another partition sdb2 of size 158MB to vgbook to increase the pool of allocatable space. - Initialize the new partition prior to adding it to the volume group.  - Increase the size of lvbook1 to 336MB. Display the basic information for the physical volumes, volume group, and logical volume</p> <p>Task 7 : - Rename lvol0 to lvbook2.  - Decrease the size of lvbook2 to 50MB using the <code>lvreduce</code> command and then add 32MB with the <code>lvresize</code> command.  - Remove both logical volumes.  - Display the summary for the volume groups, logical volumes, and physical volumes</p> <p>Task 8 : - Uninitialize all three physical volumes - sdb1, sdb2, and sdb - by deleting the LVM structural information from them.  - Use the pvs command for confirmation. - Remove the partitions from the sdd disk and verify that all disks are now in their original raw state</p> <p>Task 9 : -  Create a new logical volume (LV-A) with a size of 30 extents that belongs to the volume group VG-A (with a PE size of 32M). After creating the volume, configure the server to mount it persistently on /mnt</p> <p>Task 10 : -  Create 1 swap area in a new 40MB partition called sdc3 using the mkswap command. - Create another swap area in a 140MB logical volume called swapvol in vgfs.  - Add their entries to the <code>/etc/fstab</code> file for persistence.  - Use the UUID and priority 1 for the partition swap and the device file and priority 2 for the logical volume swap. Activate them and use appropriate tools to validate the activation</p>"},{"location":"Linux/RHCSA/Practice%20Exams/Untitled/#create-and-configure-file-systems","title":"Create and configure file systems","text":"<p>Task 1 :  - Create 2x100MB partitions on the /dev/sdb disk, initialize them separately with the Ext4 and XFS file system types  - Create mount points called<code>/ext4fs</code> and <code>/xfs1</code>  - Attach them to the directory structure, verify their availability and usage  - Mount them persistently using their UUIDS</p> <p>Task 2 : - Create a volume group called vgfs comprised of a 160MB physical volume created in a partition on the /dev/sdb disk.  - The PE size for the volume group should be set at 16MB.  - Create 2 logical volumes called ext4vol and xfsvol of size 80MB each and initialise them with the Ext4 and XFS file system types.  - Ensure that both file systems are persistently defined using their logical volume device filenames. - Create mount points /ext4fs2 and /xfsfs2, mount the file systems, and verify their availability and usage</p> <p>Task 3 : - Grow the size of the vgfs volume group that was created above by adding another disk to it. Extend the ext4vol logical volume along with the file system it contains by 40MB</p> <p>Task 4 :  - Create a directory called /common and export it to server in read/write mode. Ensure that NFS traffic is allowed through the firewall. Confirm the export</p> <p>Task 5 : - Mount the /common that exported in task 4 . Create a mount point called /local. Add the remote share to the file system table for persistence. Create a test file in the mount point and confirm the file creation on the NFS server</p> <p>Task 6 : Create users jeff, jack and group sgrp with GID 9999. add jeff and jack to this group. Create a directory /sdir with ownership and owning groups belong to root and sgrp, and set the setgid bit on /sdir</p> <p>Task 7: - Create a file under /tmp as jeff and try to delete it as jack. Unset the sticky bit on /tmp and try to erase the file again. Restore the sticky bit on /tmp</p>"},{"location":"Linux/RHCSA/Practice%20Exams/Untitled/#automount","title":"Automount","text":"<p>Task 1 : - Configure a direct map to automount the NFS share <code>/common</code> that is available from server2.  - Install the relevant software, create a local mount point /autodir, and set up AutoFS maps to support the automatic mounting.  - Note that /common is already mounted on the /local mount point on server1 via fstab. Ensure there is no conflict in configuration or functionality between the 2</p> <p>Task 2: - On server1 (NFS server), create a user account called user30 with UID 3000. Add the /home directory to the list of NFS shares so that it becomes available for remote mount.  - On server2 (NFS client), create a user account called user30 with UID 3000, base directory /nfshome, and no user home directory.  - Establish an indirect map to automount the remote home directory of user30 under /nfshome. Observe that the home directory of user30 is automounted under /nfshome when you sign in as user30</p> <ul> <li> <p>Task 3 :     Configura Autofs</p> <ul> <li>All Ldapuser2 home directory is exported via NFS, which is available on classroom.example.com (172.25.254.254) and your NFS-exports directory is\u00a0/home/guests/Ldapuser2,</li> <li>Ldapuser2's home directory is classroom.example.com:/home/guests/ldapuse2</li> <li>Ldapuser2's home directory should be automount autofs service.</li> <li>Home directories must be writable by their users. while you are able to log in as any of the user ldapuser1 through ldapuser20, the only home directory that is accessible from your system is ldapsuser2</li> </ul> </li> </ul>"},{"location":"Linux/RHCSA/Practice%20Exams/Untitled/#deploy-configure-and-maintain-systems","title":"Deploy configure and maintain systems","text":"<ul> <li> <p>Task 1 :     As Bob, create a once-off job that creates a file called /testresults/Hello.sh containing the text \"Hello World. This is Admin.\" in 2 days later</p> </li> <li> <p>Task 2:     Set the system time zone and configure the system to use NTP</p> </li> <li> <p>Task 3 :     Create a periodic job that appends the current date to the file ~/tracking every 5 minutes every Sunday and Wednesday between the hours of 3am and 4am. Remove the ability of bob to create cron jobs</p> </li> <li> <p>Task 4 :     Create a daily cron job at 4:27PM for the Derek user that runs cat /etc/redhat-release and redirects the output to /home/derek/release</p> </li> <li> <p>Task 5 :     Submit a job as jeff to run the date command at 11:30pm on March 31, 2022, and have the output and any error messages generated redirected to /tmp/date.out. List the submitted job and then remove it</p> </li> <li> <p>Task 6 :     Access the repositories that are available on the RHEL 8 image. Create a definition file for the repositories and confirm</p> </li> <li> <p>Task 7 :     Verify the integrity and authenticity of a package called dcraw located in the /mnt/AppStream/Packages directory on the installation image and then install it. Display basic information about the package, show files it contains, list documentation files, verify the package attributes and remove the package</p> </li> <li> <p>Task 8 :     Determine if the cifs-utils package is installed and if it is available for installation. Display its information before installing it. Install the package and display its information again. Remove the package along with its dependencies and confirm the removal</p> </li> <li> <p>Task 9 :     Perform management operations on a package group called system tools. Determine if this group is already installed and if it is available for installation. List the packages it contains and install it. Remove the group along with its dependencies and confirm the removal</p> </li> <li> <p>Task 10 :     Perform management operations on a module called postgresql. Determine if this module is already installed and if it is available for installation. Show its information and install the default profile for stream 10. Remove the module profile along with any dependencies and confirm its removal</p> </li> </ul>"},{"location":"Linux/RHCSA/Practice%20Exams/Untitled/#manage-basic-networking","title":"Manage basic networking","text":"<ul> <li> <p>Task 1 :     Create a connection profile for the new network interface on server using a text editing tool. Assign the IP 172.10.10.110/24 with gateway 172.10.10.1 and set it to autoactivate at system reboots. Deactivate and reactive this interface at the command prompt</p> </li> <li> <p>Task 2 :     Create a connection profile using the nmcli command for the new network interface that was added to server2. Assign the IP 172.10.10.120/24 with gateway 172.10.10.1, and set it to autoactivate at system reboot. Deactivate and reactivate this interface at the command prompt</p> </li> <li> <p>Task 3 :     Update the /etc/hosts file on both server1 and server2. Add the IP addresses assigned to both connections and map them to hostnames . Test connectivity from server to client and from client to server using their IP addresses and then their hostnames</p> </li> <li> <p>Task 4 :     Determine the current active zone. Add and activate a permanent rule to allow HTTP traffic on port 80, and then add a runtime rule for traffic intended for TCP port 443. Add a permanent rule to the internal zone for TCP port range 5901 to 5910. Confirm the changes and display the contents of the affected zone files. Switch the default zone to the internal zone and activate it</p> </li> <li> <p>Task 5 :     Remove the 2 permanent rules added above. Switch back to the public zone as the default zone, and confirm the changes</p> </li> <li> <p>Task 6 :     Set the system hostname to server1.example.com and alias server1. Make sure that the new hostname is reflected in the command prompt</p> </li> </ul>"},{"location":"Linux/RHCSA/Practice%20Exams/Untitled/#manage-users-and-groups","title":"Manage users and groups","text":"<ul> <li> <p>Task 1 :     Create three users (Derek, Tom, and Kenny) that belong to the instructors group. Prevent Tom's user from accessing a shell, and make his account expire 10 day from now</p> </li> <li> <p>Task 2 :     Add 3 new users alice, bob and charles. Create a marketing group and add these users to the group. Create a directory /marketing and change the owner to alice and group to marketing. Set permissions so that members of the marketing group can share documents in the directory but nobody else can see them. Give charles read-only permission. Create an empty file in the directory</p> </li> <li> <p>Task 3 :     Create bill with the default attributes in the useradd and login.defs files. Assign this user a password and show the line entries from all 4 authentication files</p> </li> <li> <p>Task 4 :     For jack change the login name to jacknew, UID to 2000, home directory to /home/jacknew, and login shell to /sbin/nologin. Display the line entry for user2new from the passwd for validation. Remove this user and confirm the deletion</p> </li> <li> <p>Task 5 :     Configure password aging for Derek using the chage command . Set the mindays to 7, maxdays to 28, and warndays to 5. Verify the new settings. Rerun the command and set account expiry to January 31, 2022</p> </li> <li> <p>Task 6 :     Configure password aging for using the PASSWD command. Set the mindays to 10, maxdays to 90, and warndays to 14, and verify the new settings. Set the number of inactivity days to 5 and ensure that the user is forced to change their password upon next login</p> </li> <li> <p>Task 7 : </p> <p>Create a group called linuxadm with GID 5000 and another group called dba sharing the GID 5000. Add Derek as a secondary member to group linuxadm</p> </li> <li> <p>Task 8 :     Change the linuxadm group name to sysadm and the GID to 6000. Modify the primary group for Derek to sysadm. Remove the sysadm group and confirm</p> </li> </ul>"},{"location":"Linux/RHCSA/Practice%20Exams/Untitled/#manage-security","title":"Manage security","text":"<ul> <li> <p>Task 1 :     Create a file acluser as jeff in /tmp and check if there are any ACL settings on the file. Apply access ACLs on the file for jeff for read and write access. Add jack to the file for full permissions. Remove all access ACLs from the file</p> </li> <li> <p>Task 2 :     Generate a password-less ssh key pair using RSA for jeff on server. Distribute the public key to client and attempt to log on to client from server. Show the log file message for the login attempt</p> </li> <li> <p>Task 3 :     Remove the sshd service rule from the runtime configuration on server and try to access the server from the client using the ssh command</p> </li> <li> <p>Task 4:     Create a directory sedir1 under /tmp and a file sefile1 under sedir1. Check the context on the directory and file. Change the SELinux user and type to user_u and public_content_t on both and verify</p> </li> <li> <p>Task 5 :     Add the current context on sedir1 to the SELinux policy database to ensure a relabeling will not reset it to its previous value. Next, you will change the context on the directory to some random values. Restore the default context from the policy database back to the directory recursively</p> <p>tip: chcon write the context to the file sys and not to the policy so everything is overwritten when the fs is relabeled where the original context is restored from the policy to the file sys so it's recommended to work with semanage</p> </li> <li> <p>Task 6 :     Add a non-standard port 8010 to the SELinux policy database for the httpd service and confirm the addition. Remove the port from the policy and verify the deletion</p> </li> <li> <p>Task 7 :     Create a file called sefile2 under /tmp and display its context. Copy this file to the /etc/default directory, and observe the change in the context. Remove sefile2 from /etc/default, and copy it again to the same destination, ensuring that the target file receives the source file's context</p> </li> <li> <p>Task 8 :     Display the current state of the Boolean nfs_export_all_rw. Toggle its value temporarily, and reboot the system. Flip its value persistently after the system has been back up</p> </li> </ul>"},{"location":"Linux/RHCSA/Practice%20Exams/Untitled/#manage-containers","title":"Manage containers","text":"<p>Task 1 : - Download the Apache web server container image (httpd 2.4) and inspect the container image.  - Check the exposed ports in the container image configuration</p> <p>Task 2 : - Run the httpd container in the background.  - Assign the name myweb to the container, verify that the container is running, stop the container and verify that it has stopped, and delete the container and the container image</p> <p>Task 3 :   - Pull the Apache web server container image (httpd 2.4) and run the container with the name webserver.   - Configure webserver to display content \"Welcome to container-based web server\".   - Use port 3333 on the host machine to receive http requests. Start a bash shell in the container to verify the configuration  -  Task 4 :  - Configure the system to start the webserver container at boot as a systemd service.   - Start/enable the systemd service to make sure the container will start at boot, and reboot the system to verify if the container is running as expected</p> <p>Task 5 : - Create a container logserver from an image rsyslog in server1 from registry.redhat.io -   Configure the container with systemd services by an existing user user10. -   Service name should be container-logserver, and configure it to start automatically across reboot. -   Configure your host journal to store all journal across reboot, copy all *.journal from /var/log/journal and all subdirectories to /home/user10/container_logserver -   Configure automount <code>/var/log/journal</code> from logserver (container) to /home/user10/container_logserver when container starts.</p>"},{"location":"Linux/RHCSA/Results/Round%20One/","title":"Round One","text":"<p>Passing score:          210 Your score:             200 Result: NO PASS</p>"},{"location":"Linux/RHCSA/Results/Round%20One/#objective-score","title":"OBJECTIVE: SCORE","text":""},{"location":"Linux/RHCSA/Results/Round%20One/#manage-basic-networking-100","title":"Manage basic networking: 100%","text":"<pre><code>- Configure IPv4 and IPv6 addresses\n-   Configure hostname resolution\n-   Configure network services to start automatically at boot\n-   Restrict network access using firewall-cmd/firewall\n</code></pre> <ul> <li>Is there a command that needs to be run after changing network settings? </li> <li>nmtui vs nmcli</li> </ul>"},{"location":"Linux/RHCSA/Results/Round%20One/#understand-and-use-essential-tools-89","title":"Understand and use essential tools: 89%","text":"<ul> <li>Access a shell prompt and issue commands with correct syntax</li> <li>Use input-output redirection (&gt;, &gt;&gt;, |, 2&gt;, etc.) -   Use grep and regular expressions to analyze text</li> <li>Access remote systems using SSH -   Log in and switch users in multiuser targets -   Archive, compress, unpack, and uncompress files using tar, star, gzip, and bzip2</li> <li>Create and edit text files</li> <li>Create, delete, copy, and move files and directories</li> <li>Create hard and soft links</li> <li>List, set, and change standard ugo/rwx permissions</li> <li>Locate, read, and use system documentation including man, info, and files in /usr/share/doc</li> </ul> <p>Operate running systems: 67% -   Boot, reboot, and shut down a system normally -   Boot systems into different targets manually -   Interrupt the boot process in order to gain access to a system -   Identify CPU/memory intensive processes and kill processes -   Adjust process scheduling -   Manage tuning profiles -   Locate and interpret system log files and journals -   Preserve system journals -   Start, stop, and check the status of network services -   Securely transfer files between systems</p> <p>Configure local storage: 25% -   List, create, delete partitions on MBR and GPT disks -   Create and remove physical volumes -   Assign physical volumes to volume groups -   Create and delete logical volumes -   Configure systems to mount file systems at boot by universally unique ID (UUID) or label -   Add new partitions and logical volumes, and swap to a system non-destructively</p> <p>Create and configure file systems: 50% -   Create, mount, unmount, and use vfat, ext4, and xfs file systems -   Mount and unmount network file systems using NFS -   Configure autofs -   Extend existing logical volumes -   Create and configure set-GID directories for collaboration -   Diagnose and correct file permission problems</p> <p>Deploy, configure and maintain systems: 62% -   Schedule tasks using at and cron -   Start and stop services and configure services to start automatically at boot -   Configure systems to boot into a specific target automatically -   Configure time service clients -   Install and update software packages from Red Hat Network, a remote repository, or from the local file system -   Modify the system bootloader</p> <p>Manage users and groups: 75% -   Create, delete, and modify local user accounts -   Change passwords and adjust password aging for local user accounts -   Create, delete, and modify local groups and group memberships -   Configure superuser access</p> <p>Manage security: 100% -   Configure firewall settings using firewall-cmd/firewalld -   Manage default file permissions -   Configure key-based authentication for SSH -   Set enforcing and permissive modes for SELinux -   List and identify SELinux file and process context -   Restore default file contexts -   Manage SELinux port labels -   Use boolean settings to modify system SELinux settings -   Diagnose and address routine SELinux policy violations</p>"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Labs/10.%20Securing%20Files%20With%20Permissions/","title":"10. Securing Files With Permissions","text":"<ol> <li>Create a shared group directory structure /data/profs and /data/students that meets the following conditions <ol> <li>Members of the groups have full read and write access to their directories, others has no permissions at all </li> </ol> </li> <li> <p>Modify default permission settings such that normal users have a umask that allows the user and group to write, create and execute files and directories while denying all other access to others</p> </li> <li> <p>mkdir -p</p> <ol> <li>chgrp</li> <li>chmod </li> </ol> </li> <li>Update the umask in /etc/bashrc</li> </ol>"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Labs/11.%20Managing%20Network%20Configuration/","title":"11. Managing Network Configuration","text":"<ol> <li>Set the hostname for your server to rhcsaserver.example.com </li> <li>Set your server to a fixed IP address that matches your current network configuration <ol> <li>Also set a second IP address 10.0.0.10/24 on the same network interface</li> </ol> </li> <li>Enable host name resolution for your local server hostname </li> <li>Reboot and verify your network is still working with the new settings</li> </ol>"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Labs/11.%20Managing%20Network%20Configuration/#answers","title":"Answers","text":"<ol> <li>nmtui</li> <li>nmtui</li> <li>vim /etc/hosts/<ol> <li>![[Pasted image 20220916060214.png]]</li> </ol> </li> <li>reboot</li> </ol>"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Labs/12.%20Managing%20Software/","title":"12. Managing Software","text":"<ol> <li>Ensure your system is using a repository for base packages as well as application streams </li> <li>Find the package that contains the seinfo program file and install it</li> <li>Download the http package from the repositories without installing it, and query to see if there are any scripts in it</li> </ol>"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Labs/12.%20Managing%20Software/#answers","title":"Answers","text":"<ol> <li><code>dnf repolist</code> to verify </li> <li>`dnf search all seinfo</li> <li><code>cd /repo/AppStream/Packages</code><ol> <li><code>rpm -qp --scripts hhtpd-</code></li> </ol> </li> </ol>"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Labs/13.%20Observing%20Processes/","title":"13. Observing Processes","text":"<ol> <li>Use the appropriate utilities to find out if your machine is in good shape. top</li> </ol>"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Labs/14.%20Managing%20Processes/","title":"14. Managing Processes","text":"<ol> <li>Create a user a linda and open a shell as this user </li> <li>As linda, run two background processes sleep 600; one of them with the highest possible priority, the other one with the lowest possible priority </li> <li>Use the most efficient way to terminate all current sessions for user linda</li> </ol>"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Labs/14.%20Managing%20Processes/#answers","title":"Answers","text":"<ol> <li>Self Explanatory</li> <li>nice -n 19 sleep 600 &amp;; nice -n -20 sleep 600 &amp;</li> <li>pkill -u linda</li> </ol>"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Labs/15.%20Managing%20Systemd%20Units/","title":"15. Managing Systemd Units","text":"<ol> <li>Make sure the http service is automatically started </li> <li>Edit its configuration such that on failure, it will continue after1  minute</li> </ol>"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Labs/15.%20Managing%20Systemd%20Units/#answers","title":"Answers","text":"<ol> <li>systemctl enable httpd</li> <li>systemctl edit httpd.service</li> </ol>"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Labs/16.%20Scheduling%20Tasks/","title":"16. Scheduling Tasks","text":"<ol> <li>Ensure the systemd timer that cleans up tmp files is enabled</li> <li>Run a cron job that will issue the command touch /tmp/cronfile 5 minutes from now </li> <li>Use at to schedule a job to power off your system at a convenient time later today</li> </ol>"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Labs/16.%20Scheduling%20Tasks/#answers","title":"Answers","text":"<ol> <li><code>systemctl list-unit-files -t timer</code><ol> <li>`systemctl cat systemd-tmpfiles-clean.timer</li> <li>This is a static service so we don't need to do anything here. </li> </ol> </li> <li>`06 15 * * * touch /tmp/cronfile</li> <li>![[Pasted image 20220918050331.png]]</li> </ol>"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Labs/17.%20Configuring%20Logging/","title":"17. Configuring Logging","text":"<ol> <li>Make sure the systemd journal is logged persistently </li> <li>Create an entry in rsyslog that writes all messages with a severity of error or higher to /var/log/error </li> <li>Ensure that /var/log/error is rotated on a monthly basis, and the last 12 logs are kept before they are rotated out</li> </ol>"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Labs/17.%20Configuring%20Logging/#answers","title":"Answers","text":"<ol> <li>`vim /etc/systemd/journald.conf<ol> <li>Make sure storage is set to auto</li> <li>![[Pasted image 20220918050824.png]]</li> </ol> </li> <li>`vim /etc/rsyslog.conf<ol> <li>![[Pasted image 20220918050936.png]]</li> <li>`systemctl restart rsyslog.service</li> </ol> </li> <li>`cd /etc/logrotate.d<ol> <li>Copy one of the files as a template and name it <code>error</code></li> <li>![[Pasted image 20220918051252.png]]</li> </ol> </li> </ol>"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Labs/19.%20Managing%20LVM/","title":"19. Managing LVM","text":"<p>To perform the tasks in this lab, add a new 10GiB disk to your virtual machine 1. Create an LVM logical volume with the name Ivdb a and a size of 1 GiB. Also create the VG and PV that are required for this LV  2. Format this LV with the XFS filesystem and mount it persistently on /mounts/lvdb</p>"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Labs/21.%20Managing%20The%20Boot%20Procedure/","title":"21. Managing The Boot Procedure","text":"<ol> <li>Configure your system to boot in a multi-user target by default </li> <li>Persistently remove the options that hide startup messages while booting</li> </ol>"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Labs/21.%20Managing%20The%20Boot%20Procedure/#answers","title":"Answers","text":"<ol> <li>systemctl default multi-user.target</li> <li>vim /etc/default/grub<ol> <li>Remove rhbg and quiet from the CMDLINE line</li> <li>![[Pasted image 20220918052621.png]]</li> <li>`grub2-mkconfig -o /boot/grub2/grub.cfg</li> </ol> </li> </ol>"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Labs/23.%20Shell%20Scripts/","title":"23. Shell Scripts","text":"<ol> <li>Write a script that makes a copy of each file that has the *. txt extension. The copy should be named filename.txt.bak. After making the copy, the script should move it to the /tmp directory </li> <li>While running the script, the directory where it should look for the files should be provided as an argument </li> <li> <p>If no argument was provided, the script should stop with exit code 9</p> <p>```bash</p> </li> </ol> <p>if [ -z $1 ] then     echo You need a directory as an argument.     exit 9 fi</p> <p>for i in $1/*.txt do     cp $i $i.bak     mv $i.bak /tmp done ```</p>"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Labs/23.%20Shell%20Scripts/#binbash","title":"!/bin/bash","text":""},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Labs/26.%20Managing%20SELinux/","title":"26. Managing SELinux","text":"<ol> <li>Configure the Apache web server to bind to port 82</li> <li>Use mv /etc/hosts /var/www/html/ and ensure that the file gets an SELinux context that makes it readable by the Apache web server</li> </ol>"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Labs/26.%20Managing%20SELinux/#answers","title":"Answers","text":"<pre><code>1. vim /etc/httpd/conf/httpd.conf\n2. Change the listen parameter to 82\n3. When you restart httpd, you will get an error message. To fix it, run the command: `semanage port -a -t http_port_t -p tcp 82\n4. restorecon -Rv /var/www/html\n</code></pre>"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Labs/27.%20Configuring%20a%20Firewall%20to%20ALlow%20Service%20Access/","title":"27. Configuring a Firewall to ALlow Service Access","text":"<ol> <li>Configure <code>firewalld</code> such that remote access to the SSH and FTP processes is allowed. Make sure the configuration is applied immediately as well as persistently</li> </ol>"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Labs/27.%20Configuring%20a%20Firewall%20to%20ALlow%20Service%20Access/#answers","title":"Answers","text":"<ol> <li><code>firewall-cmd --list-all</code> to verify. If they aren't being allowed, then run <ol> <li>`firewall-cmd --add-service ftp --permanent; firewall-cmd --add-service ftp --permanent </li> <li>Verify again with `firewall-cmd --list-all </li> </ol> </li> </ol>"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Labs/29.%20Configuring%20Time%20Services/","title":"29. Configuring Time Services","text":"<ol> <li>Configure your system to synchronize time with the servers in pool.ntp.org</li> </ol>"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Labs/29.%20Configuring%20Time%20Services/#answers","title":"Answers","text":"<ol> <li>`vim /etc/chrony.conf<ol> <li>![[Pasted image 20220918060017.png]]</li> </ol> </li> <li>`systemctl restart chronyd</li> </ol>"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Labs/31.%20Containers/","title":"31. Containers","text":"<ol> <li>Ensure that you have full access to the Red Hat container repositories </li> <li>Run a Mariadb container in Podman, which meets the following conditions <ol> <li>The container is started as a rootless container by user student </li> <li>The container must be accessible at host port 3206 </li> <li>The database root password should be set to password </li> <li>The container uses the name mydb </li> <li>A bind-mounted directory is accessible: the directory /home/student/mariadb on the host must be mapped to /var/lib/mysql in the container </li> </ol> </li> <li>The container must be configured such that it automatically starts as a user systemd unit upon start of the computer</li> </ol>"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Labs/31.%20Containers/#answers","title":"Answers","text":"<ol> <li>`podman login</li> <li>[[8-Attach persistent storage to a container]]</li> <li>[[7-Configure a container to start automatically as a systemd service]]</li> </ol>"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Labs/4.%20Using%20Essential%20Tools/","title":"4. Using Essential Tools","text":"<ol> <li>Locate the man page that shows how to set a password</li> <li>Use the man page for useradd and create a user with the name anna</li> <li>Set the password for user anna to <code>password</code></li> <li>Use vim to create a file with the name users, and make sure that it contains the names alex, alexander, linda, and belinda on separate lines.</li> </ol>"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Labs/4.%20Using%20Essential%20Tools/#answers","title":"Answers","text":"<ol> <li><code>apropos -k password</code></li> <li><code>useradd anna</code></li> <li><code>passwd anna</code></li> <li><code>vim users</code></li> </ol>"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Labs/5.%20Understanding%20The%20Bash%20Shell/","title":"5. Understanding The Bash Shell","text":"<ol> <li>Set a variable color to the value of red, and ensure that this setting is available every time your current user account logs in</li> <li>Also create am alias that runs the commands <code>ls -ltr</code> while executing the <code>dir</code> command</li> <li>Ensure that Bash History file can grow to a max size of 2500 entries.</li> </ol>"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Labs/5.%20Understanding%20The%20Bash%20Shell/#answers","title":"Answers","text":"<ol> <li><code>vim .bash_profile</code></li> <li>`alias dir='ls -ltr'</li> <li>`export HISTFILESIZE=2500</li> <li>Update with <code>source .bash_profile</code></li> </ol>"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Labs/6.%20Essential%20File%20Management%20Tools/","title":"6. Essential File Management Tools","text":"<ol> <li>Use tar to create a compressed archive of all files in the /etc and /opt directories. Write this archive to your home directory</li> <li>Create a symbolic link to the archive you've just created in the /tmp directory</li> <li> <p>Remove the archive from your home directory. What happens to the symbolic link?</p> </li> <li> <p>`tar -cvf lab.tar /etc /opt ; gzip lab.tar</p> <ol> <li>Shorter Version - `tar -czvf lab.tar /etc /opt </li> </ol> </li> <li>`ln -s /root/lab.tar.gz .</li> <li>The link dies :( </li> </ol>"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Labs/7.%20Working%20with%20Text%20Files/","title":"7. Working with Text Files","text":"<ol> <li>Use head and tail to display the fifth line of the file /etc/passwd </li> <li>Use sed to display the fifth line of the file /etc/passwd (-n 5p) </li> <li>Use awk in a pipe to filter the last column out of the results of the command ps aux '{ print $NF) </li> <li>Use grep to show the names of all files in /etc that have lines that contain the text 'root' as a word</li> <li>Use grep to show all lines from all files in /etc that contain exactly 3 characters </li> <li> <p>Use grep to find all files that contain the string \"alex\", but make sure that \"alexander\" is not included in the result</p> </li> <li> <p>[root@RHCSA-MAIN ~]# head -5 /etc/passwd | tail -1</p> </li> <li>sed -n 5p /etc/passwd</li> <li>ps aux | awk {print}</li> <li>ps aux | awk '{print $NF}'</li> <li>grep '^...$' * 2&gt;/dev/null</li> <li>grep '^alex*' * 2&gt;/dev/null</li> </ol>"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Labs/8.%20Configuring%20Sudo/","title":"8. Configuring Sudo","text":"<ol> <li>Use useradd linda to create a user linda </li> <li>Create a sudo configuration that allows linda to perform common user management tasks <ol> <li>Allow using useradd, usermod and userdel Allow changing passwords, but not the password for user root </li> </ol> </li> <li>Ensure that the user only needs to enter a password for sudo operations every 60 minutes</li> </ol>"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Labs/8.%20Configuring%20Sudo/#answers","title":"Answers","text":"<ol> <li>useradd linda</li> <li>vim /etc/sudoers.d/linda<ol> <li>![[Pasted image 20220915054918.png]]</li> </ol> </li> <li>visudo<ol> <li>![[Pasted image 20220915061048.png]]</li> </ol> </li> </ol>"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Labs/9.%20Manage%20Users%20and%20Groups/","title":"9. Manage Users and Groups","text":"<ol> <li>Make sure that new users require a password with a maximal validity of 90 days </li> <li>Ensure that while creating users, an empty file with the name newfile is created to their home directory </li> <li>Create users anna, audrey, linda, and lisa </li> <li>Set the passwords for anna and audrey to 'password', disable the passwords for linda and lisa </li> <li>Create the groups profs and students, and make users anna and audrey members of profs, and linda and lisa members of students</li> </ol>"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Labs/9.%20Manage%20Users%20and%20Groups/#answers","title":"Answers","text":"<ol> <li>`vim /etc/login.defs<ol> <li>![[Pasted image 20220915060830.png]]</li> </ol> </li> <li>`touch newfile /etc/skel/</li> <li>`for i in anna audrey linda lisa; do useradd $i; done</li> <li>`for i in lisa linda; do passwd -l $i; done </li> <li><code>usermod -aG GROUP USER</code></li> </ol>"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%201/2.%20Understand%20and%20Use%20Essential%20Tools/","title":"Basic Shell Skills","text":""},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%201/2.%20Understand%20and%20Use%20Essential%20Tools/#understanding-commands","title":"Understanding Commands","text":"<ul> <li>The anatomy of a command:<ol> <li>Command - <code>ls</code></li> <li>Options - <code>-l</code></li> <li>Arguments <code>/etc</code></li> </ol> </li> </ul> <p>There are 3 kinds of commands: 1. Alias - Command that the user can define as needed.  2. Internal Command - Command that is part of the shell itself and does not have to be loaded separately. 3. External Command - Command that exists as an executable file on the disk of the computer. To find external commands, use the <code>$PATH</code> variable.</p>"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%201/2.%20Understand%20and%20Use%20Essential%20Tools/#use-input-output-redirection","title":"Use Input-Output Redirection","text":"<ul> <li>&gt; (same as 1&gt;) - Redirects STDOUT. If redirection is to a file, the current contents of</li> <li>&gt;&gt; (same as 1&gt;&gt;) - Redirects STDOUT. If output is written to a file, the output is</li> <li>2&gt; - Redirects STDERR.</li> <li>2&gt;&amp;1 - Redirects STDERR to the same destination as STDOUT. Notice that this has to be used in combination with normal output redirection, as in ls whuhiu &gt; errout 2&gt;&amp;1.</li> <li>&lt; (same as 0&lt;) - Redirects STDIN.</li> </ul>"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%201/2.%20Understand%20and%20Use%20Essential%20Tools/#history","title":"History","text":"<ul> <li>!number - Execute a command with a specific number from history.</li> <li>!sometext -  Execute the last command that starts with <code>sometext</code>. Notice that this is a potentially dangerous command because the command that was found is executed immediately! </li> <li>history -c - Clear history completely</li> </ul> <p>## Vim   Vim has two modes:   1. Command Mode   2. Input Mode</p> <ul> <li>Esc - Switches from input mode to command mode. Press this key before typing any command.</li> <li>i, a - Switches from command mode to input mode at (i) or after (a) the current cursor position.</li> <li>o - Opens a new line below the current cursor position and goes to input mode</li> <li>:wq-  Writes the current file and quits.</li> <li>:q! - Quits the file without applying any changes. The ! forces the command to do its work. Add the ! only if you really know what you are doing.</li> <li>:w {filename}Writes the current file with a new filename. </li> <li>dd - Deletes the current line.  </li> <li>yy - Copies the current line.  </li> <li>p - Pastes the current selection.</li> <li>v - Enters visual mode, which allows you to select a block of text using the arrow keys. Use d to cut the selection or y to copy it.</li> <li>Ctrl -r - Undoes the last command. Repeat as often as necessary. Redoes the last undo.  </li> <li>gg - Goes to the first line in the document.  </li> <li>G - Goes to the last line in the document.</li> <li>/text - Searches for text from the current cursor position forward.</li> <li>?text - Searches for text from the current cursor position backward.</li> <li>^ - Goes to the first position in the current line.</li> <li>$ - Goes to the last position in the current line.</li> <li>!ls - Adds the output of ls (or any other command) in the current file.</li> <li>:%s/old/new/g - Replaces all occurrences of old with new.</li> </ul>"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%201/2.%20Understand%20and%20Use%20Essential%20Tools/#environment-configuration-files","title":"Environment Configuration Files","text":"File Explanation <code>/etc/profile</code> This is the generic file that is processed by all users upon login. It is executed when you first log in. This file provides values for your path in addition to setting environment variables for such things as the location of your mailbox and the size of your history files. Finally, /etc/profile gathers shell settings from configuration files in the /etc/profile.d directory. <code>/etc/bashrc</code> This file is processed when sub-shells are started. This executes for every user who runs the bash shell each time a bash shell is opened. It sets the default prompt and may add one or more aliases. Values in this file can be overridden by information in each user\u2019s ~/.bashrc file. <code>~/.bash_profile</code> In this file, user-specific login shell variables can be defined. This is used by each user to enter info that is specific to his or her use of the shell. It is executed only once-- when the user logs in. <code>~/.bashrc</code> In this user-specific file, subshell variables can be defined. This contains the information that is specific to your bash shells. It is read when you log in and also each time you open a new bash shell. This is the best location to add aliases so that your shell picks them up."},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%201/2.%20Understand%20and%20Use%20Essential%20Tools/#login-vs-subshell","title":"Login vs subshell","text":"<ul> <li>Login Shell - The first shell that is opened for a user after the user has logged in.</li> <li>Subshell - From the login shell, a user may run scripts, which will start a subshell of that login shell.</li> </ul>"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%201/2.%20Understand%20and%20Use%20Essential%20Tools/#displaying-messages-during-login","title":"Displaying Messages During Login","text":"<ul> <li>/etc/motd - Messages in /etc/motd display after a user has successfully logged in to a shell. (Note that users in a graphical environment do not see its contents after a graphical login.) Using /etc/motd can be a convenient way for system administrators to inform users about an issue or a security policy, for example.</li> <li>/etc/issue - The contents of this file display before the user logs in. Using this file provides an excellent means of specifying specific login instructions to users who are not logged in yet.</li> </ul>"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%201/2.%20Understand%20and%20Use%20Essential%20Tools/#finding-help","title":"Finding Help","text":""},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%201/2.%20Understand%20and%20Use%20Essential%20Tools/#man","title":"man","text":"<p>The most helpful parts of a man page are at the bottom. You will find actual examples, and the See Also section. </p> <p>Use <code>man -k</code> to search the mandb. To update the mandb, just type ``mandb</p> <p>Man pages are categorized in different sections. - 1: Executable programs or shell commands - 5: File formats and conventions - 8: System Admin Commands</p>"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%201/2.%20Understand%20and%20Use%20Essential%20Tools/#lab","title":"Lab","text":"<ol> <li>Modify your shell environment so that on every subshell that is started, a variable is set. The name of the variable should be COLOR, and the value should be set to red. Verify that it is working.<ol> <li><code>export COLOR=red</code> to ~/.bashrc</li> <li>Create a script that echos $COLOR, and the output should be <code>RED</code></li> </ol> </li> <li>Use the appropriate tools to find the command that you can use to set the system time 1 minute ahead.<ol> <li><code>man -k time |grep set</code></li> </ol> </li> <li>From your home directory, type the command <code>ls -al wergihl *</code> and ensure that errors as well as regular output are redirected to a file with the name <code>/tmp/lsoutput</code>.<ol> <li><code>ls -al dkjsdk* &amp;&gt; /tmp/lsoutput</code></li> </ol> </li> <li>Locate the man page that shows how to set a password.<ol> <li><code>man -k passwd</code></li> </ol> </li> <li>Use globbing and <code>ls</code> to show all files in /etc that have a number in their name.<ol> <li>`ls -ld  [0-9]</li> </ol> </li> <li>Use <code>ls -l</code> to display the results page by page.</li> </ol>"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%201/3.%20Essential%20File%20Management%20Tools/","title":"File System Hierarchy","text":"<ul> <li>/  - Specifies the root directory. This is where the file system tree starts.</li> <li>/boot - Contains all files and directories that are needed to boot the Linux kernel.</li> <li>/dev - Contains device files that are used for accessing physical devices. This directory is essential during boot.</li> <li>/etc - Contains configuration files that are used by programs and services on your server. This directory is essential during boot.</li> <li>/home - Used for local user home directories.</li> <li>/media, /mnt - Contain directories that are used for mounting devices in the file system tree.</li> <li>/opt - Used for optional packages that may be installed on your server.</li> <li>/proc - Used by the proc file system. This is a file system structure that gives access to kernel information.</li> <li>/root - Specifies the home directory of the root user.</li> <li>/run - Contains process and user-specific information that has been created since the last boot.</li> <li>/srv - May be used for data by services like NFS, FTP, and HTTP.</li> <li>/sys - Used as an interface to different hardware devices that are managed by the Linux kernel and associated processes.</li> </ul>"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%201/3.%20Essential%20File%20Management%20Tools/#finding-files","title":"Finding Files","text":""},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%201/3.%20Essential%20File%20Management%20Tools/#locate","title":"Locate","text":"<p>If you're going to use this, make sure you have a cron job set up to update the database manually</p>"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%201/3.%20Essential%20File%20Management%20Tools/#find","title":"Find","text":"<p>One of the most powerful tools in Linux. You can use the\u00a0<code>find</code>\u00a0command to search for files and directories based on their permissions, type, date, ownership, size, and more. <pre><code># Search for a file named\u00a0`document.pdf`\u00a0in the\u00a0`/home/linuxize`\u00a0directory\nfind /home/linuxize -type f -name document.pdf\n</code></pre></p> <p>The <code>exec</code> option lets us run commands on whatever file we just found. <pre><code># Search for a file named\u00a0`document.pdf`\u00a0in the\u00a0`/home/linuxize`\u00a0directory, and then change its permissions. \nfind /home/linuxize -type f -name document.pdf -exec chmod 0755 {} \\;\n</code></pre> The <code>{}</code> is the results placeholder, and the <code>;</code> is the delimiter. The <code>\\</code> is just used to escape it </p>"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%201/3.%20Essential%20File%20Management%20Tools/#mounts","title":"Mounts","text":"<p>Linux file system is presented as one hierarchy, with the root directory (/) as its starting point. This hierarchy may be distributed over dif- ferent devices and even computer systems that are mounted into the root directory.</p> <p>In the process of mounting, a device is connected to a specific directory, such that after a successful mount this directory gives access to the device contents.</p> <p>The mount command gives an overview of all mounted devices. To get this information, the /proc/mounts file is read, where the kernel keeps information about all current mounts. It shows kernel interfaces also, which may lead to a long list of mounted devices being displayed.</p> <ul> <li>df -Th  -   The -h option summarizes the output of the command in a human-readable way, and the -T option shows which file system type is used on the different mounts.</li> </ul>"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%201/3.%20Essential%20File%20Management%20Tools/#-findmnt-shows-mounts-and-the-relationship-that-exists-between-the-different-mounts-this-has-a-more-readable-output-than-mount","title":"-   findmnt -  shows mounts and the relationship that exists between the different mounts. This has a more readable output than mount","text":"<pre><code>[root@rhcsa9 ~]# findmnt\nTARGET                          SOURCE         FSTYPE  OPTIONS\n/                               /dev/nvme0n1p1 xfs     rw,relatime,seclabel,attr\n\u251c\u2500/proc                         proc           proc    rw,nosuid,nodev,noexec,re\n\u2502 \u2514\u2500/proc/sys/fs/binfmt_misc    systemd-1      autofs  rw,relatime,fd=31,pgrp=1,\n\u2502   \u2514\u2500/proc/sys/fs/binfmt_misc  binfmt_misc    binfmt_ rw,nosuid,nodev,noexec,re\n\u251c\u2500/sys                          sysfs          sysfs   rw,nosuid,nodev,noexec,re\n\u2502 \u251c\u2500/sys/kernel/security        securityfs     securit rw,nosuid,nodev,noexec,re\n\u2502 \u251c\u2500/sys/fs/cgroup              cgroup2        cgroup2 rw,nosuid,nodev,noexec,re\n\u2502 \u251c\u2500/sys/fs/pstore              pstore         pstore  rw,nosuid,nodev,noexec,re\n\u2502 \u251c\u2500/sys/fs/bpf                 none           bpf     rw,nosuid,nodev,noexec,re\n\u2502 \u251c\u2500/sys/fs/selinux             selinuxfs      selinux rw,nosuid,noexec,relatime\n\u2502 \u251c\u2500/sys/kernel/debug           debugfs        debugfs rw,nosuid,nodev,noexec,re\n\u2502 \u2502 \u2514\u2500/sys/kernel/debug/tracing tracefs        tracefs rw,nosuid,nodev,noexec,re\n\u2502 \u251c\u2500/sys/kernel/tracing         tracefs        tracefs rw,nosuid,nodev,noexec,re\n\u2502 \u251c\u2500/sys/kernel/config          configfs       configf rw,nosuid,nodev,noexec,re\n\u2502 \u2514\u2500/sys/fs/fuse/connections    fusectl        fusectl rw,nosuid,nodev,noexec,re\n\u251c\u2500/dev                          devtmpfs       devtmpf rw,nosuid,seclabel,size=1\n\u2502 \u251c\u2500/dev/shm                    tmpfs          tmpfs   rw,nosuid,nodev,seclabel,\n\u2502 \u251c\u2500/dev/pts                    devpts         devpts  rw,nosuid,noexec,relatime\n\u2502 \u251c\u2500/dev/hugepages              hugetlbfs      hugetlb rw,relatime,seclabel,page\n\u2502 \u2514\u2500/dev/mqueue                 mqueue         mqueue  rw,nosuid,nodev,noexec,re\n\u2514\u2500/run                          tmpfs          tmpfs   rw,nosuid,nodev,seclabel,\n  \u251c\u2500/run/vmblock-fuse           vmware-vmblock fuse.vm rw,relatime,user_id=0,gro\n  \u251c\u2500/run/user/1000              tmpfs          tmpfs   rw,nosuid,nodev,relatime,\n  \u2514\u2500/run/user/42                tmpfs          tmpfs   rw,nosuid,nodev,relatime,\n</code></pre>"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%201/3.%20Essential%20File%20Management%20Tools/#managing-files","title":"Managing Files","text":""},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%201/3.%20Essential%20File%20Management%20Tools/#wildcards","title":"Wildcards","text":"<ul> <li> <p>Asterisk * - Refers to an unlimited number of any characters.<code>ls *</code> , for instance, shows all files in the current directory (except those that have a name starting with a dot).</p> <ul> <li>STARTS WITH - abc*</li> <li>ENDS WITH - *abc</li> <li>CONTAINING - *abc*</li> </ul> </li> <li> <p>Question Mark? - Used to refer to one specific character that can be any character. <code>ls c?t</code> would match cat as well as cut.</p> </li> <li>[auo] - Refers to one character that may be selected from the range that is specified between square brackets. <code>ls c\\[auo\\]t</code> would match cat, cut, and cot.</li> </ul>"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%201/3.%20Essential%20File%20Management%20Tools/#absolute-vs-relative-pathnames","title":"Absolute vs Relative Pathnames","text":"<p>An absolute filename, or absolute pathname, is a complete path reference to the file or directory you want to work with. This pathname starts with the root directory, followed by all subdirectories up to the actual filename. No matter what your current directory is, absolute filenames will always work. An example of an absolute filename is /home/lisa/file1.</p> <p>A relative filename is relative to the current directory as shown with the pwd command. It contains only the elements that are required to get from the current directory up to the item you need. Suppose that your current directory is /home (as shown by the pwd command). When you refer to the relative filename lisa/file1, you are referring to the absolute filename /home/lisa/file1.</p>"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%201/3.%20Essential%20File%20Management%20Tools/#listing-files-and-directories","title":"Listing Files and Directories","text":"Command Use ls -l Shows a long listing, which includes information about file properties, such as creation date and permissions. ls -a Shows all files, including hidden files. ls -lrt Shows commands sorted on modification date. You\u2019ll see the most recently modified files last in the list. This is a very useful command. ls -d Shows the names of directories, not the contents of all directories that match the wildcards that have been used with the ls command. ls -R Shows the contents of the current directory, in addition to all of its subdirectories; that is, it Recursively descends all subdirectories."},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%201/3.%20Essential%20File%20Management%20Tools/#copying-files-and-directories","title":"Copying Files and Directories","text":"<p>Use <code>-a</code>with cp to keep all current permissions. So, to copy an exact state of your home directory and everything within it to the /tmp directory, use cp -a ~ /tmp.</p> <p>A special case when working with cp is hidden files. By default, hidden files are not copied over. There are three solutions to copy hidden files as well: - <code>cp /somedir/.* /tmp -</code>cp -a /somedir/ . - <code>cp -a /somedir/. .</code></p>"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%201/3.%20Essential%20File%20Management%20Tools/#links","title":"Links","text":""},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%201/3.%20Essential%20File%20Management%20Tools/#hard-links","title":"Hard Links","text":"<p>Linux stores administrative data about files in inodes. The inode is used to store all administrative data about files. Every file on Linux has an inode, and in the inode, important information about the file is stored.  It is interesting to know that an inode does not know which name it has; it just knows how many names are associated with the inode. These names are referred to as hard links.</p> <p>A file is just a collection of blocks. Every file has its own iNode, and every iNode has its own number. The filename is what points to this iNode. The symbolic link knows nothing about the iNode. It actually gets its own. </p> <p>![[Links.drawio.png]]</p>"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%201/3.%20Essential%20File%20Management%20Tools/#symbolic-links","title":"Symbolic Links","text":"<p>A symbolic link (also referred to as soft link) does not link directly to the inode but to the name of the file. This makes symbolic links much more flexible, but it also has some disadvantages. The advantage of symbolic links is that they can link to files on other devices, as well as on directories. The major disadvantage is that when the original file is removed, the symbolic link becomes invalid and does not work any longer.</p>"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%201/3.%20Essential%20File%20Management%20Tools/#creating-links","title":"Creating Links","text":"Command Explanation ln /etc/hosts . Creates a link to the file /etc/hosts in the current directory ln -s /etc/hosts . Creates a symbolic link to the file /etc/hosts in the current directory ln -s /home /tmp Creates a symbolic link to the directory /home in the directory /tmp"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%201/3.%20Essential%20File%20Management%20Tools/#archiving-and-compression","title":"Archiving and Compression","text":"<pre><code>ARCHIVING AND COMPRESSING ARE NOT THE SAME THING\n</code></pre>"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%201/3.%20Essential%20File%20Management%20Tools/#archiving-with-tar","title":"Archiving with Tar","text":"<p>To create an archive, you use <code>tar -cf flename.tar files-you-want-to-archive</code> . To see whats happening, use the <code>-v</code> option. To use tar, you must at least have read permissions.  To add a file to an archive, use the <code>-r</code> option. To update an existing archived file, use <code>-u</code>.  So, use  <code>tar -uvf /root/homes.tar /home</code> to write newer versions of all files in /home to the archive. To see the contents of an archive, sue <code>-t</code>, so <code>tar -tvf /root/homes.tar</code> to see the contents of the tar archive. To extract the contents of an archive, use <code>tar -xvf /archivename.tar</code>. This extracts the archive in the current directory. This might not be what you want. To get around this, you can : 1. cd to a new directory  2. Use the <code>-C /targetdir</code> option.      1. <code>` tar -xvf homes.tar -C /tmp  To extract a single file, use</code>tar -xvf /archivename.tar file-you-want-to-extract`</p> <p>For tar, ORDER matters. The -f flag must come last because it is expecting a file name. </p> Option Use c Creates an archive. v Shows verbose output while tar is working. t Shows the contents of an archive. z Compresses/decompresses the archive while creating it, by using gzip. j Compresses/decompresses the archive by using bzip2. x Extracts an archive. u Updates an archive; only newer files will be written to the archive. C Changes the working directory before performing the command. r Appends files to an archive."},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%201/3.%20Essential%20File%20Management%20Tools/#compression","title":"Compression","text":"<p>To compress use gzip. To uncompress, use gunzip</p>"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%201/3.%20Essential%20File%20Management%20Tools/#lab","title":"Lab","text":"<ol> <li>Log is user root. In the home directory of root, create one archive file that contains the contents of the <code>/home</code> directory and the <code>/etc</code> directory. Use the name <code>/root/essentials.tar</code>for the archive<ol> <li><code>tar -cf essentials.tar /home /etc</code></li> </ol> </li> <li>Copy this archive to the /tmp directory. Also create a hard link to this file in the / directory.<ol> <li><code>cp essentials.tar /tmp</code></li> <li><code>ln /tmp/essentials.tar .</code></li> </ol> </li> <li>Rename the file <code>/essentials.tar</code> to <code>/archive.tar</code>.<ol> <li><code>mv essentials.tar archive.tar</code></li> </ol> </li> <li>Create a symbolic link in the home directory of the user root that refers to  /archive.tar. Use the name link.tar for the symbolic link.<ol> <li><code>ln -s /archive.tar</code></li> </ol> </li> <li>Compress the /root/essentials.tar file.<ol> <li><code>gzip essentials.tar</code></li> </ol> </li> <li>Create a directory structure <code>/tmp/files/pictures</code>, <code>tmp/files/photos</code>, and <code>tmp/files/videos</code><ol> <li><code>mkdir -p /tmp/files/{pictures,photos,videos}</code></li> </ol> </li> <li>Copy all files that have a name starting with a,b,or c from /etc to /tmp/files<ol> <li><code>cd /etc</code></li> <li><code>cp -r [a-c]* /tmp/files/</code></li> </ol> </li> <li>From /tmp/files, move all files that have a name starting with an a, or b to <code>tmp/files/photos</code>, and files starting with a c to <code>tmp/files/videos</code><ol> <li><code>mv [a,b]* photos/</code></li> <li><code>mv c* videos/</code></li> </ol> </li> <li>Find all files in <code>/etc</code> that have a size smaller than 1000 bytes and copy those to <code>tmp/files/pictures</code><ol> <li><code>find /etc -type f -size -1000c -exec cp {} /tmp/files/pictures/  \\;</code></li> </ol> </li> <li>In <code>/tmp/files</code>, create a symbolic link to /var<ol> <li><code>ln -s /tmp/files</code></li> </ol> </li> <li>Create a compressed archive file of the <code>/home directory</code><ol> <li><code>tar -czvf home.tgz /home/</code></li> </ol> </li> <li>Extract this compressed archive with relative file names in <code>/tmp/archive</code><ol> <li><code>tar -xvf home.tar</code></li> </ol> </li> </ol>"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%201/4.%20Working%20With%20Text%20Files/","title":"4. Working With Text Files","text":""},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%201/4.%20Working%20With%20Text%20Files/#text-file-related-tools","title":"Text File Related Tools","text":"Command Explanation <code>less</code> Opens the text file in a pager, which allows for easy reading <code>cat</code> Dumps the contents of the text file on the screen <code>head</code> Shows the first ten lines of the text file <code>tail</code> Shows the last ten lines <code>cut</code> Used to filter specific columns or characters from a text file <code>sort</code> Sorts the contents of a text file <code>wc</code> Counts the number of lines, words, and characters in a file"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%201/4.%20Working%20With%20Text%20Files/#cut","title":"Cut","text":"<p>When you\u2019re working with text files, it can be useful to filter out specific fields. Imagine that you need to see a list of all users in the /etc/passwd file. In this file, several fields are defined, of which the first contains the name of the users who are defined.</p>"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%201/4.%20Working%20With%20Text%20Files/#command-anatomy","title":"Command Anatomy","text":"<ul> <li>d - Used to define the delimiter</li> </ul> <p>To display the first field of the <code>/etc/passwd</code> file, run <code>cut -d : -f 1 /etc/ passwd</code></p>"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%201/4.%20Working%20With%20Text%20Files/#sort","title":"Sort","text":"<p>By default, sort sorts in byte order. So an uppercase Zoo, would appear before lowercase apple This is not always helpful. - n - Sort in numeric order  - r - Reverse sort  - f - Ignore case. This will override sort's default byte sorting. </p>"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%201/4.%20Working%20With%20Text%20Files/#regex","title":"Regex","text":"<p>[!WARNING] Regular expressions and Globbing are NOT the same. Regular expressions are used to look for contents of files, and globbing is used to find filenames.</p> <p>[!TIP] Make sure to surround your regular expression in single quotes.</p> Expression Usage <code>\\^text</code> Matches line that starts with specified text. <code>text$</code> Matches line that ends with specified text. . Wildcard. (Matches any single character.) <code>\\[abc\\]</code> Matches a, b, or c. * Matches zero to an infinite number of the previous character. <code>\\\\{2\\\\}</code> Matches exactly two of the previous character. <code>\\\\{1,3\\\\}</code> Matches a minimum of one and a maximum of three of the previous character. <code>colou?r</code> Matches zero or one of the previous character. This makes the previous character optional, which in this example would match both color and colour."},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%201/4.%20Working%20With%20Text%20Files/#examples","title":"Examples","text":"<p>``\"/web(/.*)?\"</p> <p>In this regular expression, the text /web is referred to. This text string can be followed by the regular expression (/.)?, which means zero or one (/.), which in fact means that it can be followed by nothing or (/.). The (/.) refers to a slash, which may be followed by an unlimited number of characters. To state it differently, the regular expression refers to the text /web, which may or may not be followed by any characters. <code>r.t</code> would match the strings rat, rot, and rut. <code>r[aou]t</code> matches the strings rat, rot, and rut. <code>re\\{2\\}d,</code>  would match reed, but not red.</p>"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%201/4.%20Working%20With%20Text%20Files/#grep","title":"Grep","text":"<p>This is the ultimate utility to use WITH regex</p> <p>[!TIP] When using grep with regular expression, wrap the regex in quotes.</p> Option Use -i Not case sensitive. Matches upper- and lowercase letters. -v Shows only lines that do not contain the regular expression. -r Searches files in the current directory and all subdirectories. -e Searches for lines matching more than one regular expression. -A \\&lt;number&gt; Shows \\&lt;number&gt; of lines after the matching regular expression. -B \\&lt;number&gt; Shows \\&lt;number&gt; of lines before the matching regular expression. -l Show ONLY matching filenames, and not the contents ### Examples <pre><code># Display all lines containing the string bash in /etc/passwd\ngrep bash /etc/passwd\n\n#Display the lines that do NOT contain the string 'nologin'\ngrep -v nologin /etc/passwd\n\n#Search for the string 'linuxize.com' in all files inside the /etc/directory\ngrep -r 'linuxize.com' /etc\n\n#Searh for the string linux at the beginning of the line in file.txt\ngrep '^linux' file.txt\n</code></pre> # Other Useful Text Processing Utilities ## Awk Comand Explanation ----------------------------------- ------------------------------------------- <code>awk '{ print $1 }' list</code> Print the first line of a file called list. <code>awk -F: ' {print $1}' /etc/passwd</code> Print the first field in /etc/passwd <code>awk -F : '/user/ { print $4 }' /etc/passwd</code> Search /etc/password for the term user in the 4th filed."},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%201/4.%20Working%20With%20Text%20Files/#sed","title":"Sed","text":"Command Explanation <code>sed -n 5p /etc/passwd</code> Print the 5th line from the /etc/passwd file <code>sed -i s/old-text/new-text/g ~/myfile</code> Replace the string old-text, with the string new-text, globally"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%201/4.%20Working%20With%20Text%20Files/#lab","title":"Lab","text":"<ol> <li>Describe two ways to show line 5 from the /etc/passwd file.<ol> <li>sed</li> <li>head, then tail</li> </ol> </li> <li>How would you locate all text files on your server that contain the current IP address? Do you need a regular expression to do this?<ol> <li><code>grep -rs '192.168.213.129' *</code></li> </ol> </li> <li>You have just used the sed command that replaces all occurrences of the text <code>Administrator</code> with <code>root</code>. Your Windows administrators do not like that very much. How do you revert?<ol> <li><code>sed -i s/root/Administrator/g ~/myfile</code></li> </ol> </li> <li>Assuming that in the <code>ps aux</code> command the fifth field contains information about memory utilization, how would you process the output of that command to show the process that has the heaviest memory utilization first in the results list?<ol> <li><code>ps aux --sort -%mem</code></li> <li><code>ps aux | sort -rk4</code></li> </ol> </li> <li>Which command enables you to filter the sixth column of ps aux output?<ol> <li><code>ps aux |awk '{print $6}'</code></li> </ol> </li> <li>How do you delete the sixth line from the file <code>~/myfile</code>?<ol> <li><code>sed '5d' myfile</code></li> </ol> </li> <li>Use <code>sed</code> to display the fifth line of the file <code>/etc/passwd</code>.<ol> <li><code>sed -n 5p /etc/passwd</code></li> </ol> </li> <li>Use <code>awk</code> in a pipe to filter the last column out of the results of the ps aux command<ol> <li><code>ps aux |awk '{print $(NF)}'</code></li> </ol> </li> <li>Use <code>grep</code> to show the names of all files in <code>/etc</code> that have lines containing the text root as a word. <ol> <li><code>grep '\\&lt;root\\&gt;' * 2&gt;/dev/null</code></li> </ol> </li> <li>Use <code>grep</code> to show all lines from all files in <code>/etc</code> that contain exactly 3 characters.<ol> <li><code>grep '^...$' * 2&gt;/dev/null</code></li> </ol> </li> <li>Use <code>grep</code> to find all files that contain the string \"alex\", but make sure that \"alexander\" is not included in the result. <ol> <li><code>grep '^alex$' *</code></li> </ol> </li> </ol>"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%201/5.%20Connecting%20To%20RHEL/","title":"Understanding The Root User","text":""},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%201/5.%20Connecting%20To%20RHEL/#working-on-local-consoles","title":"Working on Local Consoles","text":""},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%201/5.%20Connecting%20To%20RHEL/#console-vs-terminal","title":"Console vs Terminal","text":"<p>A console is the environment the user is looking at. A terminal is an environment that is opened on the consoles and provides access to a text shell. You can have multiple terminals open on a console, but you cannot have multiple consoles open in a terminal. </p>"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%201/5.%20Connecting%20To%20RHEL/#working-with-multiple-terminals","title":"Working with Multiple Terminals","text":"<p>Virtual terminals allow you to open six different terminal windows from the same console at the same time and navigate between them. Use <code>Alt-F1</code> through <code>Alt-F6</code> -   F1: Gives access to the GNOME Display Manager (GDM) graphical login -   F2: Provides access to the current graphical console -   F3: Gives access back to the current graphical session -   F4\u2013F6: Gives access to nongraphical consoles</p>"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%201/5.%20Connecting%20To%20RHEL/#pseudo-terminal-devices","title":"Pseudo Terminal Devices","text":"<p>For terminal windows that are started from a graphical environment, pseudo terminals are started. These pseudo terminals are referred to using numbers in the /dev/pts directory. So, the first terminal window that is started from a graphical environment appears as /dev/pts/1, the second terminal windows appears as /dev/pts/2, and so on.</p>"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%201/5.%20Connecting%20To%20RHEL/#booting-rebooting-and-shutting-down-systems","title":"Booting Rebooting, and Shutting Down Systems","text":"<p>To issue a proper reboot, you have to alert the Systemd process. To tell the Systemd process this has to happen, you can use a few commands: -   <code>systemctl reboot</code> or <code>reboot</code> -   <code>systemctl halt</code> or <code>halt</code> -   <code>systemctl poweroff</code> or <code>poweroff</code></p> <p>[!WARNING] To force a machine restart, run  <code>echo b &gt; /proc/syrq-trigger</code>  This should only be used as a last resort. </p>"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%201/5.%20Connecting%20To%20RHEL/#using-ssh-and-related-utilities","title":"Using SSH and Related Utilities","text":"<p>How SSH Works The ssh port is 22. On the remote server, the sshd service MUST be running. </p>"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%201/5.%20Connecting%20To%20RHEL/#securely-transferring-files","title":"Securely Transferring Files","text":"<p>To transfer files, you can use, <code>scp</code>, <code>rsync</code>, or <code>sftp</code>.</p>"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%201/5.%20Connecting%20To%20RHEL/#scp","title":"SCP","text":"<p>Copy the /etc/hosts file to the /tmp directory on server2 <code>scp /etc/hosts server2: /tmp</code></p> <p>Copy an entire subdirectory. <code>scp -r server2:/etc/ /tmp</code></p>"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%201/5.%20Connecting%20To%20RHEL/#sftp","title":"SFTP","text":""},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%201/5.%20Connecting%20To%20RHEL/#rsync","title":"RSYNC","text":"<p>The rsync command uses SSH to synchronize files between a remote directory and a local directory. The advantage of synchronizing files is that only differences need to be considered. So, for example, if you synchronize a 100-MiB file in which only a few blocks have changed since the previous sync, only the changed blocks will be synchronized. This approach is also known as a delta sync.</p>"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%201/5.%20Connecting%20To%20RHEL/#key-based-authentication-for-ssh","title":"Key Based Authentication for SSH","text":"<p>When using public/private key-based authentication, the user who wants to connect to a server generates a public/private key pair. The private key needs to be kept private and will never be distributed. The public key is stored in the home directory of the target user on the SSH server in the file .ssh/authorized_keys.</p>"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%201/5.%20Connecting%20To%20RHEL/#the-screen-command","title":"The Screen Command","text":"<p>[!TIP] This is not on the exam. </p> <p>The screen command is particularly useful when used from an SSH session. You can start a task that takes a long time from a screen session, detach from it, and attach to it later. The command continues running, even if you are going home and shut down your computer. The next day, you can easily attach to the screen session again to complete the task.</p>"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%201/6.%20User%20and%20Group%20Management/","title":"Understanding Different User Types","text":"<p>In regards to security, you are either a privileged or unprivileged.  </p> Command Explanation id Get info about a user account"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%201/6.%20User%20and%20Group%20Management/#using-su","title":"Using su","text":"<p><code>su</code> allows you to open a subshell as another user. <code>su -</code> opens a login shell and gives you access to their actual environment </p>"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%201/6.%20User%20and%20Group%20Management/#sudo","title":"Sudo","text":"<p>If a non-root user needs to perform a specific system administration task, the user does not need root access; instead, the system administrator can configure <code>sudo</code> to give that user administrator permissions to perform the specific task.</p>"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%201/6.%20User%20and%20Group%20Management/#how-to-add-a-user-to-the-wheel-group","title":"How to add a user to the wheel group?","text":"<ol> <li>Make the administrative user account a member of the group wheel by using <code>usermod -aG wheel user</code>.</li> <li>Type visudo and make sure the line %wheel ALL=(ALL) ALL is included.</li> </ol>"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%201/6.%20User%20and%20Group%20Management/#managing-user-accounts","title":"Managing User Accounts","text":""},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%201/6.%20User%20and%20Group%20Management/#system-vs-normal-accounts","title":"System vs Normal Accounts","text":"<ul> <li>Normal Accounts - The average user on the server. </li> <li>System Accounts - These are used by the services on the host. </li> </ul> <p>Properties for both of these accounts are stores in <code>/etc/passwd</code> and <code>/etc/shadow</code>. </p>"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%201/6.%20User%20and%20Group%20Management/#home-directories","title":"Home Directories","text":"<p>When creating home directories (which happens by default while you\u2019re creating users), the content of the \u201cskeleton\u201d directory is copied to the user home directory. The skeleton directory is <code>/etc/skel</code>, and it contains files that are copied to the user home directory at the moment this directory is created. These files will also get the appropriate permissions to ensure that the new user can use and access them.</p>"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%201/6.%20User%20and%20Group%20Management/#managing-user-properties","title":"Managing User Properties","text":"<p>Use <code>usermod</code> to modify user properties. When you\u2019re working with tools such as <code>useradd</code>, some default values are assumed. These default values are set in two configuration files: 1. <code>/etc/login.defs</code>     1. <code>MOTD_FILE:</code> Defines the file that is used as the \u201cmessage of the day\u201d file. In this file, you can include messages to be displayed after the user has successfully logged in to the server.     2. <code>ENV_PATH</code>: Defines the $PATH variable, a list of directories that should be searched for executable files after logging in.     3. <code>PASS_MAX_DAYS</code>, <code>PASS_MIN_DAYS</code>, and <code>PASS_WARN_AGE</code>: Define the default password expiration properties when creating new users.     4. <code>UID_MIN</code>: Indicates the first UID to use when creating new users.     5. <code>CREATE_HOME</code>: Indicates whether or not to create a home directory for new users. 2. <code>/etc/default/useradd</code></p>"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%201/6.%20User%20and%20Group%20Management/#password-properties","title":"Password Properties","text":"<p>You can use 2 commands to change password properties for users. 1. chage     1. Use <code>chage -l</code> to see current password management settings.     2. <code>chage {username}</code> to enter an interactive mode. 2. passwd</p> <pre><code># Set the password for the user linda to a minimal usage period of 30 days and an expiry after 90 days, where a warning is generated 3 days before expire.\npasswd -n 30 -w 3 -x 90 linda\n</code></pre>"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%201/6.%20User%20and%20Group%20Management/#creating-a-user-environment","title":"Creating a User Environment","text":"File Explanation <code>/etc/profile</code> Used for default settings for all users when starting a login shell <code>/etc/bashrc</code> Used to define defaults for all users when starting a subshell <code>~/.profile</code> -   Specific settings for one user applied when starting a login shell <code>~/.bashrc</code> Specific settings for one user applied when starting a subshell"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%201/6.%20User%20and%20Group%20Management/#creating-and-managing-group-accounts","title":"Creating and Managing Group Accounts","text":""},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%201/6.%20User%20and%20Group%20Management/#understanding-linux-groups","title":"Understanding Linux Groups","text":"<p>Linux users can be a member of two different kinds of groups: 1. Primary - Every user must be a member of the primary group, and there is only one primary group. When you\u2019re creating files, the primary group becomes group owner of these files. The user\u2019s primary group membership is defined in <code>/etc/passwd</code>; the group itself is stored in the /etc/group configuration file. 2. Secondary - A user can be a member of a secondary group in addition to the primary group. Secondary groups are important to get access to files. If the group a user is a member of has access to specific files, the user will get access to those files also.</p>"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%201/6.%20User%20and%20Group%20Management/#creating-groups","title":"Creating Groups","text":""},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%201/6.%20User%20and%20Group%20Management/#creating-groups-with-vigr","title":"Creating groups With vigr","text":"<p>With the vigr command, you open an editor interface directly on the /etc/group configuration file. In this file, groups are defined in four fields per group: 1. <code>Group Name</code> 2. <code>Group Password</code> 3.<code>Group ID</code> 4. <code>Members</code></p>"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%201/6.%20User%20and%20Group%20Management/#creating-groups-with-groupadd","title":"Creating groups With groupadd","text":"<p>Just use <code>groupadd</code> followed by the name of the group you want to add. There are some advanced options; the only significant one is <code>-g</code>, which allows you to specify a group ID when creating the group.</p>"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%201/6.%20User%20and%20Group%20Management/#managing-group-properties","title":"Managing Group Properties","text":"Command Explanation groupmod Change the name or group ID of the group. usermod -aG Add users to new groups that will be used as their secondary group. groupmems allows a user to administer their own group membership list without the requirement of superuser privileges"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%201/6.%20User%20and%20Group%20Management/#lab","title":"Lab","text":"<ul> <li>Create two groups: sales and account.<ul> <li><code>groupadd</code> group name</li> </ul> </li> <li>Create users bob, betty, bill, and beatrix. Make sure they have their primary group set to a private group that has the name of the user<ul> <li><code>for user in bob betty bill beatrix; do useradd $user; done</code> </li> </ul> </li> <li>Make bob and betty members of the group sales, and bill and beatrix members of the group account.<ul> <li><code>usermod -aG {GROUP} {USER}</code></li> </ul> </li> <li>Set a password policy that requires users to change their password every 90 days.<ul> <li><code>vim /etc/login.defs</code></li> </ul> </li> </ul>"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%201/7.%20Managing%20Users%20and%20Groups/","title":"Managing File Ownership","text":""},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%201/7.%20Managing%20Users%20and%20Groups/#displaying-ownership","title":"Displaying Ownership","text":"<p>Every file and directory has two owners. 1. user 2. group</p> <p>When a user creates a file or directory, they become the owner. </p>"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%201/7.%20Managing%20Users%20and%20Groups/#how-does-the-shell-check-ownership-of-a-file-or-directory","title":"How does the shell check ownership of a file or directory?","text":"<ol> <li>The shell checks whether you are the user owner of the file you want to access, which is also referred to as the user of the file. If you are the user, you get the permissions that are set for the user, and the shell looks no further.</li> <li>The shell checks whether you have obtained any permissions through user-assigned ACLs. If this is the case, these permissions are assigned and the shell looks no further.</li> <li>If you are not the user owner and did not get permissions through ACLs, the shell checks whether you are a member of the group owner, which is also referred to as the group of the file. If you are a member of the group, you get access to the file with the permissions of the group, and the shell looks no further.</li> <li>If you\u2019ve come this far, the shell checks whether you have obtained any permissions through a group ACL. If that is the case, these permissions are applied, and the shell looks no further. If you are a member of multiple groups that have obtained permissions through ACLs, all of these permissions will apply.  </li> <li>If you are neither the user owner nor the group owner and have not obtained permissions through ACLs, you get the permissions of the others entity.</li> </ol>"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%201/7.%20Managing%20Users%20and%20Groups/#changing-ownership","title":"Changing Ownership","text":"<p>Use <code>chown</code> to change ownership. To change linda's ownership on the account file, run <code>chown linda account</code> </p>"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%201/7.%20Managing%20Users%20and%20Groups/#changing-group-ownership","title":"Changing Group Ownership","text":"<p>There are two ways to do this: 1. chown     1. <code>chown .account  /home/account</code> - Change group ownership of the account directory.  2. chgrp     1. <code>chgrp account /home/account</code></p>"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%201/7.%20Managing%20Users%20and%20Groups/#default-ownership","title":"Default Ownership","text":"<p>When a user creates a file or directory, they become the owner, and the primary group of that user automatically becomes group owner.  If the user is a member of more groups, however, he can change the effective primary group so that new files will get the new primary group as group owner. They can do this by using the <code>newgrp</code> command. For example, if I wanted to change my primary group to sales, i would run <code>newgrp sales</code>. So now, every file/directory I create will be owned by the sales group. To set a group password, run <code>gpasswd</code></p>"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%201/7.%20Managing%20Users%20and%20Groups/#managing-basic-permissions","title":"Managing Basic Permissions","text":""},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%201/7.%20Managing%20Users%20and%20Groups/#understanding-read-write-and-execute","title":"Understanding Read, Write, and Execute","text":"Permission Applied To Files Applied to Directories Read Open a file List contents of directory Write Change contents of a file Create and delete files Execute Run a program file Change to the directory"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%201/7.%20Managing%20Users%20and%20Groups/#applying-the-permissions","title":"Applying The Permissions","text":"<p>To apply the above permissions, use <code>chmod</code>. There are two modes for chmod 1. Absolute Mode - Use digits. Not my favorite  2. Relative Mode - Use letters. My favorite \ud83d\ude08</p> Permission Numeric Representation Read 4 Write 2 Execute 1 <p>[!TIP] To set the execute permission to directories only, use an uppercase X. The uppercase X ensures that files will not get the execute permission unless the file has already set the execute permission for some of the entities.</p>"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%201/7.%20Managing%20Users%20and%20Groups/#advanced-special-permissions","title":"Advanced /Special Permissions","text":"<p>There are three advanced permissions.  1. SUID(Set User ID) 2. SGID (Set Group ID) 3. Sticky Bit</p>"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%201/7.%20Managing%20Users%20and%20Groups/#suid","title":"SUID","text":"<p>On some very specific occasions, you may want to apply this permission to executable files. By default, a user who runs an executable file runs this file with his own permissions. For normal users, that usually means that the use of the program is restricted. In some cases, however, the user needs special permissions, just for the execution of a certain task.  </p> <p>[!WARNING] This may look useful, but you could potentially be giving root permissions by accident.  Most of the time, you wont even have to use it. </p>"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%201/7.%20Managing%20Users%20and%20Groups/#sgid","title":"SGID","text":"<p>[!TIP] Use Case:  Linda and Lori work for the accounting department, and are both members of the group <code>accounting</code>. By default, these users are members of the private group of which they are the only member of. Both users, however, are members of the <code>accounting</code> group as well, but as a secondary group setting.  When either of them create a file, the primary group becomes the owner.  BUT, if we make a shared group directory and make sure that the SGID permission is applied to that directory , AND that the group <code>accounting</code> is set as the group owner for the directory, all files created in this directory and all its subdirectories also get the group accounting as the default group owner.</p> <p>This is helpful for setting default group ownership on files and subdirectories. </p> <pre><code># Before setting the SGUID for the TAs group\n[ana@RHCSA-MAIN tas]$ ll\n-rw-r--r--. 1 ana ana 0 Jul 10 19:40 test\n\n#After setting the SGUID on the TAs group\n[ana@RHCSA-MAIN tas]$ ls -l\n-rw-r--r--. 1 ana tas 0 Jul 10 20:15 test_after\n</code></pre> <p>As we can see before setting the SGUID, when ana creates a file <code>test</code>, the group owner of the file test is ana, but after setting the SGUID, the group owner of any file created will be <code>tas</code> which is the directory owner. </p>"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%201/7.%20Managing%20Users%20and%20Groups/#sticky-bit","title":"Sticky Bit","text":"<p>This permission is useful to protect files against accidental deletion in an environment where multiple users have write permissions in the same directory. If sticky bit is applied, a user may delete a file only if she is the user owner of the file or of the directory that contains the file. It is for that reason applied as a default permission to the /tmp directory, and it can be useful on shared group directories as well.</p> <p>When you apply sticky bit, a user can delete files only if either of the following is true: -   The user is owner of the file. -   The user is owner of the directory where the file exists.</p> Permisison Numeric Value Relative Value On Files On Directories SUID 4 u+s User executes file with permissions of file owner.  A file with\u00a0SUID\u00a0always executes as the user who owns the file, regardless of the user passing the command. n/A SGID 2 g+s User executes file with permissions of group owner. -   If set on a file, it allows the file to be executed as the\u00a0group\u00a0that owns the file (similar to SUID) If set on a directory, any files created in the directory will have their\u00a0group\u00a0ownership set to that of the directory owner Sticky Bit 1 +t n/A Prevents users from deleting files from other users.   Only the owner can delete files"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%201/7.%20Managing%20Users%20and%20Groups/#acls","title":"ACLs","text":"<p>Think of a scenario in which a particular user is not a member of group created by you but still you want to give some read or write access, how can you do it without making user a member of group, here comes in picture Access Control Lists, ACL helps us to do this trick. </p> <p>[!TIP] What if you have an accounting intern (Kenny) who needs to be able to read certain files (or even just the files owned by Fred, his manager)? Or maybe people in the sales department also need access to the\u00a0<code>accounting</code>\u00a0owner\u2019s files to create invoices for Fred\u2019s team in order to bill customers, but you don\u2019t want the sales team to see the other reports that Fred's team generates. This situation can be tricky because, with regular permissions, each file and directory can have only one user and group owner at a time.</p>"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%201/7.%20Managing%20Users%20and%20Groups/#preparing-your-file-system-for-acls","title":"Preparing your File System for ACLs","text":"<p>ACLs allow us to apply a more specific set of permissions to a file or directory without (necessarily) changing the base ownership and permissions. They let us \"tack on\"\u00a0access for other users or groups.</p> <p>Benefits of ACLs - You can give permissions to more than one user or group at a directory - You can enable inheritance by working with default ACLs</p> <p>[!TIP] When setting ACLs, if you get the \"operation not supported\" message, you need to add the acl mount option in the /etc/fstab so that the file system will be mounted with ACL support by default. </p>"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%201/7.%20Managing%20Users%20and%20Groups/#changing-and-viewing-acl-settings","title":"Changing and Viewing ACL Settings","text":"<p>To set ACLs, use <code>setfacl</code>. To see current ACL settings, run <code>getfacl</code> . When using <code>ls</code>, ACLs are represented as a <code>+</code>. </p>"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%201/7.%20Managing%20Users%20and%20Groups/#group-acl","title":"Group ACL","text":"<p><code>setfacl -m g:sales:rx /dir</code>.In this command, -m indicates that the current ACL settings need to be modified. After that, <code>g:sales:rx</code> tells the command to set the ACL to read and execute (rx) for the group (g) sales. </p>"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%201/7.%20Managing%20Users%20and%20Groups/#user-acl","title":"User ACL","text":"<p><code>setfacl -m u:linda:rwx /data</code> gives permissions to user linda on the <code>/data</code> directory without making her the owner and without changing the current owner assignment.ACLs also allow you to take away permissions from users. For instance, <code>setfacl -m u:anna:- /tmp/myfile</code> would take away all permissions for user anna. This also will overwrite any permissions that the user may have obtained through the others entity.</p> <p>ACLs also allow you to take away permissions from users. For instance, <code>setfacl -m u:anna:- /tmp/myfile</code> would take away all permissions for user anna. This also will overwrite any permissions that the user may have obtained through the others entity.</p>"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%201/7.%20Managing%20Users%20and%20Groups/#acl","title":"acl","text":""},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%201/7.%20Managing%20Users%20and%20Groups/#default-acls","title":"Default ACLs","text":"<p>By setting a default ACL, you determine the permissions that will be set for all new items that are created in the directory.</p> <p>[!WARNING]  By setting a default ACL, you determine the permissions that will be set for all new items that are created in the directory.</p> <p>[!TIP] If you want to use ACLs to configure access for multiple users or groups to the same directory, you have to set ACLs twice. First, use setfacl -R -m to modify the ACLs for current files. Then, use setfacl -m d: to take care of all new items that will be created also.</p> <p>How To Set a Default ACL? Use the <code>-d</code> flag - <code>setfacl -m d:g:sales:rx /data</code></p>"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%201/7.%20Managing%20Users%20and%20Groups/#example","title":"Example","text":"<p>Let's say we have a producers, and writers group, but the writers need read access to everything in the producers directory. </p>"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%201/7.%20Managing%20Users%20and%20Groups/#setting-default-permissions-with-umask","title":"Setting Default Permissions with umask","text":"<p>If you do not use ACLs, there is a shell setting that determines the default permissions that you will get: <code>umask</code>. Default permissions for a file are 666. Default permissions for a directory are 777.  <pre><code>666 - 022 = 644\n-rw-r--r--. 1 root   root      0 Jul  9 06:22 test1\n6    4    4\n</code></pre></p> <p>So if we wanted to give every new file, read, read, and no permissions we'd run <code>umask  226</code></p> <pre><code>666 - 226 = 440\n-r--r-----. 1 root   root      0 Jul  9 06:26 test2\n4   4   0\n</code></pre> <p>To make the default file permissions 777(NOT RECOMMENDED), run <code>umask 000</code></p> <p>Lab - Ensure that others is denied default permissions to any file, linda creates     - In linda's <code>.bash_profile</code> file, add <code>umask 007</code> - Create a shred group directory structure <code>/data/profs</code> and <code>/data/students</code> that meets the following conditions:     - Members of the groups have full <code>r</code> and <code>w</code> access to their directories, others has no permissions </p> <pre><code>- Files created in these directories are writable for all members of the group\n    - `chmod 2770`\n- Users can only delete files they have created themselves\n    - `chmod 3770 `\n- Members of group profs have read access to everything in `/data/students`\n    - `setfacl -m d:g:profs:rx /data/students `\n- User `anna` is headmaster and should be able to delete everything in `/data/students` and `/data/profs`\n    - `chown anna:students students/`\n    - `chown anna:profs profs/`\n</code></pre>"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%201/8.%20Configuring%20Networking/","title":"Fundamentals","text":"<p>To set up networking on a server, your server needs a unique address on the network. For this purpose, Internet Protocol (IP) addresses are used. Currently, two versions of IP addresses are relevant:</p> <ol> <li>IPv4  - These are based on 32-bit addresses and have four octets, separated by dots, such as <code>192.168.10.100</code>.</li> <li>IPv6  - These are based on 128-bit addresses and are written in eight groups of hexadecimal numbers that are 16 bits each and separated by colons. An IPv6 address may look like <code>fe80:badb:abe01:45bc:34ad:1313:6723:8798</code>.</li> </ol>"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%201/8.%20Configuring%20Networking/#ip-addresses","title":"IP Addresses","text":"<p>To make it easier for computers to communicate with one another, every IP address belongs to a specific network, and to communicate with computers on another network, a router is used. A router is a machine (often dedicated hardware that has been created for that purpose) that connects networks to one another.</p>"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%201/8.%20Configuring%20Networking/#private-addresses","title":"Private Addresses","text":"<p>Private network addresses are addresses that are for use in internal networks only. Private networks are one solution(the other being IPv6) to the problem that arrises from the scarcity of available IP address. Some specific IP network addresses have been reserved for this purpose: -   <code>10.0.0.0/8</code> (a single Class A network) -   <code>172.16.0.0/12</code> (16 Class B networks)  -   <code>192.168.0.0/16</code> (256 Class C networks)</p> <p>When private addresses are used, the nodes that are using them cannot access the Internet directly, and nodes from the Internet cannot easily access them. Because that is not very convenient, Network Address Translation (NAT) is commonly used on the router that connects the private network to the Internet. In NAT, the nodes use a private IP address, but when accessing the Internet, this private IP address is replaced with the IP address of the NAT router. Hence, nodes on the Internet think that they are communicating with the NAT router, and not with the individual hosts. ![[Pasted image 20220712064219.png]]</p> <p>IP Address are broken into two portions. 1. 192.168.1 - The Network Portion     1. The unique number of your address     2. The class of your network 2. .14 - The Host Portion     1. Uniquely identifies the machine. </p> <p>Ok, so how do other hosts know which part of the address is the network and which part is host?? This is where subnet masking comes into play. </p>"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%201/8.%20Configuring%20Networking/#network-masks","title":"Network Masks","text":"<p>To know to which network a computer belongs, a subnet mask is used with every IP address. The subnet mask defines which part of the network address indicates the network and which part indicates the node.</p> <p>Example 192.168.123.132/24 or 255.255.255.0</p>"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%201/8.%20Configuring%20Networking/#mac-addresses","title":"Mac Addresses","text":"<p>Each network card also has a 12-byte MAC address. MAC addresses are for use on the local network (that is, the local physical network or local WLAN, just up to the first router that is encountered); they cannot be used for communications between nodes that are on different networks. MAC addresses are important, though, because they help computers find the specific network card that an IP address belongs to.</p>"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%201/8.%20Configuring%20Networking/#protocols-and-ports","title":"Protocols and Ports","text":"Port Service 80 HTTP 22 SSH"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%201/8.%20Configuring%20Networking/#managing-network-address-and-interfaces","title":"Managing Network Address and Interfaces","text":"<p>Network addresses can be assigned in two ways:</p> <ul> <li>Fixed IP addresses -  Useful for servers that always need to be available at the same IP address.</li> <li>Dynamically assigned IP addresses - Useful for end users\u2019 devices, and for instances in a cloud environment. To dynamically assign IP addresses, you usually use a Dynamic Host Configuration Protocol (DHCP) server.</li> </ul>"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%201/8.%20Configuring%20Networking/#validating-network-configuration","title":"Validating Network Configuration","text":""},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%201/8.%20Configuring%20Networking/#validating-network-address-configuration","title":"Validating Network Address Configuration","text":"<p>To verify the configuration of the network address, you need to use the <code>ip</code> utility. With the <code>ip</code> utility, many aspects of networking can be monitored:</p> <ul> <li>Use<code>ip addr</code> to configure and monitor network addresses. <ul> <li>ip addr add - Specify the device, and the IP address you want to add. </li> </ul> </li> <li>Use <code>ip route</code> to configure and monitor routing information.<ul> <li>ip route show</li> </ul> </li> <li>Use <code>ip link</code> to configure and monitor network link state.</li> </ul> <p>[!WARNING] Changes made with ip are NOT persistent.</p>"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%201/8.%20Configuring%20Networking/#configuring-network-configuration-with-nmtui-and-nmcli","title":"Configuring Network Configuration with nmtui and nmcli","text":"<p>[!WARNING] Changes made with nm are persistent.</p> <p>[!TIP] nmtui has a text interface and nmcli is the command line interface. For the exam, stick with nmtui. When working with network configuration in RHEL 8, you should know the difference between a device and a connection:</p> <ul> <li>A device is a network interface card.</li> <li>A connection is the configuration that is used on a device.</li> </ul> <p>Believe it or not, if an ordinary user is logged in to the local console, this user can make changes to the network configuration. To check your current permissions, use the <code>nmcli gen permissions</code> command, as shown in</p>"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%201/8.%20Configuring%20Networking/#nmcli","title":"NMCLI","text":"<p>[!TIP] ENsure that the bash-completion RPM package is installed with working with nmcli</p>"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%201/8.%20Configuring%20Networking/#network-configuration-files","title":"Network Configuration Files","text":"<p>Every connection that you create is stored as a configuration file in the directory <code>/etc/sysconfig/network-scripts</code>. The name of the configuration files starts with ifcfg- and is followed by the name of the network interface. If you don't like using nmcli or nmtui, you can use the config files. After you're finished editing, just make sure you run <code>nmcli con up</code></p>"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%201/8.%20Configuring%20Networking/#hostname-and-name-resolution","title":"Hostname and Name Resolution","text":"<p>You can change the hostname with one of the following:  -   Use <code>nmtui</code> and select the option Change Hostname. -   Use <code>hostnamectl set-hostname</code>. -   Edit the contents of the configuration file /etc/hostname.</p>"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%201/8.%20Configuring%20Networking/#hostname-resolution","title":"Hostname Resolution","text":"<p>Hostname resolution can be configured in <code>/etc/hosts</code>. Setting up an /etc/hosts file is easy; just make sure that it contains at least two columns. The first column has the IP address of the specific host, and the second column specifies the hostname. The hostname can be provided as a short name (like server1) or as an FQDN. In an FQDN, the hostname as well as the complete DNS name are included, as in server1.example.com.</p> <p>If a host has more than one name, like a short name and a fully qualified DNS name, you can specify both of them in /etc/hosts. In that case, the second column must contain the FQDN, and the third column can contain the alias. Example 8-10 shows a hostname configuration example.</p>"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%201/8.%20Configuring%20Networking/#dns-name-resolution","title":"DNS Name Resolution","text":"<p>To specify which DNS server should be used, set the DNS server using <code>nmcli</code> or <code>nmtui</code>. The NetworkManager configuration stores the DNS information in the configuration file for the network connection, which is in /etc/sysconfig/network-scripts, and from there pushes the configuration to the /etc/resolv.conf file, which is used for DNS name server resolving.</p> <p>[!TIP] It is recommended to always set up at least two DNS name servers to be contacted. Why? IF the first server does not answer, then 2nd one is contacted. </p> <p>[!WARNING] Do not edit <code>/etc/resolv.conf</code>. It will be overwritten the next time you restart  Network Manager.</p> <p>To specify the DNS name servers you want to use, you have a few options: -   Use nmtui to set the DNS name servers.  -   Set the DNS1 and DNS2 parameters in the ifcfg network connection configuration file in /etc/sysconfig/network-scripts. -   Use a DHCP server that is configured to hand out the address of the DNS name server. -   Use nmcli con mod  [+]ipv4.dns . <p>Remeber, when updating your IP address make sure the following are set up: 1. Ip Address 2. Netmask 3. Gateway</p>"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%202/10.%20Managing%20Processes/","title":"10. Managing Processes","text":"<p>For everything that happens on a Linux server, a process is started. There are 3 process types: 1. Shell Jobs - Commands started from the command line. They are associated with the shell that was current when the process was started. These are also refereed to as interactive processes 2. Daemons - Processes that provide services. Usually started when the computer is booted. 4. Kernel Threads - These are a part of the linux kernel. You cannot manage these with common tools. When using <code>ps</code> these are identified with [brackets]</p> <p>When a process is started, it can use multiple threads. A thread is a task started by a process and that s dedicated CPU can service. </p>"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%202/10.%20Managing%20Processes/#shell-jobs","title":"Shell Jobs","text":"<p>To see a list of jobs, use <code>jobs</code> By default, an executed command starts in the foreground and quit when they are finished. If you know a job will take a long time to complete, start it with an <code>&amp;</code> behind it. This will start it in the background to make room for other tasks to be started from the cli. To move the last job to the front, use <code>fg</code> . If a job takes much longer than predicted, use <code>Ctrl-Z</code> to temporarily stop the job. This pauses it, but does not remove it.</p>"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%202/10.%20Managing%20Processes/#ctrl-d-vs-ctrl-c","title":"Ctrl D vs Ctrl C","text":"<p>Ctrl-D sends the end of file character to the current job. This job stops waiting for further input so that it can complete what it was currently doing.  When using Ctrl-C the job is just canceled, and nothing is closed properly</p>"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%202/10.%20Managing%20Processes/#managing-shell-jobs","title":"Managing Shell Jobs","text":"<p>To get an overview of all current jobs, use the <code>jobs</code> command. </p>"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%202/10.%20Managing%20Processes/#managing-parent-child-relations","title":"Managing Parent-Child Relations","text":"<p>When a process is started from a shell, it becomes a child process of that shell. All process started from a shell are terminated when th eshell is stopped. But, processes started in th background will NOT be killed when the parent shell from which they were starte dis killed.  To terminate these processes, use the <code>kill</code> command. </p> <p>[!TIP] If a parent process is killed while the child process is still active, the child becomes a child of systemd</p>"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%202/10.%20Managing%20Processes/#command-line-tools-for-process-management","title":"Command Line Tools For Process Management","text":"Command Explanation ps Show an overview of current processes ps -ef ps ps -ef ps fax ps aux grep dd pgrep dd"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%202/10.%20Managing%20Processes/#understanding-memory","title":"Understanding Memory","text":"<p>Linux places as many files as possible in cache to guarantee fast access to the files. Because of this, linux shows as saturated. Swap is used as an overflow buffer of emulated RAM on disk. The Linux kernel moves inactive memory to swap first. </p>"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%202/10.%20Managing%20Processes/#adjusting-process-priority-with-nice","title":"Adjusting Process Priority with nice","text":"<p>When linux processes are started, they are started with a priority of 20. Niceness generally ranges from -20 to 19, with -20 being the most favorable or highest priority for scheduling and 19 being the least favorable or lowest priority. Use <code>nice</code> and <code>renice</code> to adjust this priority. Why would you ever want to adjust niceness? 1. Backup jobs can be resource intensive, but most of the time don't need to be finished fast. You might want to start the job in a way that it doesn't annoy other processes.  2. Say you want to start a very important calculation job. You might give it increased priority so that it can be handled as fast as possible,  | Command | Explanation                               | | ------- | ----------------------------------------- | | nice    | Start a process with an adjusted priority | | renice  | Change priority for current active process                                          |</p> <pre><code>#Using nice and renice\n\n[ps aux | grep dd](&lt;[root@RHCSA-MAIN etc]# nice -n 5 dd if=/dev/zero of=/dev/null &amp;\n[1] 12219\n\n[root@RHCSA-MAIN etc]# ps aux |grep dd\nroot       12219 87.1  0.0 220992  1036 pts/3    RN   17:33   0:06 dd if=/dev/zero of=/dev/null\n\n[root@RHCSA-MAIN etc]# renice -n 10 -p 12221\n\n[root@RHCSA-MAIN etc]# renice -n 10 -p 12219\n12219 (process ID) old priority 5, new priority 10\n\n[root@RHCSA-MAIN etc]# ps aux |grep dd\n\nroot       12219 77.8  0.0 220992  1036 pts/3    RN   17:33   0:31 dd if=/dev/zero of=/dev/null\n</code></pre> <p>Use a <code>-</code> to increase priority and <code>+</code> tp decrease priority. </p> <p>[! Warning] Never set priority to -20.</p>"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%202/10.%20Managing%20Processes/#kill-killall-and-pkill","title":"Kill Killall and pkill","text":"Signal Explanation SIGTERM(15) Used to ASK a process to stop SIGTERM(9) Used to FORCE a process to stop SIGHUP (1) Used to HANG UP a process. The process will reread its config files. Like a restart. <p>To send one of these signals, use <code>kill</code>.</p>"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%202/10.%20Managing%20Processes/#managing-processes-with-top","title":"Managing Processes with Top","text":"<p><code>top</code> gives an overview of the most active process currently running.  From top, you can also adjust process priority and kill processes.  Simply use <code>r</code> to renice or <code>k</code> to kill.</p> <p>To get load averages, use the <code>uptime</code> command. Load averages are shown for the last 1,5,15 minutes.  <pre><code>[root@RHCSA-MAIN etc]# uptime\n 17:47:07 up  9:18,  1 user,  load average: 0.97, 1.03, 0.69\n</code></pre></p>"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%202/10.%20Managing%20Processes/#tuned","title":"Tuned","text":"<p>Tuned is a daemon that monitors system activity and provides profiles. In these profiles, an admin can automatically tune a system for best possible latency, throughput or power consumption.  All you need to do is select the appropriate profile</p> Command Explanation tuned-adm list Shows an overview of the current available profiles tuned-adm profile Selects the profile"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%202/11.%20Working%20with%20Systemd/","title":"Understanding Systemd","text":"<p>Systemd is started as the first process after loading the kernel and is the manager of everything! It is used for starting services like the secure shell server.  Apart from services, systemd takes care of many more items. The items started by systemd are referred to as units. Systemctl is the main management tool for systemd.</p>"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%202/11.%20Working%20with%20Systemd/#systemd-unit-locations","title":"Systemd Unit Locations","text":"Location Description Precedence If Duplicates Exist /usr/lib/systemd/system Contains defaults unit files that have been installed from RPM packages. DO NOT EDIT THIS DIRECTLY 3 /etc/systemd/system Contains custom unit files. May also include files that have been written by an admin or generated by the systemctl edit command. 2 /run/systemd Contains unit files that have automatically been generated. 1"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%202/11.%20Working%20with%20Systemd/#service-units","title":"Service Units","text":"<p>Service units are used to start processes. </p> Section Explanation Unit Describes the unit and defines dependencies. This section also contains the important After statement and optionally the Before statement. These statements define dependencies between different units, and they relate to the perspective of this unit. The Before statement indicates that this unit should be started before the unit that is specified. The After statement indicates that this unit should be started after the unit that is specified. Service Describes how to start and stop the service and request status installation. Normally, you can expect an ExecStart line, which indicates how to start the unit, or an ExecStop line, which indicates how to stop the unit. Note the Type option, which is used to specify how the process should start. Install Indicates in which target this unit has to be started. <pre><code>/usr/lib/systemd/system/vsftpd.service\n[Unit]\nDescription=Vsftpd ftp daemon\nAfter=network.target\n\n[Service]\nType=forking\nExecStart=/usr/sbin/vsftpd /etc/vsftpd/vsftpd.conf\n\n[Install]\nWantedBy=multi-user.target\n</code></pre>"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%202/11.%20Working%20with%20Systemd/#systemd-mount-units","title":"Systemd Mount Units","text":"<p>A mount unit specifies how a file system can be mounted on a specific directory.  | Section | Explanation                                                                                                                                                                                                                                                                                                                                                                                                                                                   | | ------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | | Unit    | The Conflicts statement is used to list units that cannot be used together with this unit. Use this statement for mutually exclusive units.| | Mount   | This section defines exactly where the mount has to be performed. Here you see the arguments that are typically used in any mount command.            |</p> <pre><code>[Unit]\nDescription=Temporary Directory (/tmp)\nDocumentation=man:hier(7)\nDocumentation=https://www.freedesktop.org/wiki/Software/systemd/\nAPIFileSystems\nConditionPathIsSymbolicLink=!/tmp\nDefaultDependencies=no\nConflicts=umount.target\nBefore=local-fs.target umount.target\nAfter=swap.target\n\n[Mount]\nWhat=tmpfs\nWhere=/tmp\nType=tmpfs\nOptions=mode=1777,strictatime,nosuid,nodev\n</code></pre>"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%202/11.%20Working%20with%20Systemd/#systemd-socket-units","title":"Systemd Socket Units|","text":"<p>A socket creates a method for applications to communicate with one another.  Every socket needs a corresponding service file. </p> <pre><code>[Unit]\nDescription=Cockpit Web Service Socket\nDocumentation=man:cockpit-ws(8)\nWants=cockpit-motd.service\n\n[Socket]\n# Port to listen on for incoming connections.\nListenStream=9090\nExecStartPost=-/usr/share/cockpit/motd/update-motd '' localhost\nExecStartPost=-/bin/ln -snf active.motd /run/cockpit/motd\nExecStopPost=-/bin/ln -snf /usr/share/cockpit/motd/inactive.motd\n/run/cockpit/motd\n\n[Install]\nWantedBy=sockets.target\n</code></pre>"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%202/11.%20Working%20with%20Systemd/#systemd-target-units","title":"Systemd Target Units","text":"<p>Target units are used to load unit files in the right order at the right moment.  A target unit  is a group of units. </p> <pre><code>[Unit]\nDescription=Multi-User System\nDocumentation=man:systemd.special(7)\nRequires=basic.target\nConflicts=rescue.service rescue.target\n#After specifies load ordering. \nAfter=basic.target rescue.service rescue.target\nAllowIsolate=yes\n\n[Install]\nAlias=default.target\u201d\n\n#The target file does not contain any information about the units that should be included; that is defined in the [Install] section of the different unit files.\n</code></pre> <p>When administrators use the systemctl enable command, to ensure that a unit is automatically started while booting, the [Install] section of that unit is considered to determine to which target the unit should be added.</p>"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%202/11.%20Working%20with%20Systemd/#managing-units-through-systemd","title":"Managing Units Through Systemd","text":"<p>The main ways to manage a unit are to status, start, stop, enable, or disable it.  Example of  seeing the status of sshd.</p> <pre><code>root@RHCSA-MAIN etc]# systemctl status sshd\n\u25cf sshd.service - OpenSSH server daemon\n     Loaded: loaded (/usr/lib/systemd/system/sshd.service; enabled; vendor preset: enabled)\n     Active: active (running) since Mon 2022-07-18 12:59:35 EDT; 2 weeks 1 day ago\n       Docs: man:sshd(8)\n             man:sshd_config(5)\n   Main PID: 929 (sshd)\n      Tasks: 1 (limit: 22993)\n     Memory: 2.9M\n        CPU: 18ms\n     CGroup: /system.slice/sshd.service\n             \u2514\u2500929 \"sshd: /usr/sbin/sshd -D [listener] 0 of 10-100 startups\"\n</code></pre>"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%202/11.%20Working%20with%20Systemd/#managing-dependencies","title":"Managing Dependencies","text":"<p>To see a list of dependencies for a unit, run <code>systemctl list-dependencies {unit name}</code>  There are 2 ways to manage systemd dependencies:</p> <ol> <li>Unit types such as socket and path are directly related to a service unit. Accessing either of these unit types will automatically trigger the service type.</li> <li>Dependencies can be defined within the unit, using keywords like Requires, Requisite, After, and Before.</li> </ol> <p>To ensure accurate dependency management, you can use different keywords in the [Unit] section of a unit:</p> <ul> <li><code>Requires</code>: If this unit loads, units listed here will load also. If one of the other units is deactivated, this unit will also be deactivated.</li> <li><code>Requisite</code>: If the unit listed here is not already loaded, this unit will fail.</li> <li><code>Wants</code>: This unit wants to load the units that are listed here, but it will not fail if any of the listed units fail.</li> <li><code>Before</code>: This unit will start before the unit specified with Before.</li> <li><code>After</code>: This unit will start after the unit specified with After.</li> </ul>"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%202/11.%20Working%20with%20Systemd/#managing-unit-options","title":"Managing Unit Options","text":"<p>Every unit file can be configured with different options. To figure out which options are available for a specific unit, use the <code>systemctl show</code> command.  The recommended way to change unit files to apply options is to use the <code>systemctl edit {service}</code> command. This command creates a subdirectory in <code>/etc/systemd/system</code> for the service that you are editing; for example, if you use <code>systemctl edit sshd.service</code>, you get a directory with the name <code>/etc/systemd/systemd/sshd.service.d</code> in which a file with the name override.conf is created. All settings that are applied in this file overwrite any existing settings in the service file in <code>/usr/lib/systemd/system</code>.</p>"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%202/11.%20Working%20with%20Systemd/#example","title":"Example","text":"<p>Lets say we want to edit the httpd service so that on failue, it will continue after 1 minute.</p> <p><code>systemctl edit httpd</code> ![[Screenshot 2022-11-22 at 7.42.20 PM.png]]</p>"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%202/12.%20Scheduling%20Tasks/","title":"Cron","text":"<p>The cron service consists of 2  major components: 1. crond which is the cron daemon 2. Cron configuration which consists of multiple files working together to provide the right information to the right services at the right time.  <pre><code># Cron examples\n* 11 * * * Every minute between 11:00 and 11:59 (probably not what you want)\n0 11 * * 1-5 Every day at 11 a.m. on weekdays only\n0 7-18 * * 1-5 Every hour at the top of the hour between 7 a.m. and 6 p.m. on weekdays\n0 */2 2 12 5 Every two hours on the hour on December 2 and every Friday in December\n</code></pre></p> <p>The main config file is <code>/etc/crontab</code>. This is deprecated. Don't use this !  </p> <p>Instead of modifying /etc/crontab, different cron configuration files are used:</p> <ul> <li>cron files are in <code>/etc/cron.d</code></li> <li>Scripts in<code>/etc/cron.hourly</code>, <code>cron.daily</code>, <code>cron.weekly</code>, and <code>cron.monthly</code><ul> <li>When putting scripts in this directory, exact times don't matter. All that matters is that they are executed, hourly, daily, weekly, and monthly.  The anacron service takes care of starting these. Config file is in <code>/etc/anacrontab</code></li> </ul> </li> <li>User-specific files that are created with <code>crontab -e</code></li> </ul>"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%202/12.%20Scheduling%20Tasks/#cron-security","title":"Cron Security","text":"<p>By default, all users can enter cron jobs. It is possible to limit which user is allowed to schedule cron jobs by using the /etc/cron.allow and /etc/cron.deny configuration files. If the cron.allow file exists, a user must be listed in it to be allowed to use cron. If the /etc/cron.deny file exists, a user must not be listed in it to be allowed to set up cron jobs. Both files should not exist on the same system at the same time. Only root can use cron if neither file exists.</p>"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%202/12.%20Scheduling%20Tasks/#configuring-at-to-schedule-future-tasks","title":"Configuring at to Schedule Future Tasks","text":"<p>The <code>atd</code> service is available for services that need to be executed only once. Use the <code>at</code> command followed by the time the job needs to be executed. This can be a specific time, as in at 14:00, but it can also be a time indication like at teatime or at noon. After you type this, the at shell opens. From this shell, you can type several commands that will be executed at the specific time that is mentioned. After entering the commands, press Ctrl-D to quit the at shell. | Command | Explanation                                     | | ------- | ----------------------------------------------- | | <code>atq</code>     | Get an overview of all jobs currently scheduled | | <code>atm</code>     | Use this command to remove jobs                                                |</p>"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%202/12.%20Scheduling%20Tasks/#cron_1","title":"cron","text":""},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%202/13.%20Configuring%20Logging/","title":"13. Configuring Logging","text":"<p>Most services on Linux write information to log files. There are 3 approaches that can be used to write logs: 1. Direct Write  -   Some services write logging information directly to the log files\u2014even some important services such as the Apache web server and the Samba file server. 2. rsyslogd  -   rsyslogd is the enhancement of syslogd, a service that takes care of managing centralized log files. Because journald is not persistant between reboots, logs are forwarded here, which writes to different directories in <code>/var/log</code> 3. journald -   With the introduction of Systemd, the journald log service systemd- journald has been introduced also. This service is tightly integrated with Systemd, which allows administrators to read detailed information from the journal while monitoring service status using the systemctl status command. This can be queried using <code>journalctl</code>. This command enables yo to access a deep level of detail about messages that are logged.</p> <p>[!TIP] journald is NOT a replacement for rsyslog.</p> <p>To get info about what is happening on your machine use the following 3 approaches: 1. Monitor the files in <code>/var/log</code> that are written by <code>rsyslogd</code>. 2. Use the <code>journalctl</code> command to get more detailed information from the journal. 3. Use the <code>systemctl status &lt;unit&gt;</code> command to get a short overview of the last significant events that have been logged by Systemd units through <code>journald</code>.</p>"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%202/13.%20Configuring%20Logging/#understanding-log-file-contents","title":"Understanding Log File Contents","text":"<pre><code>Aug  8 06:23:56 RHCSA-MAIN systemd[1955]: Started Virtual filesystem metadata service.\nAug  8 06:23:58 RHCSA-MAIN chronyd[805]: Can't synchronise: no majority\nAug  8 06:24:00 RHCSA-MAIN chronyd[805]: Selected source 167.248.49.102 (2.rhel.pool.ntp.org)\nAug  8 06:24:00 RHCSA-MAIN chronyd[805]: Source 167.248.49.102 replaced with 2602:fe2e:3:d:f9:c7ff:fef5:379c (2.rhel.pool.ntp.org)\nAug  8 06:24:04 RHCSA-MAIN PackageKit[1467]: uid 1000 is trying to obtain org.freedesktop.packagekit.system-sources-refresh auth (only_trusted:0)\nAug  8 06:24:04 RHCSA-MAIN PackageKit[1467]: uid 1000 obtained auth for org.freedesktop.packagekit.system-sources-refresh\nAug  8 06:24:08 RHCSA-MAIN systemd[1]: Starting Fingerprint Authentication Daemon...\nAug  8 06:24:08 RHCSA-MAIN systemd[1]: Started Fingerprint Authentication Daemon.\nAug  8 06:24:09 RHCSA-MAIN journal[1467]: Skipping refresh of media: Cannot update read-only repo\nAug  8 06:24:09 RHCSA-MAIN journal[1467]: Skipping refresh of media: Cannot update read-only repo\n</code></pre> <ul> <li>Date and time: Every log message starts with a timestamp. For filtering purposes, the timestamp is written as military time.</li> <li>Host: The host the message originated from. This is relevant because rsyslogd can be configured to handle remote logging as well.</li> <li>Service or process name: The name of the service or process that generated the message.</li> <li>Message content: The content of the message, which contains the exact message that has been logged.</li> </ul>"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%202/13.%20Configuring%20Logging/#logger","title":"Logger","text":"<p>Logger allows the user to send logs directly to rsyslog from the command line or script</p>"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%202/13.%20Configuring%20Logging/#configuring-rsyslogd","title":"Configuring rsyslogd","text":"<p>To make sure that the information that needs to be logged is written to the location where you want to find it, you can configure the rsyslogd service through the <code>/etc/rsyslog.conf</code> file. In this file, you find different sections that allow you to specify where and how information should be written. The <code>/etc/rsyslog.conf</code> file is the central location where rsyslogd is configured. From this file, the content of the directory /etc/rsyslog.d is included. Below are the contents of <code>/etc/rsyslog.conf</code>:</p> <ul> <li>#### MODULES ####: rsyslogd is modular. Modules are included to enhance the supported features in rsyslogd.</li> <li>#### GLOBAL DIRECTIVES ####: This section is used to specify global parameters, such as the location where auxiliary files are written or the default timestamp format.  </li> <li>#### RULES ####: This is the most important part of the rsyslog.conf file. It contains the rules that specify what information should be logged to which destination.</li> </ul>"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%202/13.%20Configuring%20Logging/#rotating-log-files","title":"Rotating Log Files","text":"<p>To prevent syslog messages from filling up, you should rotate your logs. This means that when a certain threshold has been reached, the old log file is closed and a new log file is opened.  Configuration can be found in <code>/etc/logrotate.conf</code>. If specific files need specific settings, you can create a configuration file for that file in <code>/etc/logrotate.d</code>.</p> <p>[!WARNING] Once a log file is rotated, it's gone. </p>"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%202/13.%20Configuring%20Logging/#working-with-journald","title":"Working With journald","text":"<p>The systemd-journald service stores log messages in the journal, a binary file that is temporarily stored in the file <code>/run/log/journal</code>. If you want to see the last messages that have been logged, you can use <code>journalctl -f</code>, which shows the last lines of the messages where new log lines are automatically added. You can also type journalctl and use (uppercase) G to go to the end of the journal. Also note that the search options / and ? work in the journalctl output.</p>"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%202/13.%20Configuring%20Logging/#preserving-the-systemd-journal","title":"Preserving the Systemd Journal","text":"<p>By default, the journal is stored in the file <code>/run/log/journal</code>. The entire /run directory is used for current process status information only, which means that the journal is cleared when the system reboots. To make the journal persistent between system restarts, you should make sure that a directory <code>/var/log/journal</code> exists. Yes, all you need to do is create this directory. The system will handle the rest. </p> <p>Storing the journal permanently requires setting the Storage=auto parameter in<code>/etc/systemd/journal.conf</code>. This parameter can have different values:</p> <ul> <li><code>Storage=auto</code> The journal will be written on disk if the directory /var/log/journal exists.</li> <li><code>Storage=volatile</code> The journal will be stored only in the /run/log/ journal directory.    </li> <li><code>Storage=persistent</code>The journal will be stored on disk in the directory /var/log/journal. This directory will be created automatically if it doesn\u2019t exist.</li> <li><code>Storage=none</code> No data will be stored, but forwarding to other targets such as the kernel log buffer or syslog will still work.</li> </ul> <p>[!WARNING]  The journal is NOT kept forever. The journal has built-in log rotation that will be used monthly. To change these settings, you can modify the file <code>/etc/systemd/journald.conf</code>.</p>"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%202/14.%20Managing%20Storage/","title":"Storage Options Overview","text":"<ul> <li>Partitions- The classic solution. Used the majority of the time.</li> <li>LVM - Used as default installation of RHEL<ul> <li>Adds flexibility to storage (resize, snapshots, and more)</li> </ul> </li> <li>Statis<ul> <li>Next Gen volume managing filesystem that uses thin provisioning by default.</li> </ul> </li> <li>VDO (Virtual Data Optimizer)<ul> <li>Focused on storing files in the most efficient way. </li> <li>Manages deduplicated and compressed storage pools.</li> </ul> </li> </ul>"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%202/14.%20Managing%20Storage/#mbr-and-gpt-partitions","title":"MBR and GPT Partitions","text":""},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%202/14.%20Managing%20Storage/#master-boot-record-mbr","title":"Master Boot Record (MBR)","text":"<ul> <li>MBR is a special type of boot sector at the very beginning of partitioned computer mass storage devices like fixed disks or removable drives that holds the information on how the logical partitions, containing file systems, are organized on that medium.</li> <li>This MBR code is usually referred to as a boot loader.</li> <li>It is the first sector of the Hard Disk with a size of 512 bytes.</li> <li>The first 434 - 446 bytes are the primary boot loader, 64 bytes for partition table and 6 bytes for MBR validation timestamp.</li> <li>The Partition Table, located in the master boot record, contains 16-byte entries, each of which describes a partition.</li> <li>The organization of the partition table in the MBR limits the maximum addressable storage space of a disk to 2 TB (232 \u00d7 512 bytes)</li> </ul>"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%202/14.%20Managing%20Storage/#guid-partition-table-gpt","title":"GUID Partition Table (GPT)","text":"<p>On computers that are using the new Unified Extensible Firmware Interface (UEFI) as a replacement for the old BIOS system, GPT partitions are the only way to address disks. Also, older computer systems that are using BIOS instead of UEFI can be configured with GUID partitions, which is necessary if a disk with a size bigger than 2 TiB needs to be addressed.</p> <p>Benefits of GUID -   The maximum partition size is 8 zebibyte (ZiB), which is 1024 \u00d7 1024 \u00d7 1024 \u00d7 1024 gibibytes. -   In GPT, up to a maximum number of 128 partitions can be created. -   The 2-TiB limit no longer exists. -   Because space that is available to store partitions is much bigger than 64 bytes, which was used in MBR, there is no longer a need to distinguish between primary, extended, and logical partitions. -   GPT uses a 128-bit global unique ID (GUID) to identify partitions. -   A backup copy of the GUID partition table is created by default at the end of the disk, which eliminates the single point of failure that exists on MBR partition tables.</p>"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%202/14.%20Managing%20Storage/#managing-partitions-and-file-systems","title":"Managing Partitions and File Systems","text":""},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%202/14.%20Managing%20Storage/#common-disk-device-types","title":"Common Disk Device Types","text":"Device Name Description <code>/dev/sda</code> A hard disk that uses the SCSI driver. Used for SCSI and SATA disk devices. Common on physical servers but also in VMware virtual machines. <code>/dev/nvme0n1</code> The first hard disk on an NVM Express (NVMe) interface. NVMe is a server-grade method to address advanced SSD devices. Note at the end of the device name that the first disk in this case is referred to as n1 instead of a (as is common with the other types). <code>/dev/hda</code> Legacy IDE disk device type <code>/dev/vda</code> A disk in a KVM virtual machine that uses the virtio disk driver. This is the common disk device type for KVM virtual machines. <code>/dev/xvda</code> A disk in a Xen virtual machine that uses the Xen virtual disk driver. You see this when installing RHEL as a virtual machine in Xen virtualization. RHEL 8 cannot be used as a Xen hypervisor, but you might see RHEL 8 virtual machines on top of the Xen hypervisor using these disk types. <p>[!TIP] Almost all disk device names end with the letter a. The reason is that it is the first disk that was found in your server. The second SCSI disk, for instance, would have the name /dev/sdb etc...</p>"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%202/14.%20Managing%20Storage/#using-extended-and-logical-partitions-on-mbr","title":"Using Extended and Logical Partitions on MBR","text":"<p>If three partitions have been created already, there is room for one more primary partition, after which the partition table is completely filled up. If you want to go beyond four partitions on an MBR disk, you have to create an extended partition. Following that, you can create logical partitions within the extended partition.</p> <p>[!WARNING]  An extended partition is used only for the purpose of creating logical partitions. You cannot create file systems directly on an extended partition!</p>"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%202/14.%20Managing%20Storage/#creating-logical-partitions","title":"Creating Logical Partitions","text":"<ol> <li>In a root shell, type fdisk /dev/sda to open the fdisk interface.</li> <li>To create a logical partition, when fdisk prompts which partition type you want to create, enter e.  </li> <li>If the extended partition is the fourth partition that you are writing to the MBR, it will also be the last partition that can be added to the MBR. For that reason, it should fill the rest of your computer\u2019s hard disk. Press Enter to accept the default first sector and press Enter again when fdisk prompts for the last sector. Note that this extended partition should use the rest of the remaining disk space, because all disk space not included in this partition cannot be allocated at a later stage.</li> <li>Now that the extended partition has been created, you can create a logical partition within it. Still from the fdisk interface, press n again. The utility will prompt that all primary partitions are in use now and by default suggest adding a logical partition with partition number 5.</li> <li>Press Enter to accept the default first sector. When asked for the last sector, enter +100M (or any other size you want to use).</li> <li>Now that the logical partition has been created, enter w to write the changes to disk and quit fdisk. To complete the procedure, enter <code>partprobe</code> to update the kernel partition table. The new partition is now ready for use. If part- probe responds with an error message, you should reboot your system before continuing.</li> </ol>"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%202/14.%20Managing%20Storage/#file-systems","title":"File Systems","text":"<p>Partitions are useless unless you're doing something with them. This is where file systems come in to play. Once you make a filesystem, you mount it.</p>"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%202/14.%20Managing%20Storage/#file-system-overview","title":"File System Overview","text":"File System Description XFS The default file system in RHEL 8. Fast and Scalable. Uses CoW for data integrity. Size can be increased, NOT decreased. Ext4 The default file system in previous versions of RHEL; still available and supported in RHEL 8.    Backward compatible to Ext2. Uses Journaling for data integrity. Size can be increased, AND decreased BtrFS A relatively new file system that is not supported in RHEL 8. <p>Use <code>mkfs -t</code> to format a partition with one of the above file systems. </p> <p>[!WARNING] Never just type mkfs. This will create an Ext2 file system, and theres no need for that anymore. </p>"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%202/14.%20Managing%20Storage/#changing-file-system-properties","title":"Changing File System Properties","text":"<p>When working with file systems, you can manage some properties as well. File system properties are specific for the file system you are using, so you work with different properties and different tools for the different file systems.</p>"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%202/14.%20Managing%20Storage/#ext4","title":"Ext4","text":"<p>The generic tool for managing Ext4 file system properties is <code>tune2fs</code>.</p>"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%202/14.%20Managing%20Storage/#xfs","title":"XFS","text":"<p><code>xfs_admin</code></p>"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%202/14.%20Managing%20Storage/#creating-swap-partition","title":"Creating Swap Partition","text":"<ol> <li>Type <code>parted {device}</code>, which will bring you to interactive shell.</li> <li><code>mkpart</code>, which will ask you for a name. just call it swap</li> <li>File System type should be <code>linux-swap</code>!!!</li> <li>Start - 1GiB</li> <li>End - 2GiB</li> <li><code>quit</code></li> <li><code>mkswap</code> {device name}</li> <li>Type free -m. You see the amount of swap space that is currently allocated. This does not include the swap space you have just created, as it still needs to be activated.</li> <li>Use <code>swapon</code> to switch on the newly allocated swap space. If, for instance, the swap device you have just created is /dev/sda6, use swapon /dev/sda6 to activate the swap space.</li> <li>Type free -m again. You see that the new swap space has been added to your server.</li> </ol>"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%202/14.%20Managing%20Storage/#adding-swap-files","title":"Adding Swap Files","text":"<p>If you do not have free disk space to create a swap partition and you do need to add swap space urgently, you can use a swap file as well. From a performance perspective, it does not even make that much difference if a swap file is used instead of a swap device such as a partition or a logical volume, and it may help you fulfill an urgent need in a timely manner.</p> <p>To add a swap file, you need to create the file first. The dd if=/dev/zero of=/ swapfile bs=1M count=100 command would add 100 blocks with a size of 1 MiB from the /dev/zero device (which generates 0s) to the /swapfile file. The result is a 100-MiB file that can be configured as swap. To do so, you can follow the same procedure as for swap partitions. First use mkswap /swapfile to mark the file as a swap file, and then use swapon /swapfile to activate it.</p>"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%202/14.%20Managing%20Storage/#mounting-file-systems","title":"Mounting File Systems","text":"<p>To use a partition, you actually need to mount it. By mounting it, you make its contents accessible through a specific directory.  To mount a filesystem, we need to know: - What to mount - Where to mount it - What file system to mount - Mount options</p>"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%202/14.%20Managing%20Storage/#how-to-mount-a-filesystem-manually","title":"How To Mount a Filesystem Manually","text":"<p>[!TIP] The /mnt directory can be used to test mounts. </p> <pre><code># Mount the filesystem on /dev/sda5 on the /mnt directory\nmount /dev/sda5 /mnt\n\n#Mount using UUID\nmount UUID=\"42f419c4-633f-4ed7-b161-519a4dadd3da\" /mnt\n\n#Unmount. You can either use the device name or mount point\numount /dev/sda5 \n</code></pre>"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%202/14.%20Managing%20Storage/#mounting-automatically-through-fstab","title":"Mounting Automatically Through fstab","text":"<ol> <li>From a root shell, type <code>blkid</code>. Use the mouse to copy the UUID=\"nnnn\" part for /dev/sda5.</li> <li>Type mkdir -p /mounts/data to create a mount point for this partition.</li> <li>Open /etc/fstab in an editor and add the following line: UUID=\"nnnn\" /mounts/data xfs defaults 1 2</li> <li>Before you attempt an automatic mount while rebooting, it is a good idea to test the configuration. Type mount -a. This command mounts everything that is specified in /etc/fstab and that has not been mounted already.</li> <li>Type df -h to verify that the partition has been mounted correctly.</li> </ol> <p>![[Pasted image 20220817065549.png]] 1. Once you add your newly created partitions, save your changes. 2. Make your corresponding directories. For this example, those were /xfs and /ext4 3. Then run <code>systemctl daemon-reload</code> 4. Then run <code>mount -a</code></p>"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%202/14.%20Managing%20Storage/#note-on-naming","title":"Note on Naming","text":"<p>In fstab in the first column, don't use the device name. Instead use its UUID or create a label for it. Why? Because <code>/dev/nvme0n3p1</code> could change. Might not, but it could. To use the UUID: - Use the <code>blkid</code> command, then in fstab, you'd use UID={ID}.  To create your own label: - Use <code>tune2fs -L {NAME} {DEVICE}</code>     - <code>tune2fs -L TEST /dev/nvme0n3p1</code> - If the filesystem is XFS, use <code>xfs_admin -L</code></p>"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%202/15.%20Managing%20Advanced%20Storage/","title":"LVM","text":"<p>Logical Volume Manager allows you to dynamically grow a partition when it is running out of space. </p>"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%202/15.%20Managing%20Advanced%20Storage/#architecture","title":"Architecture","text":"<p>![[Pasted image 20220815191553.png|1000 ]]</p>"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%202/15.%20Managing%20Advanced%20Storage/#lvm-features","title":"LVM Features","text":"<ul> <li>LVM offers a flexible solution for managing storage. Volumes are no longer bound to the restrictions of physical hard drives. </li> <li>Snapshots, which are essential to backup strategies.</li> <li>The ability to replace failing hardware easily. <ul> <li>If a hard disk is failing, data can be moved within the volume group (through the <code>pvmove</code> command), the failing disk can then be removed from the volume group, and a new hard disk can be added dynamically, without requiring any downtime for the logical volume itself.</li> </ul> </li> </ul>"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%202/15.%20Managing%20Advanced%20Storage/#extents","title":"Extents","text":"<p>Extents are the elementary blocks of LVM allocation. The extent size can be defined while defining the volume group. For example <code>vgcreate -s 8M vgdata /dev/sdb1</code>. This creates a volume group with an extent size of 8MB. All of the LVM logical volumes built from this volume group will use the same extent size. You can use <code>vgdisplay</code> to check the extent size. Look for <code>PE Size</code>. You can also check how many extents with the <code>lvdisplay</code> command. Just look for <code>Current LE</code></p>"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%202/15.%20Managing%20Advanced%20Storage/#extent-amount","title":"Extent Amount","text":"<p>`lvcreate -l </p>"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%202/15.%20Managing%20Advanced%20Storage/#lvm-size","title":"LVM Size","text":"<p><code>lvcreate -L</code></p>"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%202/15.%20Managing%20Advanced%20Storage/#extent-size","title":"Extent Size","text":"<p>`vgcreate -s</p>"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%202/15.%20Managing%20Advanced%20Storage/#creating-logical-volumes","title":"Creating Logical Volumes","text":"<p>Creating logical volumes involves creating 3 layers in the LVM architecture: 1. Convert physical devices into physical volumes 2. Create the volume group and assign PVs to it. 3. Create the logical volume itself. </p> <p>[!TIP] For the exam, you must memorize pv, vg, and lv. Remember though, use tab to see their options. </p>"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%202/15.%20Managing%20Advanced%20Storage/#create-the-partition","title":"Create The Partition","text":"<ol> <li><code>parted /dev/{deviceName}</code></li> <li>It will ask for a partition table<ol> <li>msdos or gpt ![[Pasted image 20220902124750.png]]</li> </ol> </li> <li><code>mkpart</code></li> <li>It will ask for a partition name:<ol> <li>Set it to <code>lvm1</code></li> </ol> </li> <li>File System Type<ol> <li>Just press <code>enter</code></li> </ol> </li> <li>Set the start point</li> <li>Set the end point</li> <li>Verify with <code>print</code></li> <li>From the print command, get the number of the partition and type <code>set {number} lvm on</code></li> <li><code>quit</code> ![[Pasted image 20220902124832.png]]</li> </ol>"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%202/15.%20Managing%20Advanced%20Storage/#create-the-physical-volume","title":"Create The Physical Volume","text":"<ol> <li><code>pvcreate /dev/{partition}</code><ol> <li>You should receive a success message ![[Pasted image 20220902124439.png]]</li> </ol> </li> </ol>"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%202/15.%20Managing%20Advanced%20Storage/#create-the-volume-group","title":"Create The Volume Group","text":"<ol> <li><code>vgcreate vgdata /dev/{partition}</code><ol> <li>Again, you should receive a success message ![[Pasted image 20220902124506.png]]</li> </ol> </li> </ol>"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%202/15.%20Managing%20Advanced%20Storage/#create-the-logical-volume","title":"Create The Logical Volume","text":"<ol> <li><code>lvcreate -n lvdata -L 812M vgdata</code> ![[Pasted image 20220902124540.png]]</li> </ol>"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%202/15.%20Managing%20Advanced%20Storage/#putting-filesystem-on-the-logical-volume","title":"Putting Filesystem on the Logical Volume","text":"<ol> <li>mkfs.xfs /dev/vgdata/lvdata  ![[Pasted image 20220902124614.png]]</li> </ol>"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%202/15.%20Managing%20Advanced%20Storage/#mount-it-in-fstab","title":"Mount it in FSTAB","text":"<ol> <li>Create your mount point<ol> <li>mkdir /mounts/lvm1</li> </ol> </li> <li>vim /etc/fstab<ol> <li>![[Pasted image 20220902055615.png]]</li> </ol> </li> <li>mount -a</li> <li>Reboot!</li> </ol>"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%202/15.%20Managing%20Advanced%20Storage/#resizing-lvm-logical-volumes","title":"Resizing LVM Logical Volumes","text":"<p>To increase the size of a logical volume, you need to have disk space available in the volume group, so we address that first.</p> <p>[!TIP] The size of an XFS file system cannot be decreased; it can only be increased. If you need a file system that can be shrunk in size, use Ext4, not XFS.</p>"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%202/15.%20Managing%20Advanced%20Storage/#resizing-volume-groups","title":"Resizing Volume Groups","text":"<p>The <code>vgextend</code> command is used to add storage to a volume group, and the <code>vgreduce</code> command is used to take physical volumes out of a volume group. For the exam, you WILL need to know how to extend. Here are the steps: 1. Make sure that a physical volume or device is available to be added to the volume group. 2. Use <code>vgextend</code> to extend the volume group. The new disk space will show immediately in the volume group. 3. Verify everything with the <code>vgs</code> command. </p>"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%202/15.%20Managing%20Advanced%20Storage/#resizing-logical-volumes-and-file-systems","title":"Resizing Logical Volumes and File Systems","text":"<p>Logical volumes can be extended with the <code>lvextend</code> command. This command has a very useful option -r to take care of extending the file systems on the logical volume at the same time; it is recommended to use this option and not the alternative approach that separately extends the logical volumes and the file systems on top of the logical volumes. The easiest and most intuitive way to do that is by using -L followed by a + sign and the amount of disk space you want to add, as in <code>lvresize -L +1G -r /dev/vgdata/lvdata</code>.</p>"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%202/15.%20Managing%20Advanced%20Storage/#extents-lvm","title":"extents  #lvm","text":""},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%202/9.%20Managing%20Software/","title":"Managing Software Packages With Yum","text":""},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%202/9.%20Managing%20Software/#specifying-which-repo-to-use","title":"Specifying Which Repo To Use","text":""},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%202/9.%20Managing%20Software/#creating-your-own-repo","title":"Creating Your Own Repo","text":"<ol> <li>MAKE SURE YOUR DISC IS ACTUALLY LOADED</li> <li><code>dd if=/dev/sr0 of=/rhel9.iso bs=1M</code><ol> <li>substitute the 9 with whatever version of RHEL youre using.</li> </ol> </li> <li><code>mkdir /repo</code></li> <li>vim /etc/fstab<ol> <li>Add the following line:<ol> <li>/rhel9.iso              /repo                   iso9660 defaults        0 0</li> </ol> </li> </ol> </li> <li><code>systemctl daemon-reload</code></li> <li><code>mount -a</code></li> <li>Create two files<ol> <li><code>/etc/yum.repos.d/appstream.repo</code></li> <li><code>/etc/yum.repos.d/base.repo</code></li> </ol> </li> </ol> <pre><code>[appstream]\nname=appstream\nbaseurl=file:///repo/AppStream\ngpgcheck=0       \n</code></pre> <p><pre><code>[base]\nname=base\nbaseurl=file:///repo/BaseOS\ngpgcheck=0\n</code></pre> To tell your server which repository to use, you need to create a file with a name that ends in .repo in the directory /etc/yum.repos.d. In that file you need the following contents</p> <ul> <li><code>[label]</code>The .repo file can contain different repositories, each section starting with a label that identifies the specific repository.</li> <li><code>name=</code> - Use this to specify the name of the repository you want to use.</li> <li><code>baseurl=</code> - This option contains the URL that points to the specific repository location.</li> </ul>"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%202/9.%20Managing%20Software/#using-yum","title":"Using YUM","text":"Task Explanation search Search for the exact name of a package. <code>[what] provides */name</code> Perform a deep search in the package to look for specific files within the package. info Provide more infor about a package install Install a package remove Remove a package <code>list [all \\| installed]</code> List all or installed packages group list List package groups group install Install all packages from a group update Update packages specified clean all Remove all stored metadata"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%202/9.%20Managing%20Software/#yum-groups","title":"Yum Groups","text":"<p>Yum groups are provided to give access to specific categories of software</p>"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%202/9.%20Managing%20Software/#managing-package-module-streams","title":"Managing Package Module Streams","text":"<p>In RHEL, different versions of the same package can be offered using Package Module Streams. To separate core operating system packages from user-space packages, RHEL 8 provides two main repositories, referenced earlier: BaseOS and Application Stream. In BaseOS you\u2019ll find core operating system packages as RPM packages. The life cycle of these packages is comparable to the life cycle of previous RHEL versions</p>"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%202/9.%20Managing%20Software/#understanding-modules","title":"Understanding Modules","text":"<p>A module describes a set of RPM packages that belong together. Each module can have one or more application stream. A stream contains one specific version, and updates are provided for a specific stream.  Only one stream can be enabled at a time. Modules can also have more that one profile. A profile is al ist of packages that are installed together for a particular use case. </p> Item Explanation RPM The default package format. Contains files, as well as metadata that describes how to install the files. Optionally may contain pre- and post-installation scripts as well. Module A delivery mechanism to install RPM packages. In a module different versions and profiles can be provided. Application stream A specific version of the module. Profile A collection of packages that are installed together for a particular use case"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%202/9.%20Managing%20Software/#managing-modules","title":"Managing Modules","text":"<p>The <code>yum module</code> command is used to manage module properties. To get an idea of what modules are available, run <code>yum module list</code>. After you find out what module streams are available, run <code>yum module info</code>. Once you have the info you need, the next step is to enable a module stream and install modules. To use a specific version, you'd run something like <code>yum module enable perl 5.24</code> . If, for instance, you are now on php:7.1 and you want to change to php:7.2, you just have to type <code>yum module install php:7.2</code>. This will disable the old stream and enable the new stream. After doing this, to ensure that all dependent packages that are not in the module itself are updated as well, you should type <code>yum distro-sync</code> to finalize the procedure.</p>"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%202/9.%20Managing%20Software/#managing-software-packages-with-rpm","title":"Managing Software Packages with RPM","text":"<p>Before repos, people used RPM. But this wasn't good with handling dependencies, so don't use it anymore. </p>"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%202/9.%20Managing%20Software/#rpm-filenames","title":"RPM Filenames","text":"<p>When you\u2019re working with RPM packages directly, it makes sense to understand how the RPM filename is composed. A typical RPM filename looks like <code>autofs-5.0.7-40.el7.x86_64.rpm</code>. This name consists of several parts:</p> <ul> <li><code>autofs</code>: The name of the actual package.</li> <li><code>5.0.7</code>: The version of the package. This normally corresponds to the name of the package as it was released by the package creator</li> <li><code>-40</code>: The subversion of the package.</li> <li><code>el7</code>: The Red Hat version this package was created for. -<code>x86_64</code>: The platform (32 bits or 64 bits) this package was created for.</li> </ul>"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%202/9.%20Managing%20Software/#querying-the-rpm-database","title":"Querying the RPM Database","text":"<p>The rpm command enables you to get much information about packages. Using RPM queries can be a really useful way to find out how software can be configured and used. </p> <p>[!TIP] RPM queries by default are used on the RPM database, and what you are querying are installed RPM packages. It sometimes makes sense to query an RPM package file before actually installing it. To do this, you need to add the -p option to the query, because without the -p option, you will be querying the database, not the package file.</p> Command Use rpm -qf Uses a filename as its argument to find the specific RPM package a file belongs to. rpm -ql Uses the RPM database to provide a list of files in the RPM package. rpm -qi Uses the RPM database to provide package information (equivalent to yum info). rpm -qd Uses the RPM database to show all documentation that is available in the package. rpm -qc Uses the RPM database to show all configuration files that are available in the package. rpm -q --scripts Uses the RPM database to show scripts that are used in the package. This is particularly useful if combined with the -p option. rpm -qp \\&lt;pkg&gt; The -p option is used with all the previously listed options to query individual RPM package files instead of the RPM package database. Using this option before installation helps you find out what is actually in the package before it is installed. rpm -qR Shows dependencies for a specific package. rpm -V Shows which parts of a specific package have been changed since installation. rpm -Va Verifies all installed packages and shows which parts of the package have been changed since installation. This is an easy and convenient way[\u2026]"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%203/16.%20Basic%20Kernel%20Management/","title":"16. Basic Kernel Management","text":"<p>COME BACK TO THIS AS ITS NOT ON RHCSA</p>"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%203/17.%20Managing%20and%20Understandning%20the%20Boot%20Procedure/","title":"The Boot Process","text":"<p>![[Boot_Process.png | 300]]</p>"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%203/17.%20Managing%20and%20Understandning%20the%20Boot%20Procedure/#boot-process-boot","title":"boot-process #boot","text":""},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%203/17.%20Managing%20and%20Understandning%20the%20Boot%20Procedure/#systemd-targets","title":"Systemd Targets","text":"<p>A Systemd target is basically just a group of units that belong together. Isolatable targets contain everything a system needs to boot or change its current state.</p>"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%203/17.%20Managing%20and%20Understandning%20the%20Boot%20Procedure/#working-with-targets","title":"Working With Targets","text":"<p>Working with targets comes down to 3 common tasks: -   Adding units to be automatically started -   Setting a default target -   Running a non-default target to enter troubleshooting mode</p>"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%203/17.%20Managing%20and%20Understandning%20the%20Boot%20Procedure/#target-units","title":"Target Units","text":"<p>Behind a target there is some configuration. This configuration consists of two parts:</p> <ul> <li>The target unit file</li> <li>The \u201cwants\u201d directory, which contains references to all unit files that need to be loaded when entering a specific target</li> </ul>"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%203/17.%20Managing%20and%20Understandning%20the%20Boot%20Procedure/#isolating-targets","title":"Isolating Targets","text":"<p>By isolating a target, you start that target with all of its dependencies. Only targets that have the isolate option enabled can be isolated.  To isolate a target, use the <code>systemctl isolate</code> command. The following targets can be isolated:</p> <ul> <li>poweroff.target</li> <li>rescue.target</li> <li>multi-user.target </li> <li>graphical.target </li> <li>reboot.target</li> </ul>"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%203/17.%20Managing%20and%20Understandning%20the%20Boot%20Procedure/#setting-the-default-target","title":"Setting the Default Target","text":"<p>Type <code>systemctl get-default</code> to see the current default target and use <code>systemctl set-default</code> to set the desired default target.</p>"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%203/17.%20Managing%20and%20Understandning%20the%20Boot%20Procedure/#booting-into-a-specific-target","title":"Booting Into a Specific Target","text":"<ul> <li>On theGrub 2 boot prompt, use <code>systemctl.unit=xxx.target</code> to boot into a specific target. <ul> <li>![[Pasted image 20220821143355.png|700]]</li> </ul> </li> <li>To change between targets on a running system, use <code>systemctl isolate xxx.target</code></li> </ul>"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%203/17.%20Managing%20and%20Understandning%20the%20Boot%20Procedure/#working-with-grub2","title":"Working With GRUB2","text":"<p>The GRUB 2 boot loader makes sure that you can boot Linux. GRUB 2 is installed in the boot sector of your server\u2019s hard drive and is configured to load a Linux kernel and the initramfs:</p> <ul> <li>The kernel is the heart of the operating system, allowing users to interact with the hardware that is installed in the server.</li> <li>The initramfs contains drivers that are needed to start your server. It contains a mini file system that is mounted during boot. In it are kernel modules that are needed during the rest of the boot process (for example, the LVM modules and SCSI modules for accessing disks that are not supported by default).</li> </ul>"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%203/17.%20Managing%20and%20Understandning%20the%20Boot%20Procedure/#runtime-parameters","title":"Runtime Parameters","text":"<p>Use  the <code>-e</code> command</p>"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%203/17.%20Managing%20and%20Understandning%20the%20Boot%20Procedure/#persistant-parameters","title":"Persistant Parameters","text":"<p>To apply changes to the GRUB 2 configuration, the starting point is the <code>/etc/default/grub</code> file, which has options that tell GRUB what to do and how to do it. After writing changes, use one of the following commands: - <code>grub2-mkconfig -o /boot/grub2/grub.cfg</code> - <code>grub2-mkconfig -o /boot/efi/EFI/redhat/grub.cfg</code></p>"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%203/18.%20Troubleshooting/","title":"Changing The Root Password","text":"<ol> <li>ctrl + e</li> <li>In linux add <code>init=/bin/bash</code> at the end of the line. </li> <li>ctrl + x</li> <li>mount -o remount,rw /</li> <li>passwd</li> <li>touch /.autorelabel</li> <li>exec /usr/lib/systemd/systemd</li> </ol>"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%203/18.%20Troubleshooting/#filesystem-problems","title":"Filesystem Problems","text":"<p>Since you'll be editing fstab a lot, you might make a typo. A dead giveaway is after rebooting, you see the message <code>Give root password for maintenance</code> To fix: - After you enter the root password, you can edit /etc/fstab, and see what the problem is. - Remount filesystem in read/write state and edit /etc/fstab</p> <p>If you mess up the root filesystem name in fstab, no biggie. Why? Because it's already listed as an argument of the linux kernel in the grub menu. </p> <p>[!TIP] It's better to avoid problems, so you should just run <code>mount -a</code> whenever editing fstab.</p>"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%203/18.%20Troubleshooting/#network-issue","title":"Network Issue","text":"<p>Some common scenarios are: - Wrong subnet mask - Wrong router - DNS not working</p> <p>![[Pasted image 20220823064253.png]] - Use ip a to check the IP addresses. - ![[Pasted image 20220823064405.png|800]]     - We can see the following IP is missing a subnet mask     - <code>ip a d 192.168.4.235/32 dev ens</code>     - <code>ip a a dev ens33 192.168.4.235/24</code></p> <p>But now when we ping, we get a <code>Network is unreachable</code> error. This is indicative of a router issue. So lets check the routing table with <code>ip route show</code> ![[Pasted image 20220823064737.png|800]]</p> <p>Looks like we're missing a default route. Add one with <code>ip route add default via 192.168.4.2</code>  The original ping command should be working now. Make sure these settings stay persistent by adding them with nmtui. </p>"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%204/20.%20Configuring%20SSH/","title":"Key Based Authentication","text":"<p>Passwords are great, but even the strongest can be guessed. With <code>ssh-keygen</code> two keys are created. 1. Private Key - This is like your identity. NEVER SHARE THIS 2. Public Key - This is copied to the server you're trying to access</p> <p>When a user or process requests a connection to the remote server using the SSH client, a challenge-response sequence is initiated to complete authentication. The SSH server recognizes that a connection is being requested and sends an encrypted challenge request using the shared public key information. The SSH client then decrypts the challenge message and responds back to the server. The user or process must respond correctly to the challenge to be granted access. This\u00a0challenge-response\u00a0sequence happens automatically between the SSH client and server without any manual action by the user.</p>"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%204/20.%20Configuring%20SSH/#how-to","title":"How To","text":"<ol> <li><code>ssh-keygen</code></li> <li><code>ssh-copy-id {host/ip address}</code></li> </ol>"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%204/22.%20Managing%20SELINUX/","title":"The Need for SELinux","text":"<p>Linux is built on Unix security.  Unix security consists of different solutions that were never developed with current IT security needs in mind. SELinux provides a complete and mandatory security solution. The basic principle is that if it isn't specifically allowed, IT WILL BE DENIED.</p>"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%204/22.%20Managing%20SELINUX/#selinux-modes","title":"SELinux Modes","text":"<p>SELinux is enabled and disabled at the kernel level. This means to switch between off and on, you need to reboot your system. There is a trouble shooting mode, so if it is enabled, you can either set to <code>enforcing</code> or <code>permissive</code>. Permissive does logging, but it doesn't block anything. Great for troubleshooting. <code>getenforce</code> shows the current state. To switch between these two states, use the <code>setenforce</code> command. Edit <code>/etc/sysconfig/selinux</code> to manage the default state of SELinux. On the exam, DO NOT set it to <code>disabled</code>. </p>"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%204/22.%20Managing%20SELINUX/#context-labels-and-booleans","title":"Context Labels and Booleans","text":"<p>Context settings are an important part of SELinux operations. The context is a label that can be applied to different objects. Context labels define the nature of the object, and SELinux rules are created to match context labels of source objects to the context labels of target objects. To see current context settings on the objects in the previous bulleted list, many commands offer support for the <code>-Z</code> option. For example, <code>ls -Z</code> Every context label always consists of three different parts: 1. User 2. Role  3. Type - This is all we care about for the exam.</p>"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%204/22.%20Managing%20SELINUX/#setting-context-label","title":"Setting Context Label","text":"<ul> <li>Use <code>semanage fcontext</code><ul> <li>To enforce the policy, use <code>restorecon</code>.</li> </ul> </li> </ul>"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%204/22.%20Managing%20SELINUX/#selinux-log-messages","title":"SELinux Log Messages","text":"<ul> <li>SELinux uses <code>auditd</code> to write log messages. </li> <li>Ensure <code>sealert</code> is available/enabled.<ul> <li><code>sealert</code></li> </ul> </li> </ul>"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%204/22.%20Managing%20SELINUX/#troubleshooting","title":"Troubleshooting","text":"<p>Oh no! Apache isn't working.  ![[Pasted image 20220825055903.png]]</p> <ol> <li>Turn off SELinux, and then try to start apache again.      1.<code>setenforce 0</code><ol> <li><code>systemctl start httpd</code></li> </ol> </li> <li>Ok, it's working so it must be an SELinux issue. </li> <li><code>grep sealert /var/log/messages</code><ol> <li>![[Pasted image 20220825060631.png]]</li> </ol> </li> <li>Run the sealert command from the log messages</li> <li>It's literally telling you what command to run:<ol> <li>![[Pasted image 20220825060844.png]]</li> </ol> </li> <li><code>semanage port -a -t http_port_t -p tcp 83</code></li> <li><code>setenforce 1 to turn SELinux back on</code></li> <li><code>systemctl stop httpd; systemctl start httpd</code></li> <li><code>systemctl status httpd</code><ol> <li>![[Pasted image 20220825061143.png]]</li> </ol> </li> </ol>"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%204/23.%20Configuring%20a%20Firewall/","title":"Firewalld","text":"<p>Firewalld uses different components to make firewalling easier: - Service - Zone - Ports</p>"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%204/23.%20Configuring%20a%20Firewall/#adding-a-service","title":"Adding a Service","text":"<p>Lets say you want to add the ftp service. 1. <code>firewall-cmd --add-service=ftp</code> 2. Verify with <code>firewall-cmd --list-all</code> 3. This is not persistent, though. To make it so, you must add the permanent flag     1. <code>firewall-cmd --add-service=ftp --permanent</code>     2. <code>firewall-cmd --add-service=ftp</code></p>"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%204/24.%20Accessing%20Network%20Storage%20%28NFS%29/","title":"Setting up an NFS Server","text":"<ol> <li>Make sure nfs is installed<ol> <li><code>systemctl status nfs-server</code></li> </ol> </li> <li>If it is not, install it.<ol> <li><code>yum install nfs-utils</code></li> </ol> </li> <li>Create the share directory.<ol> <li><code>mkdir /data</code></li> </ol> </li> <li>vim /etc/exports<ol> <li>![[Pasted image 20220827152726.png]]</li> </ol> </li> <li>systemctl enable --now nfs-server</li> <li>Configure the firewall rules</li> <li>firewall-cmd  --add-service=nfs     1.<code>firewall-cmd  --add-service=mountd</code><ol> <li><code>firewall-cmd  --add-service=rpc-bind</code></li> <li><code>firewall-cmd  --add-service=rpc-bind--permanent</code></li> <li><code>firewall-cmd  --add-service=rpc-bind --permanent</code></li> <li><code>firewall-cmd  --add-service=mountd --permanent</code></li> <li><code>firewall-cmd  --add-service=nfs --permanent</code></li> </ol> </li> </ol>"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%204/24.%20Accessing%20Network%20Storage%20%28NFS%29/#mounting-nfs-shares","title":"Mounting NFS Shares","text":"<ol> <li><code>showmount -e {nfs-host}</code></li> <li>Add it in fstab<ol> <li>![[Pasted image 20220827153428.png]]</li> </ol> </li> <li>Check your work with <code>mount -a</code></li> <li>Reboot to test. </li> </ol>"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%204/24.%20Accessing%20Network%20Storage%20%28NFS%29/#netdev-vs-defaults","title":"Netdev vs Defaults","text":"<ul> <li><code>_netdev</code>\u00a0\u2013 When present in\u00a0<code>/etc/fstab</code>, prevents the client from attempting to mount the NFS file system until the network has been enabled.</li> </ul>"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%204/24.%20Accessing%20Network%20Storage%20%28NFS%29/#nfs-netdev-_netdev","title":"nfs #netdev #_netdev","text":""},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%204/27.%20Containers/","title":"Understanding Containers","text":"<p>Containers run applications, including all of the application dependencies, but in the end, the purpose of a container is to run an application. In some cases, the application is a process that is meant to be running all the time. In other cases, the application is just a shell, or another command that runs, produces its result, and then exits. - A container is complete package to run an application, which contains all application dependencies.  - Containers run on top of a container engine that is offered by the host operating system. For example, Docker.  - System containers are used as the foundation to build custom images, and don't come with standard applications. </p>"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%204/27.%20Containers/#containers-are-not-virtual-machines","title":"Containers are NOT Virtual Machines","text":"<p>Sometimes, a container is considered to be something like a virtual machine. If you start an Ubuntu virtual machine, for instance, it starts and will keep on running until somebody comes and uses it. Containers are not virtual machines. Every container image is configured with a default command, and as just discussed, the container runs the default command and then exits as it\u2019s done after running the command.</p>"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%204/27.%20Containers/#requirements","title":"Requirements","text":"<ul> <li>Namespaces for isolation between processes</li> <li>Control Group for resource management</li> <li>SELinux to ensure security </li> <li>Containers  usually run a single application<ul> <li>Multiple applications can be connected in Microservices<ul> <li>To manage multiple containers at an Enterprise level, orchestration is needed. </li> <li>Red Hat OpenShift, or Kubernetes, for example. <ul> <li>Red Hat OpenShift is the RH Kubernetes distribution. it offers additional features to Kubernetes. </li> </ul> </li> </ul> </li> </ul> </li> </ul>"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%204/27.%20Containers/#containers-on-rhel-8","title":"Containers on RHEL 8","text":"<ul> <li>RHEL no longer offers support for Docker :(. No worries, they have new utilities<ul> <li>podman - Used to manage containers and container images. </li> <li>buildah - Used to create new container images</li> <li>skopeo - Used to inspect, delete, copy, and sign images. </li> </ul> </li> </ul>"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%204/27.%20Containers/#rootless-containers","title":"Rootless Containers","text":"<ul> <li>If containers need to run a process on a privileged port,, they need to run with root privileges. </li> <li>Rootless containers will run as a non-root user<ul> <li>This is actually not bad because running a container as root is dangerous. </li> </ul> </li> </ul>"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%204/27.%20Containers/#scaling-containers","title":"Scaling Containers","text":"<p>In an enterprise environment, you need your containers to have additional features. For this, use OpenShift or Kubernetes. </p>"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%204/27.%20Containers/#running-containers-on-rhel-8","title":"Running Containers on RHEL 8","text":""},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%204/27.%20Containers/#images","title":"Images","text":"<p>The foundation of every container is the container image. The container is a running instance of the image, where a writable layer is added to store changes made to the container. To find available images, you can use the <code>podman search</code> command.</p> <p>To inspect images before pulling them, use <code>skopeo</code> To inspect images that are available locally, use <code>podman</code> <code>podman inspect registry.redhat.io/ubi8/ubi</code></p>"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%204/27.%20Containers/#image-housekeeping","title":"Image Housekeeping","text":"<p>When newer versions of images become available, the old version will be kept on your system.  1. <code>podman images</code> - Get a list of all images 2. <code>podman rmi</code> - Remove images. </p>"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%204/27.%20Containers/#registries","title":"Registries","text":"<p>Container images are typically fetched from container registries, which are specified in the <code>/etc/containers/registries.conf</code> configuration file. A user who runs a rootless container can create a file <code>~/.config/containers/registries.conf</code>. In case of conflict, settings in the user-specific file will override settings in the generic file.</p> <p>In the registries.conf file, you\u2019ll find three important sections: -   <code>registries.search</code> - lists the default registries that are used. When you search for an image, the registries are used in the order specified here.  -   <code>registries.insecure</code> - can be used to add registries that are not secured with TLS keys. -   <code>registries.block</code> - can be used to exclude registries that have been specified elsewhere. Using [registries.block] is useful in a user registries.conf file, to disable access to specific registries that were opened in /etc/containers/ registries.conf.</p>"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%204/27.%20Containers/#managing-containers","title":"Managing Containers","text":""},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%204/27.%20Containers/#running-commands-in-a-container","title":"Running Commands in a Container","text":"<p>Use <code>podman exec</code> to run commands inside of containers. There are two ways to run these commands.  1. As a one-shot      1. <code>podman exec mycontainer uname -r</code> 2. Interactively      1. <code>podman exec -it mycontainer /bin/bash</code></p>"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%204/27.%20Containers/#container-ports","title":"Container Ports","text":"<p>Rootless containers in podman run without a network address because a rootless container has insufficient privileges to allocate a network address. To make the service running in the container accessible from the outside, you need to configure port forwarding, where a port on the container host is used to access a port in the container application.</p> <p>Use <code>podman run --name nginxport -d -p 8080:80 nginx</code> to run the nginx image as a container and make the nginx process accessible on host port 8080, which will be forwarded to the standard http port 80 on which nginx is offering its services. Don\u2019t forget to use<code>sudo firewall-cmd --add-port 8080/tcp --permanent</code>; <code>sudo firewall-cmd --reload</code> to open the port in the firewall as well afterward! </p>"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%204/27.%20Containers/#container-environment-variables","title":"Container Environment Variables","text":"<p>mariadb is an example of a container that requires environment variables, so we'll be useing that as an example here. </p> <p>If a container needs environment variables to do its work, there are a few ways to figure this out: - Just run the container without any environment variables. It will immediately stop, and the main application will generate an error message. Use <code>podman logs</code> on your container to read the log for information on what went wrong. - Use <code>podman inspect</code> to see whether there is a usage line in the container image that tells you how to run the container.</p> <p>After you\u2019ve found out how to run the container, run it, specifying the environment variables with the <code>-e</code> option. To run a mariadb instance, for example, you can use <code>podman run -d -e MYSQL_ROOT_PASSWORD=password -e MYSQL_USER=anna -e MYSQL_PASSWORD=password -e MYSQL_ DATABASE=mydb -p 3306:3306 mariadb</code>.</p>"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%204/27.%20Containers/#container-storage","title":"Container Storage","text":"<p>By default, when you remove a container, all modifications that were made to that container are removed also. So, if you don't want this to happen, you need to add persistent storage. </p> <p>To add persistent storage to Podman containers, you bind-mount a directory on the host operating system into the container. A bind-mount is a specific type of mount, where a directory is mounted instead of a block device. To set up this storage solution, you need to prep first: 1. Ensure that the user account used in the container has access to the host directory, and set the SELinux context type to <code>container_file_t</code>     1. IF the container user is the owner of the host directory, the <code>:Z</code> option can be used.         1. <code>podman run -d -v /webfiles:/webfiles:Z nginx</code></p> <p>Okay, now we're ready to mount: 1. sudo mkdir /{DIRNAME} 2. sudo chmod o+w /{DIRNAME} 3. <code>sudo semanage fcontext -a -t container_file_t \"/{DIRNAME}(./*)?\"</code></p>"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%204/27.%20Containers/#containers-as-services","title":"Containers As Services","text":"<p>On a standalone platform where containers are running rootless containers, systemd is needed to autostart containers. To automatically start containers in standalone situation, you can create systemd user unit files for rootless containers and manage them with <code>systemctl</code> .</p> <p>In systemd, services are easily started and enabled with root permissions using commands like systemctl enable --now myservice.service. If no root permissions are available, you need to use systemctl --user. The --user option allows users to run the common systemd commands, but in user space only. This works for any service that can run without root permissions.</p> <p>When systemctl --user is used, services can be automatically started  only when a user session is started. To define an exception to that, you can use the loginctl session manager, which is part of the systemd solution to enable \u201clinger\u201d for a specific user account. If you use <code>loginctl enable-linger myuser</code>, you enable this for the user myuser. When linger is enabled, systemd services that are enabled for that specific user will be started on system start, not only when the user is logging in.</p>"},{"location":"Linux/RHCSA/Sander%20Van%20Vugt/Module%204/27.%20Containers/#the-process","title":"The Process","text":"<ol> <li>Use sudo useradd linda to create a user linda.</li> <li>Use sudo passwd linda to set the password for user linda.</li> <li>Type sudo loginctl enable-linger linda to enable the linger feature for user linda.</li> <li>Log in as user linda (no su or sudo).</li> <li>Type <code>mkdir -p ~/.config/systemd/user; cd ~/.config/systemd/user</code> to create and activate the directory where the systemd user files will be created.</li> <li>Use <code>podman run -d --name mynginx -p 8081:80 nginx</code> to start an nginx pod.</li> <li>Type <code>podman ps</code> to verify the nginx pod has been started.</li> <li>Create the systemd user files using <code>podman generate systemd --name mynginx --files</code>.</li> <li>A systemd unit file with the name <code>container-mynginx.service</code> is created.</li> <li>Use <code>vim container-mynginx.service</code> and change the WantedBy line such that it reads <code>WantedBy=default.target</code>.</li> <li>Type <code>systemctl --user daemon-reload</code> to ensure that systemd picks up the changes.</li> <li>Use <code>systemctl --user enable container-mynginx.service</code> to enable the systemd user service. (Do not try to start it because it has already been started!)</li> <li>Type <code>systemctl --user status container-mynginx.service</code> to verify the service has the state of enabled.</li> <li>Reboot your server, and after rebooting, verify that the container is automatically started.</li> </ol>"},{"location":"ansible/","title":"Test","text":""},{"location":"ansible/Ad_Hoc/","title":"Ad-Hoc","text":""},{"location":"ansible/Ad_Hoc/#title-docker-architecture","title":"title: Docker Architecture","text":""},{"location":"ansible/Ansible%20Basics/","title":"Ansible Basics","text":"<p>Control Node - Where Ansible software is installed. Consider it as an operator workstation, and not so much a server.  Managed Nodes - Computers running Windows or Linux, cloud instances, VMs, containers etc.. Inventory - Inventories organize managed nodes in centralized files that provide Ansible with system information and network locations. Using an inventory file, Ansible can manage a large number of hosts with a single command.</p>"},{"location":"ansible/Inventory/","title":"Inventory","text":"<p>Static A list of host names and IP addresses that can be managed by ansible Dynamic Dynamic Inventory can be used to discover inventory in dynamic environments such as cloud.</p>"},{"location":"ansible/Playbooks/","title":"Playbooks","text":"<p>They contain Plays (which are the basic unit of Ansible execution). This is both an \u2018execution concept\u2019 and how we describe the files on which\u00a0<code>ansible-playbook</code>\u00a0operates. Playbooks are written in YAML and are easy to read, write, share and understand.</p> <p>Here's an example <pre><code>---\n- name: deploy vsftpd\n- #Identifier. Can be used for documentation, or in tasks/handlers.\n  hosts: ansible2.example.com\n  # The host to connect to\n  tasks:\n    - name: install vsftpd\n      yum: name=vsftpd\n      #yum module - -   Installs, upgrade, downgrades, removes, and lists packages and groups with the\u00a0_yum_\u00a0package manager.\n    - name: enable vsftpd\n      service: name=vsftpd enabled=true\n      #service module - Controls services on remote hosts. Supported init systems include BSD init, OpenRC, SysV, Solaris SMF,   systemd, upstart.\n    - name: create readme\n      copy:\n      # copy module - -   Copy files to remote locations\n        content: \"WELCOME!\"\n        dest: /var/ftp/pub/README\n        force: no\n        mode: 0444\n</code></pre></p>"},{"location":"docker/","title":"Test","text":""},{"location":"docker/architecture/","title":"Docker Architecture","text":""},{"location":"docker/architecture/#docker-client","title":"Docker Client","text":"<p>The Docker client is the command line interface for interacting with the underlying Docker Ecosystem.The Docker Client abstracts the underlying complexity and provides users with a simple front end. This could be a graphical interface as Docker Desktop or a command line tool as Docker CLI. </p>"},{"location":"docker/architecture/#docker-host","title":"Docker Host","text":"<p>The docker host is the actual machine Docker is installed on. The Docker host can be a physical server, a virtual machine, or even a cloud instance. The host machine provides the resources required to run containers, such as CPU, memory, storage, and networking.</p>"},{"location":"docker/architecture/#docker-registries","title":"Docker Registries","text":"<p>A Docker registry stores Docker images. Docker Hub is a public registry that anyone can use, and Docker looks for images on Docker Hub by default. You can even run your own private registry.</p> <p>When you use the <code>docker pull</code> or docker run commands, Docker pulls the required images from your configured registry. When you use the docker push command, Docker pushes your image to your configured registry.</p>"},{"location":"docker/basics/","title":"Basics","text":""},{"location":"docker/basics/#runtimes","title":"Runtimes","text":"<p>runc is an example of a runtime</p>"},{"location":"docker/basics/#engines","title":"Engines","text":"<p>Docker or Podman are examples of container engines.</p>"},{"location":"kb/","title":"This is a test","text":""},{"location":"kubernetes/","title":"Test","text":""},{"location":"kubernetes/ckad/3_Understanding_Kubernetes/3_1_CNC/","title":"3.1 Cloud Native Computing","text":"<p>It's all about hosting the app. It should be hosted in the cloud. While being hosted in the cloud, the application is decoupled from specific servers.  You don't want your app to be tied to a specific server. With that being said, If an app is disconnected from a specific server, facilities must be provided to take care of specific features: - Access to configuration - Persistent Storage - Application Access</p> <p>Cloud Native takes care of these \ud83c\udf89</p> <p></p> <p>In the above diagram, config, storage, and access should be able to run on any one of the 4 servers. K8s takes care of this.</p>"},{"location":"kubernetes/ckad/3_Understanding_Kubernetes/3_2_how_k8s_enables_cncf/","title":"3.2 How K8s Enables CNCF","text":"<p>K8s Orchestrates containers. This means that it ensures that they are running where they need to be running. For example: - If your app os getting a huge influx of traffic, K8s can send traffic to another node. - If one of your hosts goes down, k8s can send traffic to a healthy node. </p> <p>Kubernetes is the open-source platform that allows containers to be used in a cloud native environment.</p> <p>To do so, it orchestrates containers, which means that it ensures that containers are running where they need to be running.</p> <p>Kubernetes also provides scalability: ensuring a sufficient amount of containers are running to deal with the current workload.</p> <p>The Kubernetes API defines a set of resource types, such as Pods, Deployment, and ConfigMaps that allow for storing information in a cloud native environment where no relation to specific servers exists.</p> <p></p>"},{"location":"kubernetes/ckad/3_Understanding_Kubernetes/3_5_k8s_architecture/","title":"Architecture","text":"<p>The control plane consists of one or more modules where the core services are running - kube-apiserver - Provides access to the API. - etcd - k8s database - kube-scheduler - Responsible for scheduling Pods at a specific location - kibe-controller-manager.</p> <p>Worker nodes run the containerized applications by using: - container runtimes - The part that runs containers - kubelet - The part that is contacted by the kube-scheduler to run the actual container in Pods.</p> <p></p> <p>When the user runs the <code>kubectl</code> command talks to the API server. When you create resouources (pods in this example), they are added to <code>etcd</code>. From there, the scheduler gets your resources from <code>etcd</code>, and will find eligible nodes</p>"},{"location":"kubernetes/ckad/3_Understanding_Kubernetes/3_6_essential_api_resources/","title":"Essential API Resources","text":"<p>K8s API resources allow for storing and running applications in a K8s environment</p> <p>Some of the essential resources include: - Pod - The smallest deployable unit in Kubernetes, which can contain one or more containers. - Deployments - A resource that manages the deployment of Pods, ensuring the desired number of replicas are running and enabling rolling updates.</p> <ul> <li> <p>Config Map - A resource to store non-confidential configuration data in key-value pairs, which can be injected into Pods as environment variables or mounted as files.</p> </li> <li> <p>Services - A way to expose a set of Pods as a network service, enabling stable networking for inter-Pod communication or external access.</p> </li> <li> <p>Ingress/Gateway API - A resource that manages external access to services, typically HTTP, providing load balancing, SSL termination, and routing.</p> </li> <li> <p>Persistent Volumes - A resource to provide long-term storage for Pods, allowing data to persist across Pod restarts.</p> </li> </ul>"},{"location":"kubernetes/ckad/3_Understanding_Kubernetes/3_6_essential_api_resources/#basic-resources-visualization","title":"Basic Resources Visualization","text":""},{"location":"kubernetes/ckad/5_Pod_Basic_Features/5_1_Options/","title":"Options For Running K8s Applications","text":"<ul> <li>The Pod is the minimal entity to run K8s applications.</li> <li>To run stateless applications, using Deployments is recommended becuase of the following:<ul> <li>Adds scalability </li> <li>Adds easy zero-downtime application updates</li> </ul> </li> <li>For stateful applications, the StatefulSet is used</li> <li>Helm package manager makes it easy to run applications and all required dependencies. </li> </ul>"},{"location":"kubernetes/ckad/5_Pod_Basic_Features/5_2_Pod_Structure_And_Use/","title":"Understanding Pods","text":"<p>The pod is the minimal entity managed by K8s. Pods add K8s properties to containers. For example:     - nodeSelector - Allows selection of the node that runs the Pod     - priority - Allows for adidng priority labels     - restartPolicy - Tells the cluster what to do if a pod fails.</p>"},{"location":"kubernetes/ckad/5_Pod_Basic_Features/5_2_Pod_Structure_And_Use/#disadvantages-to-running-pods-instead-of-deployments","title":"Disadvantages to Running Pods Instead of Deployments?","text":"<ul> <li>Standalone Pods are NOT rescheduled in case of failure</li> <li>Rolling updates dont apply to standalone pods. You can only bring the pod down and bring it back up with new settings</li> <li>They can't be scaled</li> <li>They can't be replaced automatically </li> </ul> <p>Note</p>"},{"location":"kubernetes/ckad/5_Pod_Basic_Features/5_2_Pod_Structure_And_Use/#standalone-pods-are-commonly-used-for-testing-and-troubleshooting","title":"Standalone pods are commonly used for testing and troubleshooting.","text":""},{"location":"kubernetes/ckad/5_Pod_Basic_Features/5_2_Pod_Structure_And_Use/#to-start-a-standalone-pod","title":"To start a Standalone Pod:","text":"<p><code>kubectl run podname --image=imagename</code></p>"},{"location":"kubernetes/ckad/5_Pod_Basic_Features/5_2_Pod_Structure_And_Use/#get-list-of-running-pods","title":"Get List of Running Pods:","text":"<p><code>kubectl get pods</code></p>"},{"location":"kubernetes/ckad/5_Pod_Basic_Features/5_2_Pod_Structure_And_Use/#get-properties-of-running-pods","title":"Get Properties of Running Pods","text":"<p><code>kubectl describe pod {podname}</code></p>"},{"location":"kubernetes/ckad/5_Pod_Basic_Features/5_3_Pods_The_DevOps_Way/","title":"5.3 Running Pods the DevOps Way","text":"<p>In DevOps the purpose is to deploy apps consistently. To do this, you use configuration as code. For K8s, instead of using commands, YAML manifest files are used, form which applications can be started. </p>"},{"location":"kubernetes/ckad/5_Pod_Basic_Features/5_3_Pods_The_DevOps_Way/#declarative-vs-imperative","title":"Declarative vs Imperative","text":"<ul> <li>Creating resources based on YAML files is referred to as declarative</li> <li>Creating resources from the command line is called imperative.</li> </ul> <p>Note</p> <p>On the exam, USE THE IMPERATIVE way. It'll be faster. </p>"},{"location":"kubernetes/ckad/5_Pod_Basic_Features/5_3_Pods_The_DevOps_Way/#k8s-yaml","title":"K8s YAML","text":"<p>All of the YAML manifest ingredients are defined as resource properties in the API. <pre><code>apiVersion: apps/v1\nkind: Pod\nmetadata:\n  name: nginx\nspec:\n  containers:\n    - name: nginx\n      image: nginx:latest\n</code></pre></p>"},{"location":"kubernetes/ckad/5_Pod_Basic_Features/5_3_Pods_The_DevOps_Way/#podspeccontainers-component","title":"pod.spec.containers Component","text":"<p>In the containers spec, different parts are commonly used</p> <ul> <li>name</li> <li>image</li> <li>command</li> <li>args</li> <li>env</li> </ul> <p>Note</p> <p>Use kubectl explain to get the above information.</p>"},{"location":"kubernetes/ckad/5_Pod_Basic_Features/5_3_Pods_The_DevOps_Way/#creating-resources-from-yaml-files","title":"Creating Resources from YAML Files","text":"<p><code>kubectl create -f resource.yaml</code> creates resources from a YAML file. If the resource already exists, it fails</p> <p><code>kubectl apply -f resource.yaml</code> Does the same as create BUT if the resource exists, it updates the properties that need updating</p> <p><code>kubectl delete -f resource.yaml</code> Deletes the resources as defined in the YAML file</p> <p><code>kubectl replace -f resource.yaml</code> replaces a current resource with the resource specification as in the YAML file</p>"},{"location":"kubernetes/ckad/5_Pod_Basic_Features/5_4_Generating_YAML_Files/","title":"5.4 Generating YAML Files","text":"<p>Note</p> <p>Do not write YAML files, GENERATE them!</p> <p>To generate YAML files, add <code>--dry-run=client -o yaml &gt; my.yaml</code> as an arg to <code>kubectl run</code> and <code>kubectl create</code>. </p> <ul> <li><code>dry-run=client</code> - All this is doing is generating code.</li> </ul> Generating the YAML Generating The YAMLmynginx.yaml <pre><code>kubectl run myginx --image=nginx --dry-run=client -o yaml &gt; mynginx.yaml\n</code></pre> <pre><code>apiVersion: v1\nkind: Pod\nmetadata:\ncreationTimestamp: null\nlabels:\n    run: myginx\nname: myginx\nspec:\ncontainers:\n- image: nginx\n    name: myginx\n    resources: {}\ndnsPolicy: ClusterFirst\nrestartPolicy: Always\nstatus: {}\n</code></pre> Applying The YAML ApplyingOutput <p><code>kubectl apply -f mynginx.yaml</code></p> <pre><code>pod/myginx created\n</code></pre> <p>Note</p> <p>If defining multiple resources in one YAML file, always seperate them with \"---\"</p>"},{"location":"kubernetes/ckad/5_Pod_Basic_Features/5_5_Multi_Container_Pods/","title":"5.5 Multicontianer Pods","text":"<p>One container pod is the standard and easier to build and maintain</p> <p>Note</p> <p>Lets say you want to create a pod with a web server and db containers. What if you need to update the db? You'll have to bring down the webserver. This is not ideal</p> <p>To create apps that consist of multiple containers , microservices should be defined. In a microservice, differnt independently managed Pods are connected by resources that can be provided by K8s.</p> <p>Multi-Container Pod Examples</p>"},{"location":"kubernetes/ckad/5_Pod_Basic_Features/5_5_Multi_Container_Pods/#sidecar-containers","title":"Sidecar Containers","text":"<p>Container that provides additional functionality to the main container, where it makes NO sense running this functionality in a seperate Pod. Think of logging, monitoring , and syncing. The main and sidecar have access to shared resources to exchange info.</p>"},{"location":"kubernetes/ckad/5_Pod_Basic_Features/5_6_Namespaced/","title":"5.5 Namespaces","text":"<p>\u2022 Kubernetes Namespace resources leverage Linux kernel namespaces to provide resource isolation. \u2022 Different Namespaces can be used to strictly separate between  resources and thus enable multi-tenancy. Namespaces are used to apply different security-related settings, \u2022 Role-Based Access Control (RBAC) \u2022 Quota \u2022 By installing complex Kubernetes applications in their own Namespace, managing them is easier</p> <p><code>kubectl get ... -A</code> Shows resources in all Namespaces <code>kubectl run ... -n</code> namespace Runs resources in a specific Namespace <code>kubectl create ns</code> {nsname} Creates a namespace</p>"},{"location":"kubernetes/ckad/5_Pod_Basic_Features/5_7_Pod_Troubleshooting/","title":"Troubleshooting Commands","text":"<ul> <li><code>kubectl get pods</code> Checks the current pod status</li> <li><code>kubectl describe pod {podname}</code> gets more info about pod status </li> <li><code>kubectl logs {podname}</code> Grabs the logs</li> <li><code>kubectl exec -it podname sh</code> Opens a shell on the Pod to analyze specific components</li> </ul>"},{"location":"kubernetes/ckad/5_Pod_Basic_Features/5_7_Pod_Troubleshooting/#scenario","title":"Scenario","text":"<p><code>kubectl run mydb --image=mariadb</code></p> <p><pre><code>[xavier@xa-dev-main ~]$ kubectl get pods\nNAME                        READY   STATUS             RESTARTS      AGE\nfirstapp-57d8d5d97f-gcrhl   1/1     Running            0             6d8h\nmydb                        0/1     CrashLoopBackOff   1 (14s ago)   27s\nmyginx                      1/1     Running            0             18h\n</code></pre> We can see mydb failed :(. Lets investigate</p> <pre><code>[xavier@xa-dev-main ~]$ kubectl logs mydb\n2024-09-29 08:59:57+00:00 [Note] [Entrypoint]: Entrypoint script for MariaDB Server 1:11.5.2+maria~ubu2404 started.\n2024-09-29 08:59:57+00:00 [Warn] [Entrypoint]: /sys/fs/cgroup///memory.pressure not writable, functionality unavailable to MariaDB\n2024-09-29 08:59:57+00:00 [Note] [Entrypoint]: Switching to dedicated user 'mysql'\n2024-09-29 08:59:57+00:00 [Note] [Entrypoint]: Entrypoint script for MariaDB Server 1:11.5.2+maria~ubu2404 started.\n2024-09-29 08:59:57+00:00 [ERROR] [Entrypoint]: Database is uninitialized and password option is not specified\n    You need to specify one of MARIADB_ROOT_PASSWORD, MARIADB_ROOT_PASSWORD_HASH, MARIADB_ALLOW_EMPTY_ROOT_PASSWORD and MARIADB_RANDOM_ROOT_PASSWORD\n</code></pre> <p>As we can see, we forgot to specify environment variables when creating the pod.</p>"},{"location":"kubernetes/ckad/6_Pod_Advanced_Features/6_1_Init_Containers/","title":"6.1 Init Containers","text":"<p>An init container is a special case of a ma multi-container pod where the init container runs to completion before the main container is started. Starting th emain container depends on the init container.</p> <pre><code>apiVersion: v1\nkind: Pod\nmetadata:\n  name: init-demo\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n    ports:\n    - containerPort: 80\n    volumeMounts:\n    - name: workdir\n      mountPath: /usr/share/nginx/html\n  # These containers are run during pod initialization\n  initContainers:\n  - name: install\n    image: busybox:1.28\n    command:\n    - wget\n    - \"-O\"\n    - \"/work-dir/index.html\"\n    - http://info.cern.ch\n    volumeMounts:\n    - name: workdir\n      mountPath: \"/work-dir\"\n  dnsPolicy: Default\n  volumes:\n  - name: workdir\n    emptyDir: {}\n</code></pre>"},{"location":"kubernetes/ckad/6_Pod_Advanced_Features/6_2_Sidecar_Containers/","title":"6.2 Sidecar Container","text":"<p>A sidecar container is an initContainer that has a restartPolicy set to Always. There is no \"sidecar\" container property. To create one just create an initContainer with the restartPolicy set to Always. Like a regular initContainer, the sidecar must complete once before the main Pod is started.</p>"},{"location":"kubernetes/ckad/6_Pod_Advanced_Features/6_3_Port_Forwarding/","title":"6.3 Port Forwarding","text":"<p>A very simple way to expose a Pod port on the kubectl host (your workstation) that forwards to the pod This is useful for TESTING Pod accessibility on a specific cluster node, not to expose it to external users. For example, if you want to verify that a pod is doing what it should be doing. In a live enviornment, you should use services or ingress.</p> <pre><code>[xavier@xa-dev-main ~]$ kubectl run fwnginx --image=nginx\npod/fwnginx created\n[xavier@xa-dev-main ~]$ kubectl port-forward fwnginx 8080:80 &amp;\n[1] 2609368\n[xavier@xa-dev-main ~]$ Forwarding from 127.0.0.1:8080 -&gt; 80\nForwarding from [::1]:8080 -&gt; 80\n\n[xavier@xa-dev-main ~]$ curl localhost:8080\nHandling connection for 8080\n&lt;!DOCTYPE html&gt;\n&lt;html&gt;\n&lt;head&gt;\n&lt;title&gt;Welcome to nginx!&lt;/title&gt;\n&lt;style&gt;\nhtml { color-scheme: light dark; }\nbody { width: 35em; margin: 0 auto;\nfont-family: Tahoma, Verdana, Arial, sans-serif; }\n&lt;/style&gt;\n&lt;/head&gt;\n&lt;body&gt;\n&lt;h1&gt;Welcome to nginx!&lt;/h1&gt;\n&lt;p&gt;If you see this page, the nginx web server is successfully installed and\nworking. Further configuration is required.&lt;/p&gt;\n\n&lt;p&gt;For online documentation and support please refer to\n&lt;a href=\"http://nginx.org/\"&gt;nginx.org&lt;/a&gt;.&lt;br/&gt;\nCommercial support is available at\n&lt;a href=\"http://nginx.com/\"&gt;nginx.com&lt;/a&gt;.&lt;/p&gt;\n\n&lt;p&gt;&lt;em&gt;Thank you for using nginx.&lt;/em&gt;&lt;/p&gt;\n&lt;/body&gt;\n&lt;/html&gt;\n</code></pre>"},{"location":"kubernetes/ckad/6_Pod_Advanced_Features/6_4_Restart_Policy/","title":"6.4 Restart Policy","text":"<p>restartPolicy determines what happens if a container, that is managed by a pod, crashes. Restart policy does not affect the state of the entire pod, though. If the Pod is stopped or killed, <code>restartPolicy=always</code> won't restart it</p>"},{"location":"kubernetes/ckad/6_Pod_Advanced_Features/6_5_Jobs/","title":"6.4 Jobs","text":"<p>In Kubernetes, a Job is a resource used to run tasks that need to be completed successfully once or a specific number of times. Unlike a Deployment or Pod, which manages long-running services or applications, a Job ensures that a particular task, such as a batch job or short-lived process, is completed successfully. Once this job is complete, though, you should use <code>spec.ttlSecondsAfterFinished</code> to clean up completed jobs automatically</p>"},{"location":"kubernetes/ckad/6_Pod_Advanced_Features/6_5_Jobs/#job-types","title":"Job Types","text":"<ul> <li>Non Parallel:<ul> <li>Only one Pod is started, unless the Pod fails.</li> <li>The Job is complete as soon as its Pod terminates successfully</li> </ul> </li> <li>Parallel Jobs:<ul> <li>Specify a non-zero positive value for .spec.completions.</li> <li>The Job represents the overall task, and is complete when there are .spec.completions successful Pods.</li> <li>When using .spec.completionMode=\"Indexed\", each Pod gets a different index in the range 0 to .spec.completions-1.</li> </ul> </li> <li>Parallel Jobs w/ Work Queue:<ul> <li>Do not specify <code>.spec.completions</code>, default to <code>.spec.parallelism</code>.</li> <li>The Pods must coordinate amongst themselves or an external service to determine what each should work on. For example, a Pod might fetch a batch of up to N items from the work queue.</li> <li>Each Pod is independently capable of determining whether or not all its peers are done, and thus that the entire Job is done.</li> <li>When any Pod from the Job terminates with success, no new Pods are created.</li> <li>Once at least one Pod has terminated with success and all Pods are terminated, then the Job is completed with success.</li> <li>Once any Pod has exited with success, no other Pod should still be doing any work for this task or writing any output. They should all be in the process of exiting.</li> </ul> </li> </ul> Generating the YAML Generating The Initial YAMLmynewjob.yaml <pre><code>kubectl create job mynewjob --image=busybox --dry-run=client -o yaml -- sleep 5 &gt; mynewjob.yaml\n</code></pre> <pre><code>apiVersion: batch/v1\nkind: Job\nmetadata:\ncreationTimestamp: null\nname: mynewjob\nspec:\ncompletions: 3 # I Added this line \nttlSecondsAfterFinished: 60 # I Added this line\ntemplate:\n    metadata:\n    creationTimestamp: null\n    spec:\n    containers:\n    - command:\n        - sleep\n        - \"5\"\n        image: busybox\n        name: mynewjob\n        resources: {}\n    restartPolicy: Never\nstatus: {}\n</code></pre>"},{"location":"kubernetes/ckad/6_Pod_Advanced_Features/6_6_Cron_Jobs/","title":"6.6 Cron Jobs","text":"<p>A Cron Job adds a schedule to a job. </p> Cronjobs Cronjob ExampleExplanation <pre><code>kubectl create cronjob runme --image=busybox --schedule=\"*/2 * * * *\" -- echo greetings from the cluster\n</code></pre> <p>The following creates a cron job, named <code>runme</code>,  that runs every 2 minutes. It uses the busybox image and echos \"greetings from the cluster\"</p>"},{"location":"kubernetes/ckad/6_Pod_Advanced_Features/6_6_Cron_Jobs/#testing","title":"Testing","text":"<p>Lets say you have a cronjob that only runs once a week, but you want to test it now. You can test your cronjobs like  this: <code>kubectl create job {name-of-job} --from=cronjob/{name-of-job}</code>. </p>"},{"location":"kubernetes/ckad/6_Pod_Advanced_Features/6_7_Cleaning_Up_Resources/","title":"6.7 Cleaning Up Resources","text":"<p>Resources are not automatically cleaned up. Some resources have options for automatic cleanup if theyre no longer used. </p> <p>Note</p> <p>If a resource is created by another resource, the parent resource must be deleted to successfully clean up. If the child is deleted, it will just be created again. For example, if a pod is created from a deployment, the deployment must be deleted.</p> <p>Warning</p> <p>DO NOT RUN THIS COMMAND --&gt; <code>kubectl delete all --all -A --force --grace-period=-1</code> This will bring the resources into an unmanageable state. You could potentially fail exam because of this.</p>"},{"location":"kubernetes/ckad/labs/5_Pod_Basic_Features/","title":"5 - Pod Basic Features","text":"<ol> <li>Create a YAML file that meets the following requirements:<ul> <li>A Namespace with the name \"microservice\" is created.</li> <li>A Pod with the name \"microdb\", based on the mariadb image is started in this Namespace.</li> </ul> </li> <li>Create the resources using the declarative methodology.</li> </ol> Answers <p><code>kubectl create ns microservice --dry-run=client -o yaml &gt; lab.yaml</code></p> <p><code>kubectl run microdb --image=mariadb --env MARIADB_ROOT_PASSWORD=password -n microservice --dry-run=client -o yaml &gt;&gt; labs.yaml</code></p> <pre><code>#lab.yaml\n---\napiVersion: v1\nkind: Namespace\nmetadata:\ncreationTimestamp: null\nname: micro\nspec: {}\nstatus: {}\n\n---\napiVersion: v1\nkind: Pod\nmetadata:\ncreationTimestamp: null\nlabels:\n    run: microdb\nname: microdb\nnamespace: micro\nspec:\ncontainers:\n- env:\n    - name: MARIADB_ROOT_PASSWORD\n    value: password\n    image: mariadb\n    name: microdb\n    resources: {}\ndnsPolicy: ClusterFirst\nrestartPolicy: Always\nstatus: {}\n</code></pre>"},{"location":"kubernetes/ckad/labs/6_Pod_Advanced_Features/","title":"6 - Pod Advanced Features","text":"<ol> <li>Create a CronJob that will run the sleep command for 30 seconds. If after 15 seconds it fails, it still runs, make sure it its killed and start the cycle over. </li> </ol> Answers <p><code>kubectl create cronjob runme --image=busybox --dry-run=client -o yaml --schedule=\"*/2 * * * *\" -- sleep 30 &gt; lab_6.yaml</code></p> <pre><code>apiVersion: batch/v1\nkind: CronJob\nmetadata:\n  creationTimestamp: null\n  name: runme\nspec:\n  jobTemplate:\n    metadata:\n      creationTimestamp: null\n      name: runme\n    spec:\n      activeDeadlineSeconds: 15\n      template:\n        metadata:\n          creationTimestamp: null\n        spec:\n          containers:\n          - command:\n            - sleep\n            - \"30\"\n            image: busybox\n            name: runme\n            resources: {}\n        restartPolicy: OnFailure\n  schedule: '* * * * *'\nstatus: {}           \n</code></pre>"},{"location":"networks/","title":"Test","text":""},{"location":"networks/IP%20Addresses/","title":"IP Addresses","text":"<p>192.168.10.5</p> <p>This is an IP adrress. Well, actually it's just a bunch of 1s and 0s (32 to be exact). You see, our  computers only understand 1s and 0s. The pretty formatting is just for us humans. </p>"},{"location":"networks/VPC/","title":"Internet Gateway","text":""},{"location":"networks/VPC/#route-table","title":"Route Table","text":"<p>Routes traffic from subnet to internet gateway</p>"},{"location":"networks/subnetting/","title":"Subnetting","text":"<p>Subnetting is the term given to splitting up a network into smaller, miniature networks within itself. Think of it as slicing up a cake for your friends. There's only a certain amount of cake to go around, but everybody wants a piece. Subnetting is you deciding who gets what slice &amp; reserving such a slice of this metaphorical cake.</p>"},{"location":"python/","title":"Test","text":""},{"location":"python/Comparisons/","title":"Walrus Operator","text":"<p>Introduced in Python 3.8, the walrus operator allows us to assign variables from within an expression  <pre><code>&gt;&gt;&gt; num = 15\n&gt;&gt;&gt; print(num)\n15\n\n\n#Again, but using the walrus opertor.\n&gt;&gt;&gt; print(num:=15)\n15\n</code></pre></p> <p>Another example:</p> <pre><code> &gt;&gt;&gt; tweet_limit = 280  \n&gt;&gt;&gt; tweet_string = \"Blah\" * 50  \n&gt;&gt;&gt; diff = tweet_limit - len(tweet_string) &gt;&gt;&gt; if diff &gt;= 0:  \n... print(\"A fitting tweet\")  \n... else:  \n... print(\"Went over by\", abs(diff)) ...  \nA fitting tweet\n\n#Again, but using the walrus operator.\n\n&gt;&gt;&gt; tweet_limit = 280  \n&gt;&gt;&gt; tweet_string = \"Blah\" * 50  \n&gt;&gt;&gt; if diff := tweet_limit - len(tweet_string) &gt;= 0: ... print(\"A fitting tweet\")  \n... else:  \n... print(\"Went over by\", abs(diff))  \n...  \nA fitting tweet\n</code></pre>"},{"location":"python/Data%20Types/","title":"Data Types","text":"<p>Data Type refers to what kind of data a value represents. The following are built in data types in Python:</p> <ul> <li>Numeric<ul> <li>Integer </li> <li>Float</li> <li>Complex Number</li> </ul> </li> <li>Dictionary</li> <li>Boolean</li> <li>Set </li> <li>Sequence Type<ul> <li>[[Strings]]</li> <li>List</li> <li>Tuple</li> </ul> </li> </ul>"},{"location":"python/Data%20Types/#-strings-are-a-fundamental-data-type-this-means-that-they-cant-be-broken-down-into-smaller-values-of-a-different-type","title":"- Strings are  a fundamental data type. This means that they can't be broken down into smaller values of a different type.","text":""},{"location":"python/Decorators/","title":"Decorators","text":"<p>Alright, imagine you have a magical pen that can change the appearance of your notebooks. Let's say you have a boring notebook, but with your magical pen, you can add cool designs or colors to it without changing the content inside. Decorator functions in Python are a bit like that magical pen.</p> <p>In Python, functions are like the content of your notebook. They do stuff when you call them, like adding numbers or printing messages. Now, a decorator function is a special kind of function that can change or enhance other functions without actually changing their code.</p> <p>Think of it this way: You have a plain function, let's call it \"plain_notebook.\" It does its job, just like a plain, boring notebook. Now, you want to spice things up a bit. You create a decorator function, let's call it \"decorate_notebook,\" which takes the plain notebook and adds some cool designs or colors to it.</p> <pre><code>def decorate_notebook(plain_notebook_function):\n    def decorated_notebook_function():\n        print(\"Decorating the notebook...\")\n        plain_notebook_function()\n        print(\"Notebook decorated!\")\n    return decorated_notebook_function\n\n@decorate_notebook\ndef plain_notebook():\n    print(\"This is a plain notebook.\")\n\nplain_notebook()\n</code></pre> <p>In this example, <code>decorate_notebook</code> is the decorator function. It takes <code>plain_notebook</code> as input, adds some extra stuff to it (printing messages before and after calling <code>plain_notebook</code>), and returns a new function called <code>decorated_notebook_function</code>. Then, we use the <code>@</code> symbol to apply the decorator to <code>plain_notebook</code>.</p> <p>So when you call <code>plain_notebook()</code>, it actually calls <code>decorated_notebook_function()</code> instead. This means it will first print \"Decorating the notebook...\", then execute the code inside <code>plain_notebook</code> (which prints \"This is a plain notebook.\"), and finally print \"Notebook decorated!\".</p> <p>So, in short, decorator functions in Python allow you to modify or enhance the behavior of other functions without changing their code directly, similar to how a magical pen can change the appearance of a notebook without altering its contents.</p> <p>Execution:</p> <ul> <li>Call <code>plain_notebook()</code>.</li> <li><code>plain_notebook</code> is decorated, so it actually calls <code>decorated_notebook_function</code>.</li> <li><code>decorated_notebook_function</code> adds extra functionality by printing messages and then calling the original <code>plain_notebook_function</code>.</li> <li>Finally, the execution completes after the messages are printed.</li> </ul>"},{"location":"python/Generator/","title":"Generator","text":"<p>A generator expression is similar to a list comprehension, but it produces values lazily as they are needed, rather than creating an entire list in memory. This can be more memory efficient, especially when dealing with large datasets.</p> <p>In Python, a generator expression is defined within parentheses <code>()</code> rather than square brackets <code>[]</code> used for list comprehensions. Here's the general syntax:</p> <pre><code>(expression for item in iterable if condition)\n</code></pre> <pre><code>test_list = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n\ndoubled_generator = (x * 2 for x in test_list)\n\nfor doubled_value in doubled_generator:        print(doubled_value)\n\n&gt;&gt; 2 4 6 8 10 12 14 16 18 20\n</code></pre> <p>When you access a key directly in a dictionary using square brackets (<code>[]</code>), it raises a <code>KeyError</code> if the key doesn't exist in the dictionary. However, using the <code>get()</code> method allows you to provide a default value that will be returned if the key is not found, thus avoiding the <code>KeyError</code></p>"},{"location":"python/Generator/#generators","title":"generators","text":""},{"location":"python/How%20To%20Modify%20%20Global%20Scope/","title":"How To Modify  Global Scope","text":"<pre><code>enemies = 1\n\n#This wont work\ndef increase_enemies():\n    enemies += 1\n    print(enemies)\n\n\n#Option 1...but bad practice \ndef increase_enemies():\n    global enemies \n    enemies += 1\n    print(enemies)\n\n#Option 2 - &gt; Using return \nenemies = 1\ndef increase_enemies():\n    return enemies + 1\n</code></pre> <p>When To Use Global Variables</p> <ol> <li>When using constants.<ol> <li>Something you define, but will NEVER change.</li> </ol> </li> </ol>"},{"location":"python/How%20To%20Modify%20%20Global%20Scope/#tips","title":"tips","text":""},{"location":"python/JSON/","title":"Dump","text":"<p>Allows you to store JSON data directly into a file. It serializes the data, then writes to a file object</p> <pre><code>import json  \n\ntest_dict = {  \n    \"name\": \"Xavier\",  \n    \"age\": 31  \n}  \n\nwith open(\"test.json\", \"w\") as file:  \n    json.dump(test_dict, file, indent=4)\n\n# test.json file\n\n{  \n    \"name\": \"Xavier\",  \n    \"age\": 31  \n}\n</code></pre>"},{"location":"python/JSON/#load","title":"Load","text":"<p>Read and deserialize from a json file.  <pre><code>with open(\"test.json\",  \"r\") as file:  \n    data = json.load(file)  \n    print(data)\n\n# Output\n{'name': 'Xavier', 'age': 31}\n</code></pre></p>"},{"location":"python/JSON/#update","title":"Update","text":""},{"location":"python/Nested%20Loops/","title":"Nested Loops","text":"<pre><code>&gt;&gt;&gt; rows=range(1,4)\n&gt;&gt;&gt; cols=range(1,3)\n&gt;&gt;&gt; for row in rows:\n    ...     for col in cols:\n    ...             print(row,col)\n...\n1 1\n1 2\n2 1\n2 2\n3 1\n3 2\n</code></pre> <p>This was a bit confusing at first. What helped me was to imagine the first loop as a counter, and the inner loop as something your doing {counter} amount of times. For each iteration of an outer loop the inner loop re-start and completes its execution\u00a0before the outer loop can continue to its next iteration. Here's another example with strings.</p> <pre><code>&gt;&gt;&gt; adj = [\"red\", \"big\", \"tasty\"]\n&gt;&gt;&gt; fruits = [\"apple\", \"banana\", \"cherry\"]\n&gt;&gt;&gt; for x in adj:\n    ...     for y in fruits:\n    ...             print(x,y)\n...\nred apple\nred banana\nred cherry\nbig apple\nbig banana\nbig cherry\ntasty apple\ntasty banana\ntasty cherry\n</code></pre>"},{"location":"python/OOP/","title":"OOP","text":"<p>``` python class User     def init(self,  user_id, username):         #ATTRIBUTES         self.id = user_id         self.username = username         self.followers = 0         self.following = 0</p> <pre><code>    #METHODS\n    def follow(self, user_to_follow):\n        user_to_follow.followers +=1\n        self.following += 1 \n    ```\n</code></pre> <p>Classes are like blueprints. Objects are built from classes. </p>"},{"location":"python/OOP/#the-anatomy-of-a-class","title":"The Anatomy of A Class","text":"<ul> <li>Attributes<ul> <li>Variables that are associated with an object. We could call these the nouns.</li> </ul> </li> <li>Methods<ul> <li>Could call these the verbs.</li> </ul> </li> <li><code>__init__</code></li> <li>Constructors<ul> <li>This says what happens when the class is called upon. </li> <li><code>def __init__(self)</code></li> </ul> </li> </ul>"},{"location":"python/Pandas/","title":"Pandas","text":"<p>Pandas is a python data analysis tool.  The two fundamental data structures in pandas are series and dataframes.</p>"},{"location":"python/Pandas/#series","title":"Series","text":"<p><code>Series</code>\u00a0is a one-dimensional labeled array capable of holding any data type (integers, strings, floating point numbers, Python objects, etc.). The axis labels are collectively referred to as the\u00a0index. The basic method to create a\u00a0<code>Series</code>\u00a0is to call: Here,\u00a0<code>data</code>\u00a0can be many different things. dict, ndarray, a scalar value (like 5)</p> <p>The passed\u00a0index\u00a0is a list of axis labels. Thus, this separates into a few cases depending on what\u00a0data is. This example the data is ndarray</p> <pre><code>&gt;&gt;&gt; s = pd.Series(np.random.randn(5), index=[\"a\", \"b\", \"c\", \"d\", \"e\"])\n&gt;&gt;&gt; s\na   -0.815774\nb   -0.369123\nc   -0.290913\nd   -1.284814\ne    2.119353\n</code></pre>"},{"location":"python/Pandas/#dictionary","title":"Dictionary","text":"<pre><code>&gt;&gt;&gt; d = {\"b\": 1, \"a\": 0, \"c\": 2}\n&gt;&gt;&gt; pd.Series(d)\nb    1\na    0\nc    2\n</code></pre>"},{"location":"python/Pandas/#dataframes","title":"Dataframes","text":"<p><code>DataFrame</code>\u00a0is a 2-dimensional labeled data structure with columns of potentially different types. You can think of it like a spreadsheet or SQL table, or a dict of Series objects. It is generally the most commonly used pandas object. Along with the data, you can optionally pass\u00a0index\u00a0(row labels) and\u00a0columns\u00a0(column labels) arguments. If you pass an index and / or columns, you are guaranteeing the index and / or columns of the resulting DataFrame. Thus, a dict of Series plus a specific index will discard all data not matching up to the passed index. \u00a0Like Series, DataFrame accepts many different kinds of input: -   Dict of 1D ndarrays, lists, dicts, or\u00a0<code>Series</code> -   2-D numpy.ndarray -   Structured or record\u00a0ndarray -   A\u00a0<code>Series</code> -   Another\u00a0<code>DataFrame</code></p> <p>It may be helpful to think of the Pandas DataFrame as a dictionary of columns, or Pandas Series, with many additional features. <pre><code>&gt;&gt;&gt; data = {\n...     'name': ['Xavier', 'Ann', 'Jana', 'Yi', 'Robin', 'Amal', 'Nori'],\n...     'city': ['Mexico City', 'Toronto', 'Prague', 'Shanghai',\n...              'Manchester', 'Cairo', 'Osaka'],\n...     'age': [41, 28, 33, 34, 38, 31, 37],\n...     'py-score': [88.0, 79.0, 81.0, 80.0, 68.0, 61.0, 84.0]\n... }\n&gt;&gt;&gt; row_labels = [101, 102, 103, 104, 105, 106, 107]\n&gt;&gt;&gt; df = pd.DataFrame(data=data, index=row_labels)\n&gt;&gt;&gt; df\n       name         city  age  py-score\n101  Xavier  Mexico City   41      88.0\n102     Ann      Toronto   28      79.0\n103    Jana       Prague   33      81.0\n104      Yi     Shanghai   34      80.0\n105   Robin   Manchester   38      68.0\n106    Amal        Cairo   31      61.0\n107    Nori        Osaka   37      84.0\n</code></pre></p> <p>Another example: <pre><code>\n</code></pre></p>"},{"location":"python/Runner%20API/","title":"Runner API Project","text":"<p>[[2023-06-06]]</p> <p>Currently learning about Blueprints and Flask MethodViews</p>"},{"location":"python/Runner%20API/#what-are-blueprints","title":"What are Blueprints?","text":"<p>Each Flask Blueprint is an\u00a0object\u00a0that works very similarly to a Flask application. They both can have resources, such as static files, templates, and views that are associated with routes.</p> <p>However, a Flask Blueprint is not actually an application. It needs to be registered in an application before you can run it. When you register a Flask Blueprint in an application, you\u2019re actually\u00a0extending\u00a0the application with the contents of the Blueprint.</p> <p>This is the key concept behind any Flask Blueprint.\u00a0They record operations to be executed later when you register them on an application.\u00a0For example, when you associate a view to a route in a Flask Blueprint, it records this association to be made later in the application when the Blueprint is registered.</p>"},{"location":"python/Runner%20API/#what-are-method-views","title":"What are Method Views?","text":"<p>For APIs it can be helpful to use a different function for each HTTP method.\u00a0<code>MethodView</code>\u00a0extends the basic\u00a0<code>View</code>\u00a0to dispatch to different methods of the class based on the request method. Each HTTP method maps to a method of the class with the same (lowercase) name</p> <p>[[2023-06-07]] Swagger UI</p>"},{"location":"python/Runner%20API/#marshmellow-schemas","title":"Marshmellow Schemas","text":"<p>The\u00a0<code>marshmallow</code>1\u00a0library is used to define\u00a0what\u00a0data fields we want, and then we can pass incoming data through the validator. We can also go the other way round, and give it a Python object which\u00a0<code>marshmallow</code>\u00a0then turns into a dictionary.</p> <p>Schemas serve as the core of Marshmallow by keeping track of the data through the declared schema. The schemas define the structure of the data and also the validation of the data. We use schemas to validate incoming data to our API</p> <pre><code>class RunnersSchema(Schema):  \nid = fields.Str(dump_only=True)  \nfirst_name = fields.Str(required=True)  \nlast_name = fields.Str(required=True)  \nhalf_marathon = fields.Str(required=True)  \nmarathon = fields.Str(required=True)\n</code></pre>"},{"location":"python/Runner%20API/#serialization-vs-deserialization","title":"Serialization vs Deserialization","text":"<p>Data serialization is the process of converting structured data to a format that allows sharing or storage of the data in a form that allows recovery of its original structure. In some cases, the secondary intention of data serialization is to minimize the data\u2019s size which then reduces disk space or bandwidth requirements.</p>"},{"location":"python/Runner%20API/#validating-the-data","title":"Validating The Data","text":"<p><code>Blueprint.arguments</code> - Validates and deserializaes a request payload <code>Blueprint.response</code> - This doesnt perform validations. It just serializes the payload.</p> <p>SQL Alchemy Intro Connecting SQL Alchemy to pur app</p> <p>[[2023-06-08]]</p>"},{"location":"python/Selenium/","title":"Selenium","text":"<pre><code>from selenium import webdriver  \nfrom selenium.webdriver.common.by import By  \nfrom selenium.webdriver.common.keys import Keys  \n\nchrome_options = webdriver.ChromeOptions()  \nchrome_options.add_experimental_option(\"detach\", True)  \n\ndriver = webdriver.Chrome(options=chrome_options)  \ndriver.get(\"https://secure-retreat-92358.herokuapp.com/\")  \n\n# captcha = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.LINK_TEXT, \"Try different image\")))  \n# captcha.click()  \n\n# WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CLASS_NAME, \"menu\")))  \n# article_number = driver.find_element(By.XPATH, value='//*[@id=\"articlecount\"]/a[1]')  \n# anyone = driver.find_element(By.LINK_TEXT, value='anyone can edit')  \n#  \n#  \n# search = driver.find_element(By.NAME, value='search')  \n# search.send_keys('Python')  \n# search.send_keys(Keys.RETURN)  \n\nfirst_name = driver.find_element(By.NAME, value='fName')  \nlast_name = driver.find_element(By.NAME, value='lName')  \nemail = driver.find_element(By.NAME, value='email')  \n\nfirst_name.send_keys('test')  \nlast_name.send_keys('tester')  \nemail.send_keys('test_example@gmail.com')  \nemail.send_keys(Keys.RETURN)\n</code></pre> <p>get_attribute</p> <p>The getAttribute method in Selenium is used to retrieve the value of a specific attribute from a web element. For example, if you have an HTML element like <code>input type=\"text\" value=\"Hello\"</code>, you can use getAttribute(\"value\") to get the value \"Hello\".</p> <p>Or in the example of the cookie cutter project:</p> <pre><code>&lt;div class=\"product unlocked enabled\" onmouseout=\"Game.tooltip.shouldHide=1;\"\n     onmouseover=\"Game.tooltip.dynamic=1;Game.tooltip.draw(this,function(){return Game.ObjectsById[0].tooltip();},'store');Game.tooltip.wobble();\"\n     id=\"product0\"&gt;\n    &lt;div class=\"icon off\" id=\"productIconOff0\" style=\"background-position: -64px 0px;\"&gt;&lt;/div&gt;\n    &lt;div class=\"icon\" id=\"productIcon0\" style=\"background-position: 0px 0px;\"&gt;&lt;/div&gt;\n    &lt;div class=\"content\"&gt;\n        &lt;div class=\"lockedTitle\"&gt;???&lt;/div&gt;\n        &lt;div class=\"title productName\" id=\"productName0\"&gt;Cursor&lt;/div&gt;\n        &lt;span class=\"priceMult\" id=\"productPriceMult0\"&gt;&lt;/span&gt;&lt;span class=\"price\" id=\"productPrice0\"&gt;15&lt;/span&gt;\n        &lt;div class=\"title owned\" id=\"productOwned0\"&gt;&lt;/div&gt;\n    &lt;/div&gt;\n&lt;/div&gt;\n</code></pre> <pre><code>unlocked_items = driver.find_elements(By.CSS_SELECTOR, '.unlocked')  \n# This returns a list of items where `unlocked' is in the class name\nunlocked_items_ids = [i.get_attribute('id') for i in unlocked_items]\n# This looks at the unlocked_items list. For every unlocked_item,, it retrvies the id and its value\n</code></pre>"},{"location":"python/Serialization/","title":"Serialization","text":"<p>Data serialization is the process of converting structured data to a format that allows sharing or storage of the data in a form that allows recovery of its original structure. In some cases, the secondary intention of data serialization is to minimize the data\u2019s size which then reduces disk space or bandwidth requirements</p>"},{"location":"python/Strings/","title":"Strings","text":"<p>Collections of text in Python are called strings. Functions used to manipulate strings are called string methods.</p>"},{"location":"python/Strings/#immutability","title":"Immutability","text":"<p>STRINGS ARE IMMUTBLE!! You can't change them once created.  You can't change the letters of a string.  If you want to change a string, do the following:</p> <pre><code>&gt;&gt;&gt;word = \"goal\"\n&gt;&gt;&gt; word = \"f\" + word[1:]\n&gt;&gt;&gt; word\n'foal'``\n</code></pre> <p>Most string methods that alter a string, simply make a copy of it. If you want to actually keep the result, you need to assign it to a variable.</p>"},{"location":"python/Strings/#tips","title":"tips","text":""},{"location":"python/Strings/#string-literals","title":"String Literals","text":"<p>Whenever you create a string by surroundng text with a quotation mark, the string is called a string literal. The quotes around the string literal are called delimiters</p>"},{"location":"python/Strings/#indexing-and-slicing","title":"Indexing and Slicing","text":"<p>The largest index in a string is always one less than the string's length.</p> <p>You can extract a portion of a string, called a substring, by inserting a colon between two index numbers set inside square brackets. This is called slicing.  For the next slicing examples, we'll be using the following: <pre><code>&gt;&gt;&gt; flavor = \"fig pie\"\n&gt;&gt;&gt; flavor[0:3]\n'fig'\n</code></pre></p> <p>Slicing can be super confusing. To remember how it works lets look at the following.</p> <p>![[Pasted image 20220314194727.png]]</p> <p>If you omit the first index in a slice, Python assumes you want to start at index 0.  ```python</p> <p>flavor = \"fig pie\" flavor[:3] 'fig' <pre><code>&gt;  If you omit the 2nd index, you start at that index, and go until the end of the string.\n\n```python\n&gt;&gt;&gt; flavor[3:]\n ' pie'\n</code></pre></p> <p>The rules for slicing with negative numbers are exactly the same as th erules for slicing with positive numbers ![[Pasted image 20220316192504.png]]</p> <p>To go backwards, omit the starting postion, and ending position. Then for the step, use -1. <pre><code>&gt;&gt;&gt; lst = [2,4,6,8]\n&gt;&gt;&gt; lst[::-1]\n[8, 6, 4, 2]\n</code></pre></p>"},{"location":"python/Strings/#string-methods","title":"String Methods","text":"<ul> <li>.rstrip()</li> <li>.lstrip()</li> <li>.strip</li> <li>.upper()</li> <li>.lower()</li> <li>.endswith()</li> <li>.startswith()</li> </ul>"},{"location":"python/Tuples/","title":"Tuples","text":"<p>Use tuples when you want to create a list of items that does not change.  <pre><code>&gt;&gt;&gt; dimensions = (0,200)\n&gt;&gt;&gt; dimensions[0] = 10\nTraceback (most recent call last):\n  File \"&lt;stdin&gt;\", line 1, in &lt;module&gt;\nTypeError: 'tuple' object does not support item assignment\n</code></pre></p>"},{"location":"python/Tuples/#but-wait","title":"But wait!","text":"<p>Although you can\u2019t modify a tuple, you can assign a new value to a variable that represents a tuple. <pre><code>&gt;&gt;&gt; print(dimensions)\n(0, 200)\n&gt;&gt;&gt; dimensions = 200,400\n&gt;&gt;&gt; print(dimensions)\n(200, 400)\n&gt;&gt;&gt;\n</code></pre></p> <p>Sidenote - You don't need parentheses. Tuples are technically defined by the presence of a comma; the parentheses make them look neater and more readable. If you want to define a tuple with one element, you need to include a trailing comma:</p>"},{"location":"python/Unpacking/","title":"Unpacking","text":"<p>Unpacking in Python refers to:</p> <ol> <li>An operation that consists of assigning an iterable of values to a tuple (or <code>list</code>) of variables in a single assignment statement. </li> <li>As a complement, the term packing can be used when we collect several values in a single variable using the iterable unpacking operator, <code>*</code>.</li> </ol> <p>For the purpose of this doc, we'll be focusing on 1.</p> <p>Python allows a <code>tuple</code> (or <code>list</code>) of variables to appear on the left side of an assignment operation. Each variable in the <code>tuple</code> can receive one value (or more, if we use the <code>*</code> operator) from an iterable on the right side of the assignment.</p> <pre><code>&gt;&gt;&gt; # Unpacking strings\n&gt;&gt;&gt; a, b, c = '123'\n&gt;&gt;&gt; a\n'1'\n&gt;&gt;&gt; b\n'2'\n&gt;&gt;&gt; c\n'3'\n&gt;&gt;&gt; # Unpacking lists\n&gt;&gt;&gt; a, b, c = [1, 2, 3]\n&gt;&gt;&gt; a\n1\n&gt;&gt;&gt; b\n2\n&gt;&gt;&gt; c\n3\n</code></pre>"},{"location":"python/Variables/","title":"Variables","text":""},{"location":"python/Variables/#what-is-happening-behind-the-scenes","title":"What is happening behind the scenes?","text":""},{"location":"python/Variables/#object-references","title":"Object References","text":"<p>Python is a highly\u00a0object-oriented language. In fact, virtually every item of data in a Python program is an object of a specific type or class. (This point will be reiterated many times over the course of these tutorials.)</p> <pre><code>&gt;&gt;&gt; print(300)\n300\n</code></pre> <p>When presented with the statement\u00a0<code>print(300)</code>, the interpreter does the following: -   Creates an integer object -   Gives it the value\u00a0<code>300</code> -   Displays it to the console</p> <p>A Python variable is a symbolic name that is a reference or\u00a0pointer\u00a0to an object. Once an object is assigned to a variable, you can refer to the object by that name. But the data itself is still contained within the object.</p> <p><pre><code>n=300\n</code></pre> This assignment creates an integer object with the value\u00a0<code>300</code>\u00a0and assigns the variable\u00a0<code>n</code>\u00a0to point to that object.</p> <p>Now, what happens when we attempt to assign a variable to <code>n</code>? <pre><code>&gt;&gt;&gt; n=300\n&gt;&gt;&gt; m=n\n&gt;&gt;&gt; m\n300\n</code></pre> What happens when it is executed? Python does not create another object. It simply creates a new symbolic name or reference,\u00a0<code>m</code>, which points to the same object that\u00a0<code>n</code>\u00a0points to. ![[Pasted image 20221116054400.png]]</p>"},{"location":"python/Variables/#reassignment","title":"Reassignment","text":"<p>If you were to reassign n to foo, n will now point to foo. There is no longer any reference to the integer object\u00a0<code>300</code>. It is orphaned, and there is no way to access it.</p> <p>![[Pasted image 20221116054559.png | 800]]</p>"},{"location":"python/Variables/#object-identity","title":"Object Identity","text":"<p>In Python, every object that is created is given a number that uniquely identifies it. It is guaranteed that no two objects will have the same identifier during any period in which their lifetimes overlap. Once an object\u2019s reference count drops to zero and it is garbage collected, as happened to the\u00a0<code>300</code>\u00a0object above, then its identifying number becomes available and may be used again.</p> <p>After the assignment\u00a0<code>m = n</code>,\u00a0<code>m</code>\u00a0and\u00a0<code>n</code>\u00a0both point to the same object, confirmed by the fact that\u00a0<code>id(m)</code>\u00a0and\u00a0<code>id(n)</code>\u00a0return the same number. Once\u00a0<code>m</code>\u00a0is reassigned to\u00a0<code>400</code>,\u00a0<code>m</code>\u00a0and\u00a0<code>n</code>\u00a0point to different objects with different identities.</p> <pre><code>&gt;&gt;&gt; id(m)\n4450787888\n&gt;&gt;&gt; id(n)\n4450787888\n&gt;&gt;&gt;\n</code></pre>"},{"location":"python/Variables/#deep-dive","title":"Deep Dive","text":"<p>With the statement\u00a0<code>m = 300</code>, Python creates an integer object with the value\u00a0<code>300</code>\u00a0and sets\u00a0<code>m</code>\u00a0as a reference to it.\u00a0<code>n</code>\u00a0is then similarly assigned to an integer object with value\u00a0<code>300</code>\u2014but not the same object. Thus, they have different identities, which you can verify from the values returned by\u00a0<code>id()</code>. <pre><code>&gt;&gt;&gt; m = 300\n&gt;&gt;&gt; n = 300\n&gt;&gt;&gt; id(m)\n60062304\n&gt;&gt;&gt; id(n)\n60062896\n</code></pre></p> <p>But wait.. <pre><code>&gt;&gt;&gt; m = 30\n&gt;&gt;&gt; n = 30\n&gt;&gt;&gt; id(m)\n1405569120\n&gt;&gt;&gt; id(n)\n1405569120\n</code></pre></p> <p>Here,\u00a0<code>m</code>\u00a0and\u00a0<code>n</code>\u00a0are separately assigned to integer objects having value\u00a0<code>30</code>. But in this case,\u00a0<code>id(m)</code>\u00a0and\u00a0<code>id(n)</code>\u00a0are identical!</p> <p>For purposes of optimization, the interpreter creates objects for the integers in the range\u00a0<code>[-5, 256]</code>\u00a0at startup, and then reuses them during program execution. Thus, when you assign separate variables to an integer value in this range, they will actually reference the same object.</p>"},{"location":"python/Write%20Pythonic%20Code/","title":"Write Pythonic Code","text":"<ul> <li>Filyer List Using Comprehension</li> <li>Natural Numbers List</li> <li>Dictionaries </li> <li>Default Arguments</li> <li>Keyword Arguments</li> <li>Variable Arguments</li> <li>Variable Keyword Arguments</li> <li>Arithmetic Using Lambda</li> </ul>"},{"location":"python/class_method_parameters/","title":"Class method parameters","text":"<p>If an attribute is used across multiple methods, it makes sense to define it as a class attribute. If a value is specific to a method, it makes sense to pass it as a parameter.</p> <p>For example, if you have a method that needs to process a specific song or playlist, instead of setting the song or playlist as an attribute of the class, you could pass it as a parameter to the method.</p>"},{"location":"python/Data%20Structures/Data%20Structures/","title":"Data Structures","text":"<p>Python has the following data structures: - [[Python/Lists/Methods]] - [[Dictionaries]] - Tuple  - Sets</p>"},{"location":"python/Errors/Catching/","title":"Catching","text":"<p>Try and Except</p> <p></p>"},{"location":"python/Errors/Types/","title":"Syntax Errors","text":"<p>A syntax error occurs when you write code that isnt allowed in the Python language.  The following would produce a syntax error. These are caught before a program even starts running.  <pre><code>print(\"Hello World)\n\nEOL while scanning stirng literal\n</code></pre> 1. A string literal is the text enclosed in quotes. 2. EOL stands for end of line. </p>"},{"location":"python/Errors/Types/#runtime-errors","title":"Runtime Errors","text":"<p>These only occur when a program is running.</p> <p>Whenever an error occurs, python stops executing the program and displays several lines of text called a traceback. <pre><code>Traceback (most recent call last):\n  File \"/home/hello_world.py\", line 1, in &lt;module&gt; \n\n print(Hello, World)\nNameError: name 'Hello' is not defined\n</code></pre></p> <p>These are best read from the bottom up.  1. The last line tells you the name of the error.  2. The second to last line shows you the code that produced the error.  3. The third to last line tells you the name of the file and the line number so you can go to the exact spot  of the error. </p>"},{"location":"python/Flask/","title":"Test","text":""},{"location":"python/Flask/Basics/","title":"Basics","text":"<p>HTTP request is client request to server. HTTP response is sever response back to client. For example, if you type url in web browser and hit <code>enter</code>, the browser creates an\u00a0http request\u00a0containing http method, request url, request headers and request body, which gets sent to the server. The server gets this and then sends info back  to the web browser.</p>"},{"location":"python/Flask/Basics/#what-does-this-have-to-do-with-flask","title":"What Does This Have to Do With Flask?","text":"<p>This tripped me because I was routes, I was looking at from the perspective of a user. I thought I was creating the request. Nope! Here's some docs about flask responses: <pre><code>The return value from a view function is automatically converted into a response object for you. If the return value is a string it\u2019s converted into a response object with the string as response body, a\u00a0`200\u00a0OK`\u00a0status code and a\u00a0_text/html_\u00a0mimetype. If the return value is a dict or list,\u00a0`jsonify()`\u00a0is called to produce a response. The logic that Flask applies to converting return values into response objects is as follows:\n</code></pre></p>"},{"location":"python/Lists/Comprehension/","title":"Comprehension","text":"<p>List Comprehension</p> <pre><code>numbers = []\nfor x in range(3):\n    numbers.append(x)\n</code></pre> <pre><code>numbers = [x for x in range(3)]\n</code></pre> <p>To make this easier on myself, I just read it out, starting from the for keyword. This is the beginning of the foor loop, and that first variable(x) is what we would be printing or doeing something with if this was a normal <code>for loop</code>.</p>"},{"location":"python/Lists/Methods/","title":"Methods","text":""},{"location":"python/Lists/Methods/#addingremoving","title":"Adding/Removing","text":""},{"location":"python/Lists/Methods/#append","title":"append","text":"<p>list.append(element) This method adds an item to the end of a list. This does not return the new list, just modifies the original. <pre><code>&gt;&gt;&gt; test = [1,2,3,4]\n&gt;&gt;&gt; test.append(5)\n&gt;&gt;&gt; test\n[1, 2, 3, 4, 5]\n</code></pre></p>"},{"location":"python/Lists/Methods/#index","title":"index","text":"<p>list.insert(index, element) - inserts the element at the given index, shifting elements to the right <pre><code>&gt;&gt;&gt; test.insert(1,1.5)\n&gt;&gt;&gt; test\n[1, 1.5, 2, 3, 4, 5]\n</code></pre></p>"},{"location":"python/Lists/Methods/#extend","title":"extend","text":"<p>list.extend(list2) - adds the elements in list2 to the end of the list. Using + or += on a list is similar to using extend(). <pre><code>&gt;&gt;&gt; lst2 = [6,7,8]\n&gt;&gt;&gt; test.extend(lst2)\n&gt;&gt;&gt; test\n[1, 1.5, 2, 3, 4, 5, 6, 7, 8]\n</code></pre></p>"},{"location":"python/Lists/Methods/#remove","title":"remove","text":"<p>list.remove(element) - searches for the FIRST instance of the given element and removes it (throws ValueError if not present) <pre><code>&gt;&gt;&gt; test.remove(1.5)\n&gt;&gt;&gt; test\n[1, 2, 3, 4, 5, 6, 7, 8]\n</code></pre></p>"},{"location":"python/Lists/Methods/#sort","title":"sort","text":"<p>list.sort() - sorts the list in place (does not return it). (The sorted() function shown later is preferred.) <pre><code>&gt;&gt;&gt; test = [4,3,55,1,53,4]\n&gt;&gt;&gt; test.sort()\n&gt;&gt;&gt; test\n[1, 3, 4, 4, 53, 55]\n</code></pre></p>"},{"location":"python/Lists/Methods/#reverse","title":"reverse","text":"<p>list.reverse() - reverses the list in place (does not return it) <pre><code>&gt;&gt;&gt; test.reverse()\n&gt;&gt;&gt; test\n[55, 53, 4, 4, 3, 1]\n</code></pre></p>"},{"location":"python/Lists/Methods/#pop","title":"pop","text":"<p>list.pop(index) - removes and returns the element at the given index. Returns the rightmost element if index is omitted (roughly the opposite of append()). <pre><code>&gt;&gt;&gt; test\n[55, 53, 4, 4, 3, 1]\n&gt;&gt;&gt; test.pop()\n1\n&gt;&gt;&gt; test\n[55, 53, 4, 4, 3]\n</code></pre></p>"},{"location":"python/Lists/Slicing/","title":"Slicing","text":"<p>You can work with a specific group of items in a list , called a slice. To make a slice, you specify the index of the first and last elements you want to work with. As with the range() function, Python stops one item before the second index you specify.</p> <p>To better understand slicing, lets use some visuals <pre><code>&gt;&gt;&gt; colors = [\"red\", \"blue\", \"yellow\", \"green\", \"black\"]\n&gt;&gt;&gt; print(colors[0:2])\n['red', 'blue']\n\n0       1         2            3           4           5\n| red | blue | yellow | green | black |\n-5      -4       -3          -2          -1         0\n</code></pre></p> <p>If you omit the 1st index, ,python starts at the beginning of the list. If you omit the 2nd index, ,python goes until the end of the list. </p> <p>We can also use slicing to copy an entire list.  <pre><code>&gt;&gt;&gt; more_colors = colors[:]\n&gt;&gt;&gt; print(more_colors)\n['red', 'blue', 'yello', 'green', 'black']\n</code></pre></p>"},{"location":"python/Lists/reverse/","title":"Reverse","text":"<p>How To Reverse a List?</p>"},{"location":"python/Lists/reverse/#using-reverse-method","title":"Using reverse() method","text":"<pre><code>my_list = [1, 2, 3, 4, 5]  \nmy_list.reverse()  \nprint(my_list)  # Output: [5, 4, 3, 2, 1]  \n  ```\n# Using slicing  \n```python\nmy_list = [1, 2, 3, 4, 5]  \nreversed_list = my_list[::-1]  \nprint(reversed_list)  # Output: [5, 4, 3, 2, 1]\n</code></pre> <ul> <li>my_list = [1, 2, 3, 4, 5]: This line is creating a list of integers from 1 to 5 and assigning it to the variable my_list.  </li> <li>reversed_list = my_list[::-1]: This line is using slicing to create a reversed copy of my_list. The [::-1] part is the slicing syntax. The colon : is used to indicate the start and end indices. When no index is provided before the first colon, it means start from the beginning. When no index is provided after the first colon, it means go till the end. The -1 after the second colon indicates the step, which in this case is -1, meaning go backwards.  </li> <li>print(reversed_list): This line is printing the reversed list to the console. The output is [5, 4, 3, 2, 1], which is the list [1, 2, 3, 4, 5] in reverse order.</li> </ul>"},{"location":"python/requests/json_vs_data/","title":"Json vs data","text":"<ol> <li>json: This parameter is used to send JSON data in the body of the HTTP request. When you pass a Python dictionary to the <code>json</code> parameter, <code>requests</code> automatically serializes the dictionary to JSON format and sets the appropriate Content-Type header to <code>application/json</code>. This is particularly useful when working with APIs that expect JSON data.</li> </ol> <pre><code>    import requests  \n    data = {\"key\": \"value\"} \n    response = requests.post(url, json=data)\n    ```\n\n\n2. **data**: This parameter is used to send form-encoded data in the body of the HTTP request. When you pass a dictionary to the `data` parameter, `requests` encodes the data as key-value pairs and sets the Content-Type header to `application/x-www-form-urlencoded`. This is commonly used when submitting HTML forms or interacting with APIs that expect form-encoded data.\n\n\n```python\nimport requests\n\ndata = {\"key\": \"value\"}\nresponse = requests.post(url, data=data)\n</code></pre> <p>In summary, use json when you want to send JSON data and data when you want to send form-encoded data or raw bytes.</p>"},{"location":"python/requests/json_vs_data/#requests","title":"requests","text":""}]}